<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Python 爬虫获取指定主机子域名及IP信息 | Anka9080&#39;s Note</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="0x 00 前言前天自己在玩的时候，自己通过百度搜索主机的二级域名感觉好麻烦，自已要一页页的去翻
而且人工识别是否是重复的二级域名也够蛋疼的，正好最近在学正则表达式，权当练手了
2016年更新：发现了一些不错的扫子域名的网站，如下
http://subdomain.chaxun.la
0x 01 Code# coding=utf-8
# author:Anka9080
# environment">
<meta property="og:type" content="article">
<meta property="og:title" content="Python 爬虫获取指定主机子域名及IP信息">
<meta property="og:url" content="http://www.evilclay.com/2015/06/10/python-spider-subdomain-ip/index.html">
<meta property="og:site_name" content="Anka9080's Note">
<meta property="og:description" content="0x 00 前言前天自己在玩的时候，自己通过百度搜索主机的二级域名感觉好麻烦，自已要一页页的去翻
而且人工识别是否是重复的二级域名也够蛋疼的，正好最近在学正则表达式，权当练手了
2016年更新：发现了一些不错的扫子域名的网站，如下
http://subdomain.chaxun.la
0x 01 Code# coding=utf-8
# author:Anka9080
# environment">
<meta property="og:image" content="http://images0.cnblogs.com/blog2015/671902/201506/100041310046606.png">
<meta property="og:updated_time" content="2016-05-28T09:40:37.958Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python 爬虫获取指定主机子域名及IP信息">
<meta name="twitter:description" content="0x 00 前言前天自己在玩的时候，自己通过百度搜索主机的二级域名感觉好麻烦，自已要一页页的去翻
而且人工识别是否是重复的二级域名也够蛋疼的，正好最近在学正则表达式，权当练手了
2016年更新：发现了一些不错的扫子域名的网站，如下
http://subdomain.chaxun.la
0x 01 Code# coding=utf-8
# author:Anka9080
# environment">
<meta name="twitter:image" content="http://images0.cnblogs.com/blog2015/671902/201506/100041310046606.png">
  
    <link rel="alternative" href="/atom.xml" title="Anka9080&#39;s Note" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars2.githubusercontent.com/u/13638980?v=3&amp;s=460" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Anka9080</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
						<li>A propos</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="http://xss.evilclay.com">XSS 平台</a></li>
				        
							<li><a href="/2048">Just 4 Fun</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Evi1CLAY" title="github">github</a>
					        
								<a class="rss" target="_blank" href="http://www.cnblogs.com/anka9080" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/amzhoupeng" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="#" title="mail">mail</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Cookie劫持/" style="font-size: 10px;">Cookie劫持</a> <a href="/tags/DirBuster/" style="font-size: 10px;">DirBuster</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoogleHacking/" style="font-size: 10px;">GoogleHacking</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/Kali/" style="font-size: 10px;">Kali</a> <a href="/tags/Nessus/" style="font-size: 10px;">Nessus</a> <a href="/tags/Nmap/" style="font-size: 10px;">Nmap</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Python脚本/" style="font-size: 10px;">Python脚本</a> <a href="/tags/SQLMap/" style="font-size: 10px;">SQLMap</a> <a href="/tags/SQL注入/" style="font-size: 13.33px;">SQL注入</a> <a href="/tags/WIFI热点伪造/" style="font-size: 10px;">WIFI热点伪造</a> <a href="/tags/Wiki/" style="font-size: 10px;">Wiki</a> <a href="/tags/ZoomEye/" style="font-size: 10px;">ZoomEye</a> <a href="/tags/kali/" style="font-size: 13.33px;">kali</a> <a href="/tags/乌云爬虫/" style="font-size: 10px;">乌云爬虫</a> <a href="/tags/信息收集/" style="font-size: 13.33px;">信息收集</a> <a href="/tags/内网渗透/" style="font-size: 10px;">内网渗透</a> <a href="/tags/多线程/" style="font-size: 16.67px;">多线程</a> <a href="/tags/安全工具/" style="font-size: 20px;">安全工具</a> <a href="/tags/密码破解/" style="font-size: 10px;">密码破解</a> <a href="/tags/御剑/" style="font-size: 10px;">御剑</a> <a href="/tags/打印机漏洞/" style="font-size: 10px;">打印机漏洞</a> <a href="/tags/正则表达式/" style="font-size: 10px;">正则表达式</a> <a href="/tags/漏洞分析/" style="font-size: 13.33px;">漏洞分析</a> <a href="/tags/目录扫描/" style="font-size: 10px;">目录扫描</a> <a href="/tags/端口扫描/" style="font-size: 13.33px;">端口扫描</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://xss.evilclay.com">XSS 平台</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/anka9080">CnBlogs博客</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">该作者并木有留下任何痕迹，相信你，会找到他是谁的 :P</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Anka9080</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="https://avatars2.githubusercontent.com/u/13638980?v=3&amp;s=460" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Anka9080</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="http://xss.evilclay.com">XSS 平台</a></li>
		        
					<li><a href="/2048">Just 4 Fun</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Evi1CLAY" title="github">github</a>
			        
						<a class="rss" target="_blank" href="http://www.cnblogs.com/anka9080" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/amzhoupeng" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="#" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-python-spider-subdomain-ip" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/06/10/python-spider-subdomain-ip/" class="article-date">
  	<time datetime="2015-06-10T09:09:11.000Z" itemprop="datePublished">2015-06-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python 爬虫获取指定主机子域名及IP信息
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python脚本/">Python脚本</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/信息收集/">信息收集</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://images0.cnblogs.com/blog2015/671902/201506/100041310046606.png" alt=""></p>
<h2 id="0x-00-前言"><a href="#0x-00-前言" class="headerlink" title="0x 00 前言"></a>0x 00 前言</h2><p>前天自己在玩的时候，自己通过百度搜索主机的二级域名感觉好麻烦，自已要一页页的去翻</p>
<p>而且人工识别是否是重复的二级域名也够蛋疼的，正好最近在学正则表达式，权当练手了</p>
<p>2016年更新：<br>发现了一些不错的扫子域名的网站，如下</p>
<p><strong><a href="http://subdomain.chaxun.la" target="_blank" rel="external">http://subdomain.chaxun.la</a></strong></p>
<h2 id="0x-01-Code"><a href="#0x-01-Code" class="headerlink" title="0x 01 Code"></a>0x 01 Code</h2><pre><code># coding=utf-8
# author:Anka9080
# environment:Eclipse

import urllib
import urllib2
import cookielib
import re


#site = &apos;baidu.com&apos;
print &apos;Please input the root site like &quot;baidu.com&quot;:&apos;
site = raw_input()
siteFormat1 = site
siteFormat1 = siteFormat1.replace(&apos;.&apos;, &apos;\.&apos;)
#print siteFormat1

urlPage = &apos;http://www.haosou.com/s?src=360sou_newhome&amp;q=site:&apos;+site
req = urllib2.Request(urlPage)
res = urllib2.urlopen(req)
html = res.read().decode(&apos;utf-8&apos;)
# 获得搜索结果的页面数
pageStr = re.search(ur&apos;找到相关结果约(.*?)个&apos;,html)
page = pageStr.group(1)
formatNum = &apos;0123456789&apos;
for c in page:
    if not c in formatNum:
        page = page.replace(c,&apos;&apos;)
page = int(page) / 10
print &apos;Total Page: &apos; + str(page)

if page &gt; 6:
    page = 6
newItems = []
for p in range(1, page):
    urlDomain = &apos;http://www.haosou.com/s?src=360sou_newhome&amp;q=site:&apos;+site+&apos;&amp;pn=&apos;+str(p)
    req = urllib2.Request(urlDomain)
    res = urllib2.urlopen(req)
    html = res.read().decode(&apos;utf-8&apos;)
    tmp = &apos;linkinfo\&quot;\&gt;\&lt;cite\&gt;(.+?\.&apos;+siteFormat1+&apos;)&apos;;
    pattern = re.compile(tmp)        
    items = re.findall(pattern, html)


    # 去重操作
    for item in items:
        if item not in newItems:  
            newItems.append(item)

print &apos;SubDomain Count: &apos;+ str(len(newItems) - 1)

for item in newItems: 

    # 获得对应 IP 信息
    pattern = re.compile(ur&apos;\&gt;\&gt;\ (.*?)\&lt;\/font[\s|\S]*?本站主数据：(.*?)\&lt;\/li\&gt;&apos;)
    urlIP = &apos;http://www.ip138.com/ips138.asp?ip=&apos;+item
    req = urllib2.Request(urlIP)
    res = urllib2.urlopen(req)
    html = res.read().decode(&apos;gb2312&apos;)    
    result = re.search(pattern,html)
    print item + &apos;    &apos; + result.group(1) + &apos;    &apos; + result.group(2)
</code></pre><p>脚本运行结果如下：</p>
<pre><code>Please input the root site like &quot;baidu.com&quot;:
baidu.com
Total Page: 2
SubDomain Count: 9
www.baidu.com    61.135.169.121    北京市 百度蜘蛛 联通
tieba.baidu.com    123.125.65.93    北京市  联通
fanyi.baidu.com    202.108.23.153    北京市  联通
wenku.baidu.com    123.125.70.102    北京市 百度蜘蛛 联通
map.baidu.com    112.80.248.48    江苏省南京市  联通
music.baidu.com    123.125.114.14    北京市  联通
zhidao.baidu.com    123.125.65.91    北京市  联通
baike.baidu.com    123.125.70.105    北京市 百度蜘蛛 联通
yun.baidu.com    123.125.65.51    北京市  联通
pan.baidu.com    202.108.23.29    北京市  联通
</code></pre><h2 id="0x-02-总结"><a href="#0x-02-总结" class="headerlink" title="0x 02 总结"></a>0x 02 总结</h2><p>　　　　思路大概是这个样子：</p>
<p>　　　　先通过<strong>urllib2.Request()</strong> 和<strong> urllib2.urlopen()</strong>访问url</p>
<p>　　　　再从返回结果中得到搜索结果页面数 </p>
<p>　　　　为了提高效率 页面数 大于 5 会只爬行搜索结果的前5个页面</p>
<p>　　　　后面 又做了去重操作 然后就得到二级域名列表咯 : )</p>
<p>　　　　中间蛋疼的 地方倒是 Py 的 转义符号问题  身边能有个可以问问的大牛多好~</p>
<p>　　　　后期 准备使用 <a href="http://dns.aizhan.com/" target="_blank" rel="external">http://dns.aizhan.com/</a> 的查询结果 直接获得 IP以及旁站信息</p>
<p>　　　　==================6.13号更新====================</p>
<p>　　　　现在已经可以查出二级域名对应的IP地址以及地理位置信息</p>
<p>　　　　感觉<a href="http://dns.aizhan.com" target="_blank" rel="external">http://dns.aizhan.com</a> 的调用比较麻烦，接口已经换成 <a href="http://www.ip138.com" target="_blank" rel="external">http://www.ip138.com</a></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/07/10/github-cmd/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          GitHub 常用命令备忘录
        
      </div>
    </a>
  
  
    <a href="/2015/01/02/fake-wifi-ap/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">搭建假冒 WIFI 热点等小(mei)白(zhi)兔(men)来蹭网啊 - -。</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">Share to: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="python-spider-subdomain-ip" data-title="Python 爬虫获取指定主机子域名及IP信息" data-url="http://www.evilclay.com/2015/06/10/python-spider-subdomain-ip/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>



  
  <section id="comments">
    <!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="post-python-spider-subdomain-ip" data-title="Python 爬虫获取指定主机子域名及IP信息" data-url="http://www.evilclay.com/2015/06/10/python-spider-subdomain-ip/"></div>
    <!-- 多说评论框 end -->
    <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
    <script type="text/javascript">
    var duoshuoQuery = {short_name:'evi1clay'};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] 
         || document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
    <!-- 多说公共JS代码 end -->
  </section>
  </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Anka9080
    	</div>
      	<div class="footer-right">

          
Analyse with <script src="http://s23.cnzz.com/z_stat.php?id=1259317280&web_id=1259317280" language="JavaScript"></script>

      	</div>
    </div>
  </div>
</footer>

    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>